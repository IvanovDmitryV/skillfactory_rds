{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описаение \n",
    "Данный блок производт парсинг обучающего набора данных для проекта [Проект 7. Выбираем авто выгодно](https://lms.skillfactory.ru/courses/course-v1:Skillfactory+DST-12+11MAR2020/courseware/c16441cf4f0a4f8486955f2be47f1cf0/67e09c15d9cd4b8eb691417898f4dfc2/1?activate_block_id=block-v1%3ASkillfactory%2BDST-12%2B11MAR2020%2Btype%40vertical%2Bblock%40f820a06d37d84dd98ab6acaa03392b5e)\n",
    "\n",
    "Данные сбираются на сайте https://auto.ru/,  \n",
    "из них формируется *pd.DataFrame* со следуюшими колонками:   \n",
    "  \n",
    "**bodytype** -   наименование типа кузова  \n",
    "**brand** -  наименование марки  \n",
    "**car_url** -  ссылка на обьявления о продаже  \n",
    "**color** -  ссылки на обьявления о продаже  \n",
    "**engineDisplacement** -  обьем двигателя  \n",
    "**enginePower** -  мощность двигателя  \n",
    "**equipment_dict** -  словарь с перечислением оснащения автомобиля.  \n",
    "**fuelType** -  тип топлива  \n",
    "**mileage** -  пробег авто  \n",
    "**modelDate** -  год начала выпуска модели  \n",
    "**model_name** -  наименование модели  \n",
    "**numberOfDoors** -  количество дверей  \n",
    "**productionDate** -  Год производства автомобиля  \n",
    "**sell_id** -  содержит id обьявления   \n",
    "**vehicleTransmission** -  содержит id обьявления  \n",
    "**vendor** -  обобщающий признак: принадлежность марки к европейским либо японским маркам  \n",
    "**Владельцы** -  количество владельцев авто  \n",
    "**ПТС** -  Колонка содержит ('Оригинал', 'Дубликат') категорию ПТС  \n",
    "**Привод** -   категория привода  \n",
    "**Руль** -   категрию право- или левосторонности управления  \n",
    "**offerprice** - цена продпажи (целевая переменная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек, установка параметров, определение функций\n",
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "# import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marks_models():\n",
    "    '''\n",
    "    возврашщает pd.Series в котором \n",
    "    индекс - название марки автомобиоя, \n",
    "    значения - списки названий моделей для каждой маркию\n",
    "    \n",
    "    '''\n",
    "    url_for_marks_models = 'https://auto.ru/catalog/cars/all/'\n",
    "    \n",
    "    marks_models = dict() \n",
    "\n",
    "\n",
    "    driver = webdriver.Chrome(service=service)  # открываем driver\n",
    "    driver.maximize_window()                    # масксимизируем окно\n",
    "\n",
    "    for pages_num in range(1,20):\n",
    "        \n",
    "        if pages_num==1: url = url_for_marks_models + '?view_type=list'\n",
    "        else:            url = url_for_marks_models + '?page_num='+ str(pages_num) +'&view_type=list'\n",
    "        \n",
    "        driver.get(url)                         # открываем страницу по url\n",
    "        res = driver.execute_script(\"return document.body.innerHTML;\") # получаем html\n",
    "        soup = BeautifulSoup(res, 'html.parser') # создаем обьект bs4.BeautifulSoup\n",
    "        \n",
    "        # Список html-ек перечня моделей каждой марки на странице:\n",
    "        marks_on_page_list = soup.find_all('dd', class_='catalog-all-text-list__desc') \n",
    "    \n",
    "        if not marks_on_page_list: \n",
    "            break\n",
    "        \n",
    "        for mark_html in marks_on_page_list:\n",
    "            models_of_mark = mark_html.find_all('a', class_='link_theme_auto') # список html-ек моделей марки\n",
    "        \n",
    "            link_for_mark_name = models_of_mark[0].get('href')  # линк первой модели, содержит обозначене марки на auto.ru\n",
    "            mark_start = link_for_mark_name.find('cars/') + 5   # первый символ обозначеня марки\n",
    "            mark_end = link_for_mark_name.find('/', mark_start) # последний символ обозначения марки\n",
    "            mark_name = link_for_mark_name[mark_start:mark_end].upper() # получение обозначения марки  \n",
    "        \n",
    "            models_list = []\n",
    "            for model in models_of_mark:\n",
    "                link_theme_auto = model.get('href')                 # линк модели, содержит обозначение модели на auto.ru\n",
    "                model_start = mark_end+1                            # первый символ обозначения модели\n",
    "                model_end = link_theme_auto.find('/', model_start)  # последний символ обозначения модели\n",
    "                model_name = link_theme_auto[model_start:model_end].upper() # получение обозначения модели\n",
    "                models_list.append(model_name)\n",
    "                \n",
    "            marks_models[mark_name] = models_list\n",
    "        \n",
    "        time.sleep(1) \n",
    "    # Закрываем процесс браузера:\n",
    "    driver.quit()\n",
    "    \n",
    "    return marks_models\n",
    "\n",
    "def get_generation_year(model_url,driver):\n",
    "    '''\n",
    "    возврашщает pd.DataFrame  в котором: \n",
    "        full_name - полное название модели с указанием поколения, \n",
    "        bodytype - тип кузова поколения модели\n",
    "        generation_year - год начала выпуска поколения\n",
    "        \n",
    "    model_url - ссылка на страницу со списокм поколений модели\n",
    "    \n",
    "    '''\n",
    "    driver.get(model_url+'?output_type=models_list') # открываем страницу по url\n",
    "    \n",
    "    models_list_res = driver.execute_script(\"return document.body.innerHTML;\") # получаем html        \n",
    "    \n",
    "    # создаем обьект bs4.BeautifulSoup из html: \n",
    "    models_list_bs = BeautifulSoup(models_list_res, 'html.parser') \n",
    "    \n",
    "    # получаем список html-ек описаний для всех поколений модели  \n",
    "    posting_tag = models_list_bs.find_all('h3',class_ = \"ListingItemGroup__title\")\n",
    "    \n",
    "    # формируем списки с указанием поколения модели, типом кузова поколения и годом начала выпуска поколения\n",
    "    # (необходимость указания типа кузова вызвана тем, что разные кузова зачастую переходят на следующее \n",
    "    #  поколение в разные годы)\n",
    "    data = [\n",
    "    [tag.find('a',class_ = 'ListingItemTitle__link').text,             # поколение\n",
    "     tag.find('div',class_ = \"ListingItemGroup__subtitle\").text[:      # кузов\n",
    "        tag.find('div',class_ = \"ListingItemGroup__subtitle\").text.find(' •')],\n",
    "     int(tag.find('div',class_ = \"ListingItemGroup__subtitle\").text    # год\n",
    "        [tag.find('div',class_ = \"ListingItemGroup__subtitle\").text.find('(')+1:\n",
    "        tag.find('div',class_ = \"ListingItemGroup__subtitle\").text.find('(')+5])] \n",
    "        for tag in posting_tag]\n",
    "    result = pd.DataFrame(data,columns = ['full_name','bodytype','generation_year'])\n",
    "    return result \n",
    "\n",
    "def get_model_generation_year(marks_models_for_parsing):\n",
    "    '''\n",
    "    возврашщает pd.DataFrame  в котором: \n",
    "        full_name - полное название марки и модели с указанием поколения \n",
    "        bodytype - тип кузова поколения модели\n",
    "        generation_year - год начала выпуска поколения\n",
    "    \n",
    "    marks_models_for_parsing - pd.Series в котором\n",
    "        индекс: марка автомобиля\n",
    "        значение: список моделей данной марки\n",
    "    '''\n",
    "    driver = webdriver.Chrome(service=service)  # запускаем процесс браузера\n",
    "    driver.maximize_window()                    # масксимизируем окно    \n",
    "    \n",
    "    model_generation_year = pd.DataFrame(columns = ['full_name','bodytype','generation_year'])\n",
    "    \n",
    "    for mark in marks_models_for_parsing:\n",
    "        print(mark, end=' | ')\n",
    "        \n",
    "        for model in marks_models_for_parsing[mark]:\n",
    "            model_url = 'https://auto.ru/moskva/cars/' + mark.lower() + '/' + model.lower() + '/used/'\n",
    "            tmp = get_generation_year(model_url,driver)\n",
    "            model_generation_year = model_generation_year.append(tmp)\n",
    "            time.sleep(1)\n",
    "            \n",
    "    driver.quit()    # закрываем процесс браузера\n",
    "    \n",
    "    return model_generation_year\n",
    "\n",
    "def get_features_from_ticket(ticket_url, driver):\n",
    "    '''\n",
    "    возвращает pd.Series с признакамии полученными из карточки обьявления\n",
    "    \n",
    "    ticket_url: str, ссылка на страницу обьявления\n",
    "    service : обьект selenium.webdriver.chrome.service\n",
    "        \n",
    "    '''\n",
    "    features = pd.Series(index = data_columns)\n",
    "    \n",
    "    # получем html карточки текщего обьявления\n",
    "#     driver = webdriver.Chrome(service=service)\n",
    "#     driver.maximize_window()\n",
    "    driver.get(ticket_url)\n",
    "    # Находим и кликаем 'Все опции'\n",
    "    try:\n",
    "        butt = driver.find_element(By.CLASS_NAME, 'ComplectationGroupsDesktop__cut') \n",
    "        butt.click() \n",
    "    except Exception: pass\n",
    "    # Получаем содержимое html-страницы:\n",
    "    ticket_res = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "    # Закрываем процесс браузера:\n",
    "#     driver.quit()\n",
    "    # создаем обьект bs4.BeautifulSoup из html карточки текщего обьявления\n",
    "    ticket_bs = BeautifulSoup(ticket_res, 'html.parser')  \n",
    "\n",
    "    # проверка корректности результата BeautifulSoup\n",
    "    if ticket_bs:\n",
    "    # получение признаков из карточки текущего обьявления\n",
    "        # bodyType      \n",
    "        try: features['bodyType'] = ticket_bs.find('li',class_='CardInfoRow_bodytype').find('a').text\n",
    "        except Exception: features['bodytype'] = np.NaN\n",
    "\n",
    "        # brand        \n",
    "        try: features['brand'] = ticket_bs.find_all('a',class_='CardBreadcrumbs__itemText')[2].text.strip().upper()\n",
    "        except Exception: features['brand'] = np.NaN\n",
    "            \n",
    "        # car_url\n",
    "        features['car_url'] = ticket_url\n",
    "            \n",
    "        # color        \n",
    "        try: features['color'] = ticket_bs.find('li',class_='CardInfoRow_color').find('a').text\n",
    "        except Exception: features['color'] = np.NaN \n",
    "            \n",
    "        # description\n",
    "        try:\n",
    "            rows = ticket_bs.find('div',class_='CardDescriptionHTML').find_all('span')\n",
    "            features['description'] = '\\n'.join([row.text for row in rows])\n",
    "        except Exception: features['description'] = np.NaN\n",
    "        \n",
    "        #engineDisplacement            \n",
    "        try: \n",
    "            engineDisplacement = ticket_bs.find('li',class_='CardInfoRow_engine').find('div').text.split(' / ')[0]\n",
    "            features['engineDisplacement'] =  re.sub(\"[^\\d.]\", \"\", engineDisplacement)\n",
    "        except Exception: features['engineDisplacement'] = np.NaN\n",
    "            \n",
    "        # enginePower\n",
    "        try: \n",
    "            enginePower = ticket_bs.find('li',class_='CardInfoRow_engine').find('div').text.split(' / ')[1]\n",
    "            features['enginePower'] = re.sub(\"\\D\", \"\", enginePower)\n",
    "        except Exception: features['enginePower'] = np.NaN            \n",
    "\n",
    "        # equipment_dict \n",
    "        try: \n",
    "            complectation_groups = ticket_bs.find(\n",
    "                'div',class_='ComplectationGroupsDesktop__row').find_all(\n",
    "                'div',class_='ComplectationGroupsDesktop__group')\n",
    "            features['equipment_dict'] = {\n",
    "                group.text.split('•')[0]: group.text.split('•')[1:] for group in complectation_groups}\n",
    "        except Exception: features['equipment_dict'] = np.NaN             \n",
    "  \n",
    "        # fuelType\n",
    "        try: features['fuelType'] = ticket_bs.find('li',class_='CardInfoRow_engine').find('div').text.split(' / ')[2]\n",
    "        \n",
    "        except Exception: features['fuel_type'] = np.NaN\n",
    "            \n",
    "        # mileage\n",
    "        try:\n",
    "            mileage = ticket_bs.find('li',class_='CardInfoRow_kmAge').find_all('span')[1].text\n",
    "            features['mileage'] = re.sub(\"\\D\", \"\", mileage)\n",
    "        except Exception: features['mileage'] = np.NaN            \n",
    "            \n",
    "        # model_name\n",
    "        brand = features['brand']\n",
    "        model_name_start = ticket_url.find(brand.lower()) + len(brand) + 1\n",
    "        model_name_end = ticket_url.find('/',model_name_start)\n",
    "        features['model_name'] = ticket_url[model_name_start:model_name_end].upper()        \n",
    "#         try: features['model_name'] = ticket_bs.find_all('a',class_='CardBreadcrumbs__itemText')[3].text.strip()\n",
    "#         except Exception: features['model_name'] = np.NaN            \n",
    "            \n",
    "        # numberOfDoors\n",
    "        try:\n",
    "            numberOfDoors_tag = ticket_bs.find('li',class_='CardInfoRow_bodytype').find('a')\n",
    "            numberOfDoors_pre = re.findall('\\d', numberOfDoors_tag.text)\n",
    "            features['numberOfDoors'] = int(numberOfDoors_pre[0])\n",
    "        except Exception: features['numberOfDoors'] = np.NaN\n",
    "\n",
    "        # productionDate\n",
    "        try: features['productionDate'] = ticket_bs.find('li',class_='CardInfoRow_year').find('a').text\n",
    "        except Exception: features['productionDate'] = np.NaN\n",
    "            \n",
    "        # sell_id\n",
    "        try:         \n",
    "            invers_ticket_url = ticket_url[::-1]\n",
    "            id_start, id_end = invers_ticket_url.find('/',1) , invers_ticket_url.find('-')+1\n",
    "            features['sell_id'] = ticket_url[-id_start:-id_end]\n",
    "        except Exception: features['sell_id'] = np.NaN\n",
    "            \n",
    "        # vehicleTransmission\n",
    "        try:\n",
    "            features['vehicleTransmission'] = (ticket_bs.find('li',class_='CardInfoRow_transmission').\n",
    "                                               find_all('span')[1].text)\n",
    "        except Exception: features['vehicleTransmission'] = np.NaN            \n",
    "            \n",
    "        # vendor\n",
    "        european = ['SKODA', 'AUDI',  'VOLVO', 'BMW', 'MERCEDES', 'VOLKSWAGEN']\n",
    "        japanese = ['HONDA','NISSAN','TOYOTA','INFINITI',  'LEXUS', 'MITSUBISHI']\n",
    "        if features['brand'] in european :  features['vendor'] = 'EUROPEAN'\n",
    "        elif features['brand'] in japanese :  features['vendor'] = 'JAPANESE'\n",
    "        else: features['vendor'] = 'NAN'  \n",
    "\n",
    "        # Владение\n",
    "        \n",
    "        try: features['Владение'] = ticket_bs.find('li',class_='CardInfoRow_owningTime').find_all('span')[1].text\n",
    "        except Exception: features['Владение'] = np.NaN             \n",
    "            \n",
    "        # Владельцы\n",
    "        try: features['Владельцы'] = ticket_bs.find('li',class_='CardInfoRow_ownersCount').find_all('span')[1].text\n",
    "        except Exception: features['Владельцы'] = np.NaN            \n",
    "            \n",
    "        # ПТС\n",
    "        try: features['ПТС'] = ticket_bs.find('li',class_='CardInfoRow_pts').find_all('span')[1].text\n",
    "        except Exception: features['ПТС'] = np.NaN               \n",
    "            \n",
    "        # Привод\n",
    "        try: features['Привод'] = ticket_bs.find('li',class_='CardInfoRow_drive').find_all('span')[1].text\n",
    "        except Exception: features['Привод'] = np.NaN            \n",
    "            \n",
    "        # Руль\n",
    "        try: features['Руль'] = ticket_bs.find('li',class_='CardInfoRow_wheel').find_all('span')[1].text \n",
    "        except Exception: features['Руль'] = np.NaN         \n",
    "            \n",
    "        # Цена предложения\n",
    "        try:\n",
    "            offerprice = ticket_bs.find('span',class_='OfferPriceCaption__price').text\n",
    "            features['offerprice'] = re.sub(\"\\D\", \"\", offerprice)\n",
    "        except Exception: features['offerprice'] = np.NaN\n",
    "\n",
    "        # modelDate              \n",
    "        try:\n",
    "            modelDate_tag = ticket_bs.find_all('a',class_='CardBreadcrumbs__itemText')\n",
    "            features['modelDate'] = (modelDate_tag[2].text.strip() + ' ' +\n",
    "                                     modelDate_tag[3].text.strip() + ' ' +\n",
    "                                     modelDate_tag[4].text.strip())  \n",
    "        except Exception: features['modelDate'] = np.NaN   \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка параметров, определение констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "service=Service('C:/Users/GANSOR-PC/chromium/chromedriver.exe') # C:\\Users\\GANSOR-PC\n",
    "executable_path = 'C:/Users/GANSOR-PC/chromium/chromedriver.exe'\n",
    "marks_for_parsing = ['SKODA', 'AUDI', 'HONDA', 'VOLVO', 'BMW', 'NISSAN', 'INFINITI',\n",
    "       'MERCEDES', 'TOYOTA', 'LEXUS', 'VOLKSWAGEN', 'MITSUBISHI']\n",
    "\n",
    "# data_columns = ['bodyType', 'brand', 'car_url', 'color', 'engineDisplacement',\n",
    "#        'enginePower', 'equipment_dict', 'fuelType', 'mileage', 'modelDate',\n",
    "#        'model_name', 'numberOfDoors', 'productionDate', 'sell_id', 'vehicleTransmission',\n",
    "#        'vendor', 'Владельцы', 'ПТС', 'Привод', 'Руль', 'offerprice'] \n",
    "data_columns = ['bodyType', 'brand', 'car_url', 'color', 'engineDisplacement', 'enginePower', \n",
    "                      'equipment_dict','fuelType', 'mileage', 'modelDate', 'model_name', 'numberOfDoors', \n",
    "                      'productionDate', 'sell_id', 'vehicleTransmission', 'vendor', \n",
    "                      'Владельцы', 'Владение', 'ПТС', 'Привод', 'Руль']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг\n",
    "## Парсинг вспомогательных данных\n",
    "### Создаем и наполняем ***`marks_models `*** , получаем ***`marks_models_for_parsing`*** и \n",
    "***marks_models*** - словарь в которм   \n",
    "ключ:  обозначения марки на сайте auto.ru  \n",
    "значения: списки всех моделей для каждой марки.\n",
    "\n",
    "***marks_models_for_parsing*** - содержит только марки, присутсвующие в валидационном наборе данных **test**\n",
    "\n",
    "затем сохраняем / читаем сохраненный ***marks_models_for_parsing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marks_models = get_marks_models()\n",
    "# marks_models_for_parsing = dict([(k, marks_models.get(k)) for k in marks_for_parsing])\n",
    "\n",
    "# with open('./Project_7_data/marks_models_for_parsing.json', 'w') as f: json.dump(marks_models_for_parsing, f)\n",
    "with open('./Project_7_data/marks_models_for_parsing.json') as f: marks_models_for_parsing = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем и заполняем `model_generation_year`\n",
    "***model_generation_year*** - **pd.DataFrame**  в котором:  \n",
    "        *full_name* - полное название марки и модели с указанием поколения;   \n",
    "        *bodytype* - тип кузова поколения модели;  \n",
    "        *generation_year* - год начала выпуска поколения  \n",
    "\n",
    "Этот DataFrame нужен для преобразования полного названия модели в год начала выпуска модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model_generation_year_all =  get_model_generation_year(marks_models_for_parsing)\n",
    "\n",
    "# model_generation_year_all.to_csv('./Project_5_data/model_generation_year.csv',index=False)\n",
    "model_generation_year = pd.read_csv('./Project_7_data/model_generation_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг набора данных для обучения\n",
    "## Получение данных по маркам, присутсвующим в валидационном наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(columns=data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SKODA', 'AUDI', 'HONDA', 'VOLVO', 'BMW', 'NISSAN', 'INFINITI', 'MERCEDES', 'TOYOTA', 'LEXUS', 'VOLKSWAGEN', 'MITSUBISHI'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marks_models_for_parsing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HONDA\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ee90e0509d73>\u001b[0m in \u001b[0;36mget_features_from_ticket\u001b[1;34m(ticket_url, driver)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;31m#     driver = webdriver.Chrome(service=service)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;31m#     driver.maximize_window()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticket_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[1;31m# Находим и кликаем 'Все опции'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     70\u001b[0m             return self.request_encode_body(method, url, fields=fields,\n\u001b[0;32m     71\u001b[0m                                             \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                                             **urlopen_kw)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     def request_encode_url(self, method, url, fields=None, headers=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for mark in {k: marks_models_for_parsing[k] for k in ['HONDA'] }: # 'VOLKSWAGEN' 'MITSUBISHI'\n",
    "    print(mark)\n",
    "    for model in marks_models_for_parsing[mark]:      \n",
    "        model_url = 'https://auto.ru/moskva/cars/' + mark + '/' + model + '/used/' + '?output_type=table'\n",
    "    # просмотр последовательно всех страниц текущей модели-model текущей марки-mark\n",
    "        for pages_num in range(1,10): \n",
    "            if pages_num==1: page_url = model_url\n",
    "            else:            page_url = model_url + '&page=' +  str(pages_num)  \n",
    "            # получем html страницы\n",
    "            driver = webdriver.Chrome(executable_path)\n",
    "            driver.maximize_window()\n",
    "            driver.get(page_url)\n",
    "            page_html = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "            # создаем обьект bs4.BeautifulSoup из html страницы\n",
    "            page_bs = BeautifulSoup(page_html, 'html.parser') \n",
    "            # список html-ек карточек на странице                                               \n",
    "            tickets_on_page = page_bs.find_all('a', class_='ListingItemTitle__link') \n",
    "            # выход по исчерпанию страниц текущей модели текущей марки\n",
    "            if not tickets_on_page: \n",
    "                driver.quit()\n",
    "                break            \n",
    "            # обработка карточек на странице\n",
    "            for ticket in tickets_on_page:\n",
    "                # получаем url карточки текущего обьявления\n",
    "                ticket_url = ticket.get('href')\n",
    "                # извлекаем признаки и заполняем строку train-а\n",
    "                train.loc[len(train)] =get_features_from_ticket(ticket_url,driver)\n",
    "                time.sleep(0.5) \n",
    "            time.sleep(0.5) \n",
    "            driver.quit()\n",
    "        print ('|',len(train),end='') # <==============================             \n",
    "    print ('|') # <==============================       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3 entries, 0 to 2\n",
      "Data columns (total 21 columns):\n",
      "bodyType               3 non-null object\n",
      "brand                  3 non-null object\n",
      "car_url                3 non-null object\n",
      "color                  3 non-null object\n",
      "engineDisplacement     3 non-null object\n",
      "enginePower            3 non-null object\n",
      "equipment_dict         3 non-null object\n",
      "fuelType               3 non-null object\n",
      "mileage                3 non-null object\n",
      "modelDate              3 non-null object\n",
      "model_name             3 non-null object\n",
      "numberOfDoors          0 non-null object\n",
      "productionDate         3 non-null object\n",
      "sell_id                3 non-null object\n",
      "vehicleTransmission    3 non-null object\n",
      "vendor                 3 non-null object\n",
      "Владельцы              3 non-null object\n",
      "Владение               3 non-null object\n",
      "ПТС                    3 non-null object\n",
      "Привод                 3 non-null object\n",
      "Руль                   3 non-null object\n",
      "dtypes: object(21)\n",
      "memory usage: 528.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    accord\n",
       "1    accord\n",
       "2    accord\n",
       "Name: model_name, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('./Project_7_data/train_mod.csv',index=False)\n",
    "# train = pd.read_csv('./Project_7_data/train_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./Project_7_data/train_mod.csv' does not exist: b'./Project_7_data/train_mod.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-999b592d4cf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Project_7_data/train_mod.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./Project_7_data/train_mod.csv' does not exist: b'./Project_7_data/train_mod.csv'"
     ]
    }
   ],
   "source": [
    "# pd.read_csv('./Project_7_data/train_mod.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========== TEST ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FABIA',\n",
       " 'FABIA_RS',\n",
       " 'FELICIA',\n",
       " 'FORMAN',\n",
       " 'KAROQ',\n",
       " 'KODIAQ',\n",
       " 'OCTAVIA',\n",
       " 'OCTAVIA_RS',\n",
       " 'RAPID',\n",
       " 'ROOMSTER',\n",
       " 'SUPERB',\n",
       " 'YETI']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marks_models_for_parsing['SKODA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://auto.ru/moskva/cars/SKODA/FABIA/used/'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mark = 'SKODA'\n",
    "model = 'FABIA'\n",
    "\n",
    "model_url = 'https://auto.ru/moskva/cars/' + mark + '/' + model + '/used/'\n",
    "model_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SKODA': ['FABIA',\n",
       "  'FABIA_RS',\n",
       "  'FELICIA',\n",
       "  'FORMAN',\n",
       "  'KAROQ',\n",
       "  'KODIAQ',\n",
       "  'OCTAVIA',\n",
       "  'OCTAVIA_RS',\n",
       "  'RAPID',\n",
       "  'ROOMSTER',\n",
       "  'SUPERB',\n",
       "  'YETI']}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([(k, marks_models_for_parsing.get(k)) for k in ['SKODA']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= EXERCISE ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc': 1, 'def': [2, 3]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_json = {'abc': 1, \n",
    "           'def': [2,3]}\n",
    "to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc': 1, 'def': [2, 3]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('example.json', 'w') as f: json.dump(to_json, f)\n",
    "with open('example.json') as f: from_json = json.loads(f.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for mark in marks_models_for_parsing.index:\n",
    "    for model in marks_models_for_parsing[mark]:\n",
    "        model_url = 'https://auto.ru/moskva/cars/' + mark + '/' + model + '/used/'\n",
    "\n",
    "    # просмотр последовательно всех страниц текущей модели-model текущей марки-mark\n",
    "        for pages_num in range(1,100): \n",
    "        \n",
    "            if pages_num==1: params = {}\n",
    "            else:            params = {'page': pages_num}\n",
    "    \n",
    "            res = requests.get(model_url + '?output_type=table', params=params, headers=headers)\n",
    "            res.encoding = 'utf-8'\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "            # создаем обьект bs4.BeautifulSoup из html очередной страницы с обьявлениями по текущей модели текущей марки\n",
    "            soup = BeautifulSoup(res.text, 'html.parser')  \n",
    "    \n",
    "            # список html-ек карточек на странице                                               \n",
    "            tickets_on_page_list = soup.find_all('a', class_='ListingItemTitle-module__link') \n",
    "    \n",
    "            if not tickets_on_page_list: # выход по исчерпанию страниц текущей модели текущей марки\n",
    "                break\n",
    "        \n",
    "            # обработка карточек на странице\n",
    "            for ticket in tickets_on_page_list:\n",
    "                # получаем url карточки текущего обьявления\n",
    "                ticket_url = ticket.get('href')\n",
    "    \n",
    "                # извлекаем признаки и заполняем строку train-а\n",
    "                train.loc[len(train)] = get_features_from_ticket(ticket_url)\n",
    "                ''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
