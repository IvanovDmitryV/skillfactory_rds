{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описаение \n",
    "Данный блок производт парсинг обучающего набора данных для проекта [Проект 7. Выбираем авто выгодно](https://lms.skillfactory.ru/courses/course-v1:Skillfactory+DST-12+11MAR2020/courseware/c16441cf4f0a4f8486955f2be47f1cf0/67e09c15d9cd4b8eb691417898f4dfc2/1?activate_block_id=block-v1%3ASkillfactory%2BDST-12%2B11MAR2020%2Btype%40vertical%2Bblock%40f820a06d37d84dd98ab6acaa03392b5e)\n",
    "\n",
    "Данные сбираются на сайте https://auto.ru/,  \n",
    "из них формируется *pd.DataFrame* со следуюшими колонками:   \n",
    "  \n",
    "**bodytype** -   наименование типа кузова  \n",
    "**brand** -  наименование марки  \n",
    "**car_url** -  ссылка на обьявления о продаже  \n",
    "**color** -  ссылки на обьявления о продаже  \n",
    "**engineDisplacement** -  обьем двигателя  \n",
    "**enginePower** -  мощность двигателя  \n",
    "**equipment_dict** -  словарь с перечислением оснащения автомобиля.  \n",
    "**fuel_type** -  тип топлива  \n",
    "**mileage** -  пробег авто  \n",
    "**modelDate** -  год начала выпуска модели  \n",
    "**model_name** -  наименование модели  \n",
    "**numberOfDoors** -  количество дверей  \n",
    "**productionDate** -  Год производства автомобиля  \n",
    "**sell_id** -  содержит id обьявления   \n",
    "**vehicleTransmission** -  содержит id обьявления  \n",
    "**vendor** -  обобщающий признак: принадлежность марки к европейским либо японским маркам  \n",
    "**Владельцы** -  количество владельцев авто  \n",
    "**ПТС** -  Колонка содержит ('Оригинал', 'Дубликат') категорию ПТС  \n",
    "**Привод** -   категория привода  \n",
    "**Руль** -   категрию право- или левосторонности управления  \n",
    "**offerprice** - цена продпажи (целевая переменная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек, установка параметров, определение функций\n",
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "# import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marks_models():\n",
    "    '''\n",
    "    возврашщает pd.Series в котором \n",
    "    индекс - название марки автомобиоя, \n",
    "    значения - списки названий моделей для каждой маркию\n",
    "    \n",
    "    '''\n",
    "    url_for_marks_models = 'https://auto.ru/catalog/cars/all/'\n",
    "    \n",
    "#     marks_models = pd.Series() \n",
    "    marks_models = dict() \n",
    "\n",
    "\n",
    "    driver = webdriver.Chrome(service=service)  # открываем driver\n",
    "    driver.maximize_window()                    # масксимизируем окно\n",
    "\n",
    "    for pages_num in range(1,20):\n",
    "        \n",
    "        if pages_num==1: url = url_for_marks_models + '?view_type=list'\n",
    "        else:            url = url_for_marks_models + '?page_num='+ str(pages_num) +'&view_type=list'\n",
    "        \n",
    "        driver.get(url)                         # открываем страницу по url\n",
    "        res = driver.execute_script(\"return document.body.innerHTML;\") # получаем html\n",
    "        soup = BeautifulSoup(res, 'html.parser') # создаем обьект bs4.BeautifulSoup\n",
    "        \n",
    "        # Список html-ек перечня моделей каждой марки на странице:\n",
    "        marks_on_page_list = soup.find_all('dd', class_='catalog-all-text-list__desc') \n",
    "    \n",
    "        if not marks_on_page_list: \n",
    "            break\n",
    "        \n",
    "        for mark_html in marks_on_page_list:\n",
    "            models_of_mark = mark_html.find_all('a', class_='link_theme_auto') # список html-ек моделей марки\n",
    "        \n",
    "            link_for_mark_name = models_of_mark[0].get('href')  # линк первой модели, содержит обозначене марки на auto.ru\n",
    "            mark_start = link_for_mark_name.find('cars/') + 5   # первый символ обозначеня марки\n",
    "            mark_end = link_for_mark_name.find('/', mark_start) # последний символ обозначения марки\n",
    "            mark_name = link_for_mark_name[mark_start:mark_end].upper() # получение обозначения марки  \n",
    "        \n",
    "            models_list = []\n",
    "            for model in models_of_mark:\n",
    "                link_theme_auto = model.get('href')                 # линк модели, содержит обозначение модели на auto.ru\n",
    "                model_start = mark_end+1                            # первый символ обозначения модели\n",
    "                model_end = link_theme_auto.find('/', model_start)  # последний символ обозначения модели\n",
    "                model_name = link_theme_auto[model_start:model_end].upper() # получение обозначения модели\n",
    "                models_list.append(model_name)\n",
    "                \n",
    "            marks_models[mark_name] = models_list\n",
    "        \n",
    "        time.sleep(1) \n",
    "    # Закрываем процесс браузера:\n",
    "    driver.quit()\n",
    "    \n",
    "    return marks_models\n",
    "\n",
    "def get_generation_year(model_url,driver):\n",
    "    '''\n",
    "    возврашщает pd.DataFrame  в котором: \n",
    "        full_name - полное название модели с указанием поколения, \n",
    "        bodytype - тип кузова поколения модели\n",
    "        generation_year - год начала выпуска поколения\n",
    "        \n",
    "    model_url - ссылка на страницу со списокм поколений модели\n",
    "    \n",
    "    '''\n",
    "    driver.get(model_url+'?output_type=models_list') # открываем страницу по url\n",
    "    \n",
    "    models_list_res = driver.execute_script(\"return document.body.innerHTML;\") # получаем html        \n",
    "    \n",
    "    # создаем обьект bs4.BeautifulSoup из html: \n",
    "    models_list_bs = BeautifulSoup(models_list_res, 'html.parser') \n",
    "    \n",
    "    # получаем список html-ек описаний для всех поколений модели  \n",
    "    posting_tag = models_list_bs.find_all('h3',class_ = \"ListingItemGroup__title\")\n",
    "    \n",
    "    # формируем списки с указанием поколения модели, типом кузова поколения и годом начала выпуска поколения\n",
    "    # (необходимость указания типа кузова вызвана тем, что разные кузова зачастую переходят на следующее \n",
    "    #  поколение в разные годы)\n",
    "    \n",
    "    \n",
    "    \n",
    "    data = [\n",
    "    [tag.find('a',class_ = 'ListingItemTitle__link').text,             # поколение\n",
    "     tag.find('div',class_ = \"ListingItemGroup__subtitle\").text[:      # кузов\n",
    "                tag.find('div',class_ = \"ListingItemGroup__subtitle\").text.find(' •')],\n",
    "     int(tag.find('div',class_ = \"ListingItemGroup__subtitle\").text    # год\n",
    "                [tag.find('div',class_ = \"ListingItemGroup__subtitle\").text.find('(')+1:\n",
    "                 tag.find('div',class_ = \"ListingItemGroup__subtitle\").text.find('(')+5])] \n",
    "        \n",
    "        for tag in posting_tag]\n",
    "    \n",
    "    result = pd.DataFrame(data,columns = ['full_name','bodytype','generation_year'])\n",
    "    \n",
    "    return result \n",
    "\n",
    "def get_model_generation_year(marks_models_for_parsing):\n",
    "    '''\n",
    "    возврашщает pd.DataFrame  в котором: \n",
    "        full_name - полное название марки и модели с указанием поколения \n",
    "        bodytype - тип кузова поколения модели\n",
    "        generation_year - год начала выпуска поколения\n",
    "    \n",
    "    marks_models_for_parsing - pd.Series в котором\n",
    "        индекс: марка автомобиля\n",
    "        значение: список моделей данной марки\n",
    "    '''\n",
    "    driver = webdriver.Chrome(service=service)  # запускаем процесс браузера\n",
    "    driver.maximize_window()                    # масксимизируем окно    \n",
    "    \n",
    "    model_generation_year = pd.DataFrame(columns = ['full_name','bodytype','generation_year'])\n",
    "    \n",
    "    for mark in marks_models_for_parsing:\n",
    "        print(mark, end=' | ')\n",
    "        \n",
    "        for model in marks_models_for_parsing[mark]:\n",
    "            model_url = 'https://auto.ru/moskva/cars/' + mark.lower() + '/' + model.lower() + '/used/'\n",
    "            tmp = get_generation_year(model_url,driver)\n",
    "            model_generation_year = model_generation_year.append(tmp)\n",
    "            time.sleep(1)\n",
    "            \n",
    "    driver.quit()    # закрываем процесс браузера\n",
    "    \n",
    "    return model_generation_year\n",
    "\n",
    "def get_features_from_ticket(ticket_url, driver):\n",
    "    '''\n",
    "    возвращает pd.Series с признакамии полученными из карточки обьявления\n",
    "    \n",
    "    ticket_url: str, ссылка на страницу обьявления\n",
    "    service : обьект selenium.webdriver.chrome.service\n",
    "        \n",
    "    '''\n",
    "    features = pd.Series(index = data_columns)\n",
    "    \n",
    "    # получем html карточки текщего обьявления\n",
    "#     driver = webdriver.Chrome(service=service)\n",
    "#     driver.maximize_window()\n",
    "    driver.get(ticket_url)\n",
    "    # Находим и кликаем 'Все опции'\n",
    "    try:\n",
    "        butt = driver.find_element(By.CLASS_NAME, 'ComplectationGroupsDesktop__cut') \n",
    "        butt.click() \n",
    "    except Exception: pass\n",
    "    # Получаем содержимое html-страницы:\n",
    "    ticket_res = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "    # Закрываем процесс браузера:\n",
    "#     driver.quit()\n",
    "    # создаем обьект bs4.BeautifulSoup из html карточки текщего обьявления\n",
    "    ticket_bs = BeautifulSoup(ticket_res, 'html.parser')  \n",
    "\n",
    "    # проверка корректности результата BeautifulSoup\n",
    "    if ticket_bs:\n",
    "    # получение признаков из карточки текущего обьявления\n",
    "        # bodyType      \n",
    "        try: features['bodyType'] = ticket_bs.find('li',class_='CardInfoRow_bodytype').find('a').text\n",
    "        except Exception: features['bodytype'] = np.NaN\n",
    "\n",
    "        # brand        \n",
    "        try: features['brand'] = ticket_bs.find_all('a',class_='CardBreadcrumbs__itemText')[2].text.strip().upper()\n",
    "        except Exception: features['brand'] = np.NaN\n",
    "            \n",
    "        # car_url\n",
    "        features['car_url'] = ticket_url\n",
    "            \n",
    "        # color        \n",
    "        try: features['color'] = ticket_bs.find('li',class_='CardInfoRow_color').find('a').text\n",
    "        except Exception: features['color'] = np.NaN \n",
    "            \n",
    "        # description\n",
    "        try:\n",
    "            rows = ticket_bs.find('div',class_='CardDescriptionHTML').find_all('span')\n",
    "            features['description'] = '\\n'.join([row.text for row in rows])\n",
    "        except Exception: features['description'] = np.NaN\n",
    "        \n",
    "        #engineDisplacement            \n",
    "        try: \n",
    "            engineDisplacement = ticket_bs.find('li',class_='CardInfoRow_engine').find('div').text.split(' / ')[0]\n",
    "            features['engineDisplacement'] =  re.sub(\"[^\\d.]\", \"\", engineDisplacement)\n",
    "        except Exception: features['engineDisplacement'] = np.NaN\n",
    "            \n",
    "        # enginePower\n",
    "        try: \n",
    "            enginePower = ticket_bs.find('li',class_='CardInfoRow_engine').find('div').text.split(' / ')[1]\n",
    "            features['enginePower'] = re.sub(\"\\D\", \"\", enginePower)\n",
    "        except Exception: features['enginePower'] = np.NaN            \n",
    "\n",
    "        # equipment_dict \n",
    "        try: \n",
    "            complectation_groups = ticket_bs.find(\n",
    "                'div',class_='ComplectationGroupsDesktop__row').find_all(\n",
    "                'div',class_='ComplectationGroupsDesktop__group')\n",
    "            features['equipment_dict'] = {\n",
    "                group.text.split('•')[0]: group.text.split('•')[1:] for group in complectation_groups}\n",
    "        except Exception: features['equipment_dict'] = np.NaN             \n",
    "  \n",
    "        # fuel_type\n",
    "        try: features['fuel_type'] = ticket_bs.find('li',class_='CardInfoRow_engine').find('div').text.split(' / ')[2]\n",
    "        \n",
    "        except Exception: features['fuel_type'] = np.NaN\n",
    "            \n",
    "        # mileage\n",
    "        try:\n",
    "            mileage = ticket_bs.find('li',class_='CardInfoRow_kmAge').find_all('span')[1].text\n",
    "            features['mileage'] = re.sub(\"\\D\", \"\", mileage)\n",
    "        except Exception: features['mileage'] = np.NaN            \n",
    "            \n",
    "        # model_name\n",
    "        try: features['model_name'] = ticket_bs.find_all('a',class_='CardBreadcrumbs__itemText')[3].text.strip()\n",
    "        except Exception: features['model_name'] = np.NaN            \n",
    "            \n",
    "        # numberOfDoors\n",
    "        try:\n",
    "            numberOfDoors_tag = ticket_bs.find('li',class_='CardInfoRow_bodytype').find('a')\n",
    "            numberOfDoors_pre = re.findall('\\d', numberOfDoors_tag.text)\n",
    "            features['numberOfDoors'] = int(numberOfDoors_pre[0])\n",
    "        except Exception: features['numberOfDoors'] = np.NaN\n",
    "\n",
    "        # productionDate\n",
    "        try: features['productionDate'] = ticket_bs.find('li',class_='CardInfoRow_year').find('a').text\n",
    "        except Exception: features['productionDate'] = np.NaN\n",
    "            \n",
    "        # sell_id\n",
    "        try:         \n",
    "            invers_ticket_url = ticket_url[::-1]\n",
    "            id_start, id_end = invers_ticket_url.find('/',1) , invers_ticket_url.find('-')+1\n",
    "            features['sell_id'] = ticket_url[-id_start:-id_end]\n",
    "        except Exception: features['sell_id'] = np.NaN\n",
    "            \n",
    "        # vehicleTransmission\n",
    "        try:\n",
    "            features['vehicleTransmission'] = (ticket_bs.find('li',class_='CardInfoRow_transmission').\n",
    "                                               find_all('span')[1].text)\n",
    "        except Exception: features['vehicleTransmission'] = np.NaN            \n",
    "            \n",
    "        # vendor\n",
    "        european = ['SKODA', 'AUDI',  'VOLVO', 'BMW', 'MERCEDES', 'VOLKSWAGEN']\n",
    "        japanese = ['HONDA','NISSAN','TOYOTA','INFINITI',  'LEXUS', 'MITSUBISHI']\n",
    "        if features['brand'] in european :  features['vendor'] = 'EUROPEAN'\n",
    "        elif features['brand'] in japanese :  features['vendor'] = 'JAPANESE'\n",
    "        else: features['vendor'] = 'NAN'\n",
    "            \n",
    "        # Владельцы\n",
    "        try: features['Владельцы'] = ticket_bs.find('li',class_='CardInfoRow_ownersCount').find_all('span')[1].text\n",
    "        except Exception: features['Владельцы'] = np.NaN            \n",
    "            \n",
    "        # ПТС\n",
    "        try: features['ПТС'] = ticket_bs.find('li',class_='CardInfoRow_pts').find_all('span')[1].text\n",
    "        except Exception: features['ПТС'] = np.NaN               \n",
    "            \n",
    "        # Привод\n",
    "        try: features['Привод'] = ticket_bs.find('li',class_='CardInfoRow_drive').find_all('span')[1].text\n",
    "        except Exception: features['Привод'] = np.NaN            \n",
    "            \n",
    "        # Руль\n",
    "        try: features['Руль'] = ticket_bs.find('li',class_='CardInfoRow_wheel').find_all('span')[1].text \n",
    "        except Exception: features['Руль'] = np.NaN         \n",
    "            \n",
    "        # Цена предложения\n",
    "        try:\n",
    "            offerprice = ticket_bs.find('span',class_='OfferPriceCaption__price').text\n",
    "            features['offerprice'] = re.sub(\"\\D\", \"\", offerprice)\n",
    "        except Exception: features['offerprice'] = np.NaN\n",
    "\n",
    "        # modelDate              \n",
    "        try:\n",
    "            modelDate_tag = ticket_bs.find_all('a',class_='CardBreadcrumbs__itemText')\n",
    "            features['modelDate'] = (modelDate_tag[2].text.strip() + ' ' +\n",
    "                                     modelDate_tag[3].text.strip() + ' ' +\n",
    "                                     modelDate_tag[4].text.strip())  \n",
    "        except Exception: features['modelDate'] = np.NaN   \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка параметров, определение констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "service=Service('C:/Users/GANSOR-PC/chromium/chromedriver.exe') # C:\\Users\\GANSOR-PC\n",
    "executable_path = 'C:/Users/GANSOR-PC/chromium/chromedriver.exe'\n",
    "marks_for_parsing = ['SKODA', 'AUDI', 'HONDA', 'VOLVO', 'BMW', 'NISSAN', 'INFINITI',\n",
    "       'MERCEDES', 'TOYOTA', 'LEXUS', 'VOLKSWAGEN', 'MITSUBISHI']\n",
    "\n",
    "data_columns = ['bodyType', 'brand', 'car_url', 'color', 'engineDisplacement',\n",
    "       'enginePower', 'equipment_dict', 'fuel_type', 'mileage', 'modelDate',\n",
    "       'model_name', 'numberOfDoors', 'productionDate', 'sell_id', 'vehicleTransmission',\n",
    "       'vendor', 'Владельцы', 'ПТС', 'Привод', 'Руль', 'offerprice'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг\n",
    "## Парсинг вспомогательных данных\n",
    "### Создаем и наполняем ***`marks_models `*** , получаем ***`marks_models_for_parsing`*** и \n",
    "***marks_models*** - словарь в которм   \n",
    "ключ:  обозначения марки на сайте auto.ru  \n",
    "значения: списки всех моделей для каждой марки.\n",
    "\n",
    "***marks_models_for_parsing*** - содержит только марки, присутсвующие в валидационном наборе данных **test**\n",
    "\n",
    "затем сохраняем / читаем сохраненный ***marks_models_for_parsing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marks_models = get_marks_models()\n",
    "# marks_models_for_parsing = dict([(k, marks_models.get(k)) for k in marks_for_parsing])\n",
    "\n",
    "# with open('./Project_7_data/marks_models_for_parsing.json', 'w') as f: json.dump(marks_models_for_parsing, f)\n",
    "with open('./Project_7_data/marks_models_for_parsing.json') as f: marks_models_for_parsing = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем и заполняем `model_generation_year`\n",
    "***model_generation_year*** - **pd.DataFrame**  в котором:  \n",
    "        *full_name* - полное название марки и модели с указанием поколения;   \n",
    "        *bodytype* - тип кузова поколения модели;  \n",
    "        *generation_year* - год начала выпуска поколения  \n",
    "\n",
    "Этот DataFrame нужен для преобразования полного названия модели в год начала выпуска модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model_generation_year_all =  get_model_generation_year(marks_models_for_parsing)\n",
    "\n",
    "# model_generation_year_all.to_csv('./Project_5_data/model_generation_year.csv',index=False)\n",
    "model_generation_year = pd.read_csv('./Project_7_data/model_generation_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг набора данных для обучения\n",
    "## Получение данных по маркам, присутсвующим в валидационном наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  marks_models_for_parsing_TMP = {k: marks_models_for_parsing[k] for k in ['SKODA'] }\n",
    "# https://auto.ru/moskva/cars/skoda/fabia/used/?output_type=table\n",
    "# https://auto.ru/moskva/cars/skoda/fabia/used/?output_type=table&page=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticket_url = 'https://auto.ru/cars/used/sale/skoda/fabia/1114813721-910c47b4/'\n",
    "# get_features_from_ticket(ticket_url,service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MITSUBISHI': ['SPACE_WAGON']}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: marks_models_for_parsing[k][41:] for k in ['MITSUBISHI'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MITSUBISHI\n",
      "| 23221|\n",
      "Wall time: 57.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for mark in {k: marks_models_for_parsing[k][41:] for k in ['MITSUBISHI'] }: # 'VOLKSWAGEN' 'MITSUBISHI'\n",
    "    print(mark)\n",
    "    for model in marks_models_for_parsing[mark][41:]:      \n",
    "        model_url = 'https://auto.ru/moskva/cars/' + mark + '/' + model + '/used/' + '?output_type=table'\n",
    "    # просмотр последовательно всех страниц текущей модели-model текущей марки-mark\n",
    "        for pages_num in range(1,10): \n",
    "            if pages_num==1: page_url = model_url\n",
    "            else:            page_url = model_url + '&page=' +  str(pages_num)  \n",
    "            # получем html страницы\n",
    "            driver = webdriver.Chrome(executable_path)\n",
    "            driver.maximize_window()\n",
    "            driver.get(page_url)\n",
    "            page_html = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "            # создаем обьект bs4.BeautifulSoup из html страницы\n",
    "            page_bs = BeautifulSoup(page_html, 'html.parser') \n",
    "            # список html-ек карточек на странице                                               \n",
    "            tickets_on_page = page_bs.find_all('a', class_='ListingItemTitle__link') \n",
    "            # выход по исчерпанию страниц текущей модели текущей марки\n",
    "            if not tickets_on_page: \n",
    "                driver.quit()\n",
    "                break            \n",
    "            # обработка карточек на странице\n",
    "            for ticket in tickets_on_page:\n",
    "                # получаем url карточки текущего обьявления\n",
    "                ticket_url = ticket.get('href')\n",
    "                # извлекаем признаки и заполняем строку train-а\n",
    "                train.loc[len(train)] =get_features_from_ticket(ticket_url,driver)\n",
    "                time.sleep(0.5) \n",
    "            time.sleep(0.5) \n",
    "            driver.quit()\n",
    "        print ('|',len(train),end='') # <==============================             \n",
    "    print ('|') # <==============================       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23221 entries, 0 to 23220\n",
      "Data columns (total 21 columns):\n",
      "bodyType               22786 non-null object\n",
      "brand                  22786 non-null object\n",
      "car_url                23221 non-null object\n",
      "color                  22786 non-null object\n",
      "engineDisplacement     22686 non-null object\n",
      "enginePower            22686 non-null object\n",
      "equipment_dict         18354 non-null object\n",
      "fuel_type              22686 non-null object\n",
      "mileage                22786 non-null object\n",
      "modelDate              22786 non-null object\n",
      "model_name             22786 non-null object\n",
      "numberOfDoors          12067 non-null float64\n",
      "productionDate         22786 non-null object\n",
      "sell_id                23221 non-null object\n",
      "vehicleTransmission    22786 non-null object\n",
      "vendor                 23221 non-null object\n",
      "Владельцы              22786 non-null object\n",
      "ПТС                    22786 non-null object\n",
      "Привод                 22786 non-null object\n",
      "Руль                   22786 non-null object\n",
      "offerprice             22783 non-null object\n",
      "dtypes: float64(1), object(20)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('./Project_7_data/train.csv',index=False)\n",
    "# train = pd.read_csv('./Project_7_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('./Project_7_data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========== TEST ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FABIA',\n",
       " 'FABIA_RS',\n",
       " 'FELICIA',\n",
       " 'FORMAN',\n",
       " 'KAROQ',\n",
       " 'KODIAQ',\n",
       " 'OCTAVIA',\n",
       " 'OCTAVIA_RS',\n",
       " 'RAPID',\n",
       " 'ROOMSTER',\n",
       " 'SUPERB',\n",
       " 'YETI']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marks_models_for_parsing['SKODA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://auto.ru/moskva/cars/SKODA/FABIA/used/'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mark = 'SKODA'\n",
    "model = 'FABIA'\n",
    "\n",
    "model_url = 'https://auto.ru/moskva/cars/' + mark + '/' + model + '/used/'\n",
    "model_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SKODA': ['FABIA',\n",
       "  'FABIA_RS',\n",
       "  'FELICIA',\n",
       "  'FORMAN',\n",
       "  'KAROQ',\n",
       "  'KODIAQ',\n",
       "  'OCTAVIA',\n",
       "  'OCTAVIA_RS',\n",
       "  'RAPID',\n",
       "  'ROOMSTER',\n",
       "  'SUPERB',\n",
       "  'YETI']}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([(k, marks_models_for_parsing.get(k)) for k in ['SKODA']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= EXERCISE ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc': 1, 'def': [2, 3]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_json = {'abc': 1, \n",
    "           'def': [2,3]}\n",
    "to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc': 1, 'def': [2, 3]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('example.json', 'w') as f: json.dump(to_json, f)\n",
    "with open('example.json') as f: from_json = json.loads(f.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for mark in marks_models_for_parsing.index:\n",
    "    for model in marks_models_for_parsing[mark]:\n",
    "        model_url = 'https://auto.ru/moskva/cars/' + mark + '/' + model + '/used/'\n",
    "\n",
    "    # просмотр последовательно всех страниц текущей модели-model текущей марки-mark\n",
    "        for pages_num in range(1,100): \n",
    "        \n",
    "            if pages_num==1: params = {}\n",
    "            else:            params = {'page': pages_num}\n",
    "    \n",
    "            res = requests.get(model_url + '?output_type=table', params=params, headers=headers)\n",
    "            res.encoding = 'utf-8'\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "            # создаем обьект bs4.BeautifulSoup из html очередной страницы с обьявлениями по текущей модели текущей марки\n",
    "            soup = BeautifulSoup(res.text, 'html.parser')  \n",
    "    \n",
    "            # список html-ек карточек на странице                                               \n",
    "            tickets_on_page_list = soup.find_all('a', class_='ListingItemTitle-module__link') \n",
    "    \n",
    "            if not tickets_on_page_list: # выход по исчерпанию страниц текущей модели текущей марки\n",
    "                break\n",
    "        \n",
    "            # обработка карточек на странице\n",
    "            for ticket in tickets_on_page_list:\n",
    "                # получаем url карточки текущего обьявления\n",
    "                ticket_url = ticket.get('href')\n",
    "    \n",
    "                # извлекаем признаки и заполняем строку train-а\n",
    "                train.loc[len(train)] = get_features_from_ticket(ticket_url)\n",
    "                ''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
