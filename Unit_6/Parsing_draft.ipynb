{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описаение \n",
    "Данный блок производт парсинг обучающего набора данных для проекта [Проект 5. Выбираем авто выгодно](https://lms.skillfactory.ru/courses/course-v1:Skillfactory+DST-12+11MAR2020/courseware/c16441cf4f0a4f8486955f2be47f1cf0/67e09c15d9cd4b8eb691417898f4dfc2/1?activate_block_id=block-v1%3ASkillfactory%2BDST-12%2B11MAR2020%2Btype%40vertical%2Bblock%40f820a06d37d84dd98ab6acaa03392b5e)\n",
    "\n",
    "Данные сбираются на сайте https://auto.ru/, формируется pd.DataFrame со следуюшими колнками:  \n",
    " **bodytype** -   наименование типа кузова  \n",
    "**brand** -  наименование марки  \n",
    "**car_url** -  ссылка на обьявления о продаже  \n",
    "**color** -  ссылки на обьявления о продаже  \n",
    "**engineDisplacement** -  обьем двигателя  \n",
    "**enginePower** -  мощность двигателя  \n",
    "**equipment_dict** -  словарь с перечислением оснащения автомобиля.  \n",
    "**fuel_type** -  тип топлива  \n",
    "**mileage** -  пробег авто  \n",
    "**modelDate** -  год начала выпуска модели  \n",
    "**model_name** -  наименование модели  \n",
    "**numberOfDoors** -  количество дверей  \n",
    "**productionDate** -  Год производства автомобиля  \n",
    "**sell_id** -  содержит id обьявления   \n",
    "**vehicleTransmission** -  содержит id обьявления  \n",
    "**vendor** -  обобщающий признак: принадлежность марки к европейским либо японским маркам  \n",
    "**Владельцы** -  количество владельцев авто  \n",
    "**ПТС** -  Колонка содержит ('Оригинал', 'Дубликат') категорию ПТС  \n",
    "**Привод** -   категория привода  \n",
    "**Руль** -   категрию право- или левосторонности управления  \n",
    "**offerprice'** - цена продпажи (целевая перенная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек, установка параметров, определение функций\n",
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marks_models():\n",
    "    '''\n",
    "    возврашщает pd.Series в котором \n",
    "    индекс - название марки автомобиоя, \n",
    "    значения - списки названий моделей для каждой маркию\n",
    "    \n",
    "    '''\n",
    "    marks_models = pd.Series() \n",
    "\n",
    "    for pages_num in range(1,20):\n",
    "        if pages_num==1: params = {'view_type': 'list'}\n",
    "        else:            params = {'page_num': pages_num,'view_type': 'list'}\n",
    "    \n",
    "        res = requests.get(url_for_marks_models, params=params, headers=headers)\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # создаем обьект bs4.BeautifulSoup\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        \n",
    "        # список html-ек марок на странице\n",
    "        marks_on_page_list = soup.find_all('dd', class_='catalog-all-text-list__desc') \n",
    "    \n",
    "        if not marks_on_page_list: \n",
    "            break\n",
    "        \n",
    "        for mark in marks_on_page_list:\n",
    "            models_of_mark = mark.find_all('a', class_='link_theme_auto') # список html-ек моделей марки\n",
    "        \n",
    "            link_for_mark_name = models_of_mark[0].get('href')  # линк первой модели, содержит обозначене марки на auto.ru\n",
    "            mark_start = link_for_mark_name.find('cars/') + 5   # первый символ обозначеня марки\n",
    "            mark_end = link_for_mark_name.find('/', mark_start) # последний символ обозначения марки\n",
    "            mark_name = link_for_mark_name[mark_start:mark_end].upper() # получение обозначения марки      \n",
    "        \n",
    "            models_list = []\n",
    "            for model in models_of_mark:\n",
    "                link_theme_auto = model.get('href')                 # линк модели, содержит обозначение модели на auto.ru\n",
    "                model_start = mark_end+1                            # первый символ обозначения модели\n",
    "                model_end = link_theme_auto.find('/', model_start)  # последний символ обозначения модели\n",
    "                model_name = link_theme_auto[model_start:model_end].upper() # получение обозначения модели\n",
    "                models_list.append(model_name)\n",
    "      \n",
    "            marks_models[mark_name] = models_list\n",
    "    return marks_models\n",
    "\n",
    "def get_generation_year(model_url):\n",
    "    '''\n",
    "    возврашщает pd.Series  в котором \n",
    "        индекс - полное название модели с указанием поколения, \n",
    "        значение - год начала выпуска поколения\n",
    "        \n",
    "    model_url - ссылка на страницу со списокм поколений модели\n",
    "    \n",
    "    '''    \n",
    "    # получем html \n",
    "    models_list_res = requests.get(model_url+'?output_type=models_list')\n",
    "    models_list_res.encoding = 'utf-8'\n",
    "    \n",
    "    # создаем обьект bs4.BeautifulSoup из html \n",
    "    models_list_bs = BeautifulSoup(models_list_res.text, 'html.parser') \n",
    "    \n",
    "    # получаем список полных названий модели с указание поколения и список годов начала выпуска поколения\n",
    "    full_name_tag = models_list_bs.find_all('a',class_ = 'ListingItemTitle-module__link')\n",
    "    generation_years_tag = models_list_bs.find_all('div',class_ = \"ListingItemTitle-module__subtitle\")\n",
    "    \n",
    "    data=[int(x.text[x.text.find('(')+1:x.text.find('(')+5])  for x in generation_years_tag]\n",
    "    index=[x.text for x in full_name_tag][:len(data)] # иногда бывает модель без поколения и года - обрезаем\n",
    "\n",
    "    return pd.Series(index=index,data=data)\n",
    "\n",
    "def get_model_generation_year(marks_models_for_parsing):\n",
    "    '''\n",
    "    возвращает pd.Series в котором\n",
    "        индекс: марки и модели данной марки автомобиля с указанием поколения модели\n",
    "        значение: год начала выпуска поколоения модели\n",
    "    \n",
    "    marks_models_for_parsing - pd.Series в котором\n",
    "        индекс: марка автомобиля\n",
    "        значение: список моделей данной маркеи\n",
    "    '''\n",
    "    model_generation_year = pd.Series()\n",
    "    \n",
    "    for mark in marks_models_for_parsing.index:\n",
    "        print(mark)\n",
    "        for model in marks_models_for_parsing[mark]:\n",
    "            model_url = 'https://auto.ru/moskva/cars/' + mark.lower() + '/' + model.lower() + '/used/'\n",
    "            tmp = get_generation_year(model_url)\n",
    "            model_generation_year = model_generation_year.append(tmp)\n",
    "            time.sleep(0.5)\n",
    "    return model_generation_year\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_features_from_ticket(ticket_url):\n",
    "    '''\n",
    "    возвращает pd.Series с признакамии полученными из карточки обьявления\n",
    "    \n",
    "    ticket_url: str, ссылка на страницу обьявления\n",
    "        \n",
    "    '''\n",
    "    features = pd.Series(index = data_columns)\n",
    "    \n",
    "    # получем html карточки текщего обьявления\n",
    "    ticket_res = requests.get(ticket_url)\n",
    "    ticket_res.encoding = 'utf-8'\n",
    "    \n",
    "    # создаем обьект bs4.BeautifulSoup из html карточки текщего обьявления\n",
    "    ticket_bs = BeautifulSoup(ticket_res.text, 'html.parser')  \n",
    "    # проверка корректности резкльтата BeautifulSoup\n",
    "    if ticket_bs:\n",
    "    \n",
    "    # получение признаков из карточки текущего обьявления\n",
    "    #\n",
    "        # bodyType      \n",
    "        try: features['bodyType'] = ticket_bs.find('li',class_='CardInfoRow_bodytype').find('a').text\n",
    "        except Exception: features['bodytype'] = np.NaN\n",
    "           \n",
    "        # brand        \n",
    "        try: features['brand'] = ticket_bs.find_all('a',class_='CardBreadcrumbs__itemText')[0].text.strip().upper()\n",
    "        except Exception: features['brand'] = np.NaN\n",
    "    \n",
    "        # car_url\n",
    "        features['car_url'] = ticket_url\n",
    "    \n",
    "        # color        \n",
    "        try: features['color'] = ticket_bs.find('li',class_='CardInfoRow_color').find('a').text\n",
    "        except Exception: features['color'] = np.NaN\n",
    "    \n",
    "        #engineDisplacement            \n",
    "        try: \n",
    "            engineDisplacement = ticket_bs.find('li',class_='CardInfoRow_engine').find('div').text.split(' / ')[0]\n",
    "            features['engineDisplacement'] =  re.sub(\"[^\\d.]\", \"\", engineDisplacement)\n",
    "        except Exception: features['engineDisplacement'] = np.NaN\n",
    "          \n",
    "        # enginePower\n",
    "        try: \n",
    "            enginePower = ticket_bs.find('li',class_='CardInfoRow_engine').find('div').text.split(' / ')[1]\n",
    "            features['enginePower'] = re.sub(\"\\D\", \"\", enginePower)\n",
    "        except Exception: features['enginePower'] = np.NaN\n",
    "    \n",
    "        # equipment_dict\n",
    "        equipment_dict = dict()\n",
    "        try:\n",
    "            complectation = ticket_bs.find('section',class_='CardComplectation')\n",
    "            complectation_items = complectation.find_all('div',class_=\"ComplectationGroups__group\")\n",
    "            for item in complectation_items:\n",
    "                item_name = item.find('span',class_=\"ComplectationGroups__itemName\").text\n",
    "                item_content_tag = item.find_all('li',class_=\"ComplectationGroups__itemContentEl\")\n",
    "                item_content = [x.text for x in item_content_tag]\n",
    "                equipment_dict[item_name] = item_content \n",
    "            features['equipment_dict'] = equipment_dict\n",
    "        except Exception: features['equipment_dict'] = np.NaN\n",
    "    \n",
    "        # fuelType\n",
    "        try: features['fuelType'] = ticket_bs.find('li',class_='CardInfoRow_engine').find('div').text.split(' / ')[2]\n",
    "        except Exception: features['fuel_type'] = np.NaN\n",
    "        \n",
    "        # mileage\n",
    "        try:\n",
    "            mileage = ticket_bs.find('li',class_='CardInfoRow_kmAge').find_all('span')[1].text\n",
    "            features['mileage'] = re.sub(\"\\D\", \"\", mileage)\n",
    "        except Exception: features['mileage'] = np.NaN\n",
    "    \n",
    "        # modelDate\n",
    "        ## заполняется названием марки, модели и поколением модели - следует далее заменить на год модели/поколения\n",
    "        try:\n",
    "            modelDate_tag = ticket_bs.find_all('a',class_='CardBreadcrumbs__itemText')\n",
    "            features['modelDate'] = (modelDate_tag[0].text.strip() + ' ' +\n",
    "                                     modelDate_tag[1].text.strip() + ' ' +\n",
    "                                     modelDate_tag[2].text.strip())  \n",
    "        except Exception: features['modelDate'] = np.NaN\n",
    "    \n",
    "        # model_name\n",
    "        try: features['model_name'] = ticket_bs.find_all('a',class_='CardBreadcrumbs__itemText')[1].text.strip()\n",
    "        except Exception: features['model_name'] = np.NaN\n",
    "     \n",
    "        # numberOfDoors\n",
    "        try:\n",
    "            numberOfDoors_tag = ticket_bs.find('li',class_='CardInfoRow_bodytype').find('a')\n",
    "            numberOfDoors_pre = re.findall('\\d', numberOfDoors_tag.text)\n",
    "            features['numberOfDoors'] = int(numberOfDoors_pre[0])\n",
    "        except Exception: features['numberOfDoors'] = np.NaN\n",
    "    \n",
    "        # productionDate\n",
    "        try: features['productionDate'] = ticket_bs.find('li',class_='CardInfoRow_year').find('a').text\n",
    "        except Exception: features['productionDate'] = np.NaN\n",
    "    \n",
    "        # sell_id\n",
    "        try:         \n",
    "            invers_ticket_url = ticket_url[::-1]\n",
    "            id_start, id_end = invers_ticket_url.find('/',1) , invers_ticket_url.find('-')+1\n",
    "            features['sell_id'] = ticket_url[-id_start:-id_end]\n",
    "        except Exception: features['sell_id'] = np.NaN\n",
    "    \n",
    "        # vehicleTransmission\n",
    "        try:\n",
    "            features['vehicleTransmission'] = (ticket_bs.find('li',class_='CardInfoRow_transmission').\n",
    "                                               find_all('span')[1].text)\n",
    "        except Exception: features['vehicleTransmission'] = np.NaN\n",
    "            \n",
    "        # vendor\n",
    "        european = ['SKODA', 'AUDI',  'VOLVO', 'BMW', 'MERCEDES', 'VOLKSWAGEN']\n",
    "        japanese = ['HONDA','NISSAN','TOYOTA','INFINITI',  'LEXUS', 'MITSUBISHI']\n",
    "        if features['brand'] in european :  features['vendor'] = 'EUROPEAN'\n",
    "        elif features['brand'] in japanese :  features['vendor'] = 'JAPANESE'\n",
    "        else: features['vendor'] = 'NAN'\n",
    "        \n",
    "        # Владельцы\n",
    "        try: features['Владельцы'] = ticket_bs.find('li',class_='CardInfoRow_ownersCount').find_all('span')[1].text\n",
    "        except Exception: features['Владельцы'] = np.NaN\n",
    "\n",
    "        # ПТС\n",
    "        try: features['ПТС'] = ticket_bs.find('li',class_='CardInfoRow_pts').find_all('span')[1].text\n",
    "        except Exception: features['ПТС'] = np.NaN\n",
    "        \n",
    "        # Привод\n",
    "        try: features['Привод'] = ticket_bs.find('li',class_='CardInfoRow_drive').find_all('span')[1].text\n",
    "        except Exception: features['Привод'] = np.NaN\n",
    "    \n",
    "        # Руль\n",
    "        try: features['Руль'] = ticket_bs.find('li',class_='CardInfoRow_wheel').find_all('span')[1].text \n",
    "        except Exception: features['Руль'] = np.NaN\n",
    "    \n",
    "        # Привод\n",
    "        try: features['Привод'] = ticket_bs.find('li',class_='CardInfoRow_drive').find_all('span')[1].text\n",
    "        except Exception: features['Привод'] = np.NaN\n",
    "\n",
    "        # Цена предложения\n",
    "        try:\n",
    "            offerprice = ticket_bs.find('span',class_='OfferPriceCaption__price').text\n",
    "            features['offerprice'] = re.sub(\"\\D\", \"\", offerprice)\n",
    "        except Exception: features['offerprice'] = np.NaN\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка параметров, определение констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_for_marks_models = 'https://auto.ru/catalog/cars/all/'\n",
    "\n",
    "data_columns = ['bodytype', 'brand', 'car_url', 'color', 'engineDisplacement',\n",
    "       'enginePower', 'equipment_dict', 'fuel_type', 'mileage', 'modelDate',\n",
    "       'model_name', 'numberOfDoors', 'productionDate', 'sell_id', 'vehicleTransmission',\n",
    "       'vendor', 'Владельцы', 'ПТС', 'Привод', 'Руль', 'offerprice']\n",
    "\n",
    "headers = {\n",
    "'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "'Accept-Encoding': 'gzip, deflate, br',\n",
    "'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "'Cache-Control': 'max-age=0',\n",
    "'Connection': 'keep-alive',\n",
    "'Cookie': 'suid=bf4a59ff8840503c2077bf716a7bbeef.295e234731ada0bc538a541689345348; tmr_lvid=d2115cf4bc0ee3e6bc3ad89db8fdac9d; tmr_lvidTS=1596630011564; _ym_uid=1596630015684249973; _ga=GA1.2.1113974574.1596630016; autoruuid=g5f949c622cu74bpb1qps6a12l6p5u7t.07262c19ce2a1f07cac53c4ce06ef69b; gids=213; gradius=200; mindboxDeviceUUID=a231f610-2f9e-4911-9cb8-9112afa13ab1; directCrm-session=%7B%22deviceGuid%22%3A%22a231f610-2f9e-4911-9cb8-9112afa13ab1%22%7D; tmr_reqNum=15; yuidlt=1; yandexuid=1471619051363959249; my=YysBgNU2AQEA; crookie=uCcId3jGlYfIvH+2UzzszOwTawIMGSzWumxanVb1Ras+Mu6qi+8yzj8EL+czftU9orxvkiKDKe/wgGsJDdJMlqyn6WU=; cmtchd=MTYxMjgyMjU3MTQ4MA==; _csrf_token=04c10009d8f17a08b4d507f70f2a287c28bf3c17f7b3ef42; gdpr=0; _ym_isad=2; index-selector-tab=marks; listing_view_session={}; listing_view=%7B%22output_type%22%3Anull%2C%22version%22%3A1%7D; autoru-visits-count=2; salon_phone_utms=utm_medium%3Dcpm%26utm_source%3Dauto-ru%26utm_campaign%3Dauto-ru_rus-r225_proauto-rk2021%26utm_content%3D113pa-100PRx40-otchety-o-proshlom-mashiny-ot-99-rublei_proauto-promo-page_rus-r225; hide-proauto-pimple=1; from=direct; autoru_sid=a%3Ag5f949c622cu74bpb1qps6a12l6p5u7t.07262c19ce2a1f07cac53c4ce06ef69b%7C1613427368824.604800.BYczsuAhOkO7E_tI9WN3ZQ.vyyvypdKR_sNAGlonPspJxUInUX2GwuD7owqbI5Sw58; X-Vertis-DC=vla; _ym_d=1613250934; from_lifetime=1613250934966; cycada=FXXHRKJxPTj6XyBIJ1I0Or150N9cGJGcL1yh7v8BaXc=',\n",
    "'Host': 'auto.ru',\n",
    "'sec-ch-ua': '\"Chromium\";v=\"88\", \"Google Chrome\";v=\"88\", \";Not A Brand\";v=\"99\"',\n",
    "'sec-ch-ua-mobil': '?0',\n",
    "'Sec-Fetch-Dest': 'document',\n",
    "'Sec-Fetch-Mode': 'navigate',\n",
    "'Sec-Fetch-Site': 'same-origin',\n",
    "'Sec-Fetch-User': '?1',\n",
    "'Upgrade-Insecure-Requests': '1',\n",
    "'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'\n",
    "};\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг\n",
    "## Парсинг вспомогательных данных\n",
    "### Создаем и наполняем ***`marks_models `*** , получаем ***`marks_models_for_parsing`*** и ***`extra_marks_models`***\n",
    "***marks_models*** - pd.Series в которм   \n",
    "индекс:  обозначения марки на сайте auto.ru  \n",
    "значения: списки всех моделей для каждой марки.\n",
    "\n",
    "***marks_models_for_parsing*** - содержит только марки, присутсвующие в валидационном наборе данных **test**\n",
    "\n",
    "***extra_marks_models*** - содержит все марки, за исключением присутсвующиx в валидационном наборе данных **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GANSOR-PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "marks_models = get_marks_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks_for_parsing = ['SKODA', 'AUDI', 'HONDA', 'VOLVO', 'BMW', 'NISSAN', 'INFINITI',\n",
    "       'MERCEDES', 'TOYOTA', 'LEXUS', 'VOLKSWAGEN', 'MITSUBISHI']\n",
    "marks_models_for_parsing = marks_models.loc[marks_for_parsing]\n",
    "\n",
    "extra_marks = marks_models.index.drop(marks_for_parsing)\n",
    "extra_marks_models = marks_models.loc[extra_marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем и заполняем `model_generation_year`\n",
    "***model_generation_year*** - pd.Series в котором:  \n",
    "индекс: марки и модели данной марки автомобиля с указанием поколения модели  \n",
    "значение: год начала выпуска поколоения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model_generation_year_all =  get_model_generation_year(marks_models)\n",
    "# model_generation_year_all.to_csv('./Project_5_data/model_generation_year_all.csv',index=False)\n",
    "model_generation_year_all = pd.read_csv('./Project_5_data/model_generation_year_all.csv')\n",
    "\n",
    "# model_generation_year =  get_model_generation_year(marks_models_for_parsing)\n",
    "# model_generation_year.to_csv('./Project_5_data/model_generation_year',index=False)\n",
    "# model_generation_year = pd.read_csv('./Project_5_data/model_generation_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг набора данных для обучения\n",
    "## Получение данных по маркам, присутсвующим в валидационном наборе данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(columns=data_columns)\n",
    "'''\n",
    "for mark in marks_models_for_parsing.index:\n",
    "    for model in marks_models_for_parsing[mark]:\n",
    "        model_url = 'https://auto.ru/moskva/cars/' + mark + '/' + model + '/used/'\n",
    "\n",
    "    # просмотр последовательно всех страниц текущей модели-model текущей марки-mark\n",
    "        for pages_num in range(1,100): \n",
    "        \n",
    "            if pages_num==1: params = {}\n",
    "            else:            params = {'page': pages_num}\n",
    "    \n",
    "            res = requests.get(model_url + '?output_type=table', params=params, headers=headers)\n",
    "            res.encoding = 'utf-8'\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "            # создаем обьект bs4.BeautifulSoup из html очередной страницы с обьявлениями по текущей модели текущей марки\n",
    "            soup = BeautifulSoup(res.text, 'html.parser')  \n",
    "    \n",
    "            # список html-ек карточек на странице                                               \n",
    "            tickets_on_page_list = soup.find_all('a', class_='ListingItemTitle-module__link') \n",
    "    \n",
    "            if not tickets_on_page_list: # выход по исчерпанию страниц текущей модели текущей марки\n",
    "                break\n",
    "        \n",
    "            # обработка карточек на странице\n",
    "            for ticket in tickets_on_page_list:\n",
    "                # получаем url карточки текущего обьявления\n",
    "                ticket_url = ticket.get('href')\n",
    "    \n",
    "                # извлекаем признаки и заполняем строку train-а\n",
    "                train.loc[len(train)] = get_features_from_ticket(ticket_url)\n",
    "                ''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('./Project_5_data/train',index=False)\n",
    "train = pd.read_csv('./Project_5_data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение данных по всем остальным ( т.е. за исключением присутсвующиx в валидационном наборе ) маркам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_train = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "'''for mark in extra_marks_models.loc['KIA':].index:\n",
    "    print(mark, len(extra_train), end='\\n\\t')\n",
    "    for model in extra_marks_models.loc['KIA':][mark]:\n",
    "        model_url = 'https://auto.ru/moskva/cars/' + mark + '/' + model + '/used/'\n",
    "\n",
    "    # просмотр последовательно всех страниц текущей модели-model текущей марки-mark\n",
    "        for pages_num in range(1,100): \n",
    "        \n",
    "            if pages_num==1: params = {}\n",
    "            else:            params = {'page': pages_num}\n",
    "    \n",
    "            res = requests.get(model_url + '?output_type=table', params=params, headers=headers)\n",
    "            res.encoding = 'utf-8'\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "            # создаем обьект bs4.BeautifulSoup из html очередной страницы с обьявлениями по текущей модели текущей марки\n",
    "            soup = BeautifulSoup(res.text, 'html.parser')  \n",
    "    \n",
    "            # список html-ек карточек на странице                                               \n",
    "            tickets_on_page_list = soup.find_all('a', class_='ListingItemTitle-module__link') \n",
    "    \n",
    "            if not tickets_on_page_list: # выход по исчерпанию страниц текущей модели текущей марки\n",
    "                break\n",
    "        \n",
    "            # обработка карточек на странице\n",
    "            for ticket in tickets_on_page_list:\n",
    "                # получаем url карточки текущего обьявления\n",
    "                ticket_url = ticket.get('href')\n",
    "    \n",
    "                # извлекаем признаки и заполняем строку train-а\n",
    "                extra_train.loc[len(extra_train)] = get_features_from_ticket(ticket_url)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_train.to_csv('./Project_5_data/extra_train.csv',index=False)\n",
    "extra_train = pd.read_csv('./Project_5_data/extra_train.csv')\n",
    "\n",
    "# all_marks = train.append(extra_train, ignore_index=True)\n",
    "\n",
    "# all_marks.to_csv('./Project_5_data/all_marks.csv',index=False)\n",
    "all_marks = pd.read_csv('./Project_5_data/all_marks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('./Project_5_data/model_generation_year_all.csv',header=None)\n",
    "\n",
    "model_generation_year_all = pd.Series(data = list(tmp[1]),index=tmp[0])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "Skoda Fabia II                        2008\n",
       "Skoda Fabia I                         2001\n",
       "Skoda Fabia II Рестайлинг             2010\n",
       "Skoda Fabia II                        2007\n",
       "Skoda Fabia I Рестайлинг              2004\n",
       "                                      ... \n",
       "Mitsubishi Space Star I Рестайлинг    2002\n",
       "Mitsubishi Space Star I               1998\n",
       "Mitsubishi Space Wagon III            1999\n",
       "Mitsubishi Space Wagon I              1986\n",
       "Mitsubishi Space Wagon II             1991\n",
       "Length: 1810, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_generation_year_all[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-532c92901357>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_marks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_generation_year_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   3823\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3824\u001b[0m         \"\"\"\n\u001b[1;32m-> 3825\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3826\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m   1275\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1278\u001b[0m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   2983\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2984\u001b[0m             raise InvalidIndexError(\n\u001b[1;32m-> 2985\u001b[1;33m                 \u001b[1;34m\"Reindexing only valid with uniquely\"\u001b[0m \u001b[1;34m\" valued Index objects\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2986\u001b[0m             )\n\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "all_marks.modelDate.map(model_generation_year_all[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "Skoda 1200 I                          1960\n",
       "Skoda Fabia II                        2008\n",
       "Skoda Fabia I                         2001\n",
       "Skoda Fabia II Рестайлинг             2010\n",
       "Skoda Fabia II                        2007\n",
       "                                      ... \n",
       "Mitsubishi Space Star I Рестайлинг    2002\n",
       "Mitsubishi Space Star I               1998\n",
       "Mitsubishi Space Wagon III            1999\n",
       "Mitsubishi Space Wagon I              1986\n",
       "Mitsubishi Space Wagon II             1991\n",
       "Length: 1811, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_generation_year_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
