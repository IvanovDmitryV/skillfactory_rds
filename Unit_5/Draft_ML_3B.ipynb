{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем реализовать классификацию и вычислить разобранные метрики.\n",
    "Для начала подгружаем библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # функция, чтобы разбить данные на трейн и тест\n",
    "from sklearn.linear_model import LogisticRegression # наша модель для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся встроенным датасетом, который содержит информацию об опухолях груди:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer # подгружаем датасет\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь зададим зависимую и независимые переменные:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = breast_cancer.target ## Наша целевая переменная, 0 — если рака нет, 1 — если есть \n",
    "X = breast_cancer.data # X - признаки, по которым мы будем предсказывать рак "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем выборку на обучающую и тестовую и обучаем нашу модель:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GANSOR-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.3)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готово! Теперь осталось только вычислить необходимые метрики:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239766081871345\n",
      "0.8962264150943396\n",
      "0.979381443298969\n",
      "0.9359605911330049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "Y_predicted = model.predict(X_val)\n",
    "print(accuracy_score(Y_val,Y_predicted))\n",
    "print(precision_score(Y_val,Y_predicted))\n",
    "print(recall_score(Y_val,Y_predicted))\n",
    "print(f1_score(Y_val,Y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.2.1\n",
    "Вы создали классификатор, который разделяет экономические и политические новости на два разных Telegram-канала, и хотите проверить его качество. За день вышло 15 политических новостей и 20 экономических.  \n",
    "Ваш алгоритм из 15 политических новостей отметил 9 как экономические, а из 20 экономических — 6 как политические.  \n",
    "Найдите метрику $Accuracy$ .  \n",
    "Ответ округлите до сотых. Пример ввода: 5.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (6+14)/(15+20)\n",
    "round(accuracy,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B2.2\n",
    "Загрузите встроенный в библиотеку `sklearn` датасет про ирисы с помощью функции `load_iris`. Обучите модель логистической регрессии (random_state=50, размер тестовой выборки 0.3) и укажите полученное значение метрики $Accuracy$.  \n",
    "Ответ округлите до сотых. Пример ввода: 5.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=50)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(round(accuracy_score(y_pred, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B.3. Классификация. Практика\n",
    "У вас есть датасет с параметрами мобильных телефонов. Переменная `price_range` отвечает за то, к какой категории относится телефон: 1 — дорогие, 0 — дешевые.  \n",
    "Ваша задача состоит в том, чтобы наиболее точно научиться классифицировать телефоны по этим двум категориям на основании других параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Unit_5_data/train_mobile.csv', sep =';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1\n",
    "Для начала нам надо отобрать признаки, с помощью которых мы будем предсказывать категорию телефона.\n",
    "\n",
    "### Задание 3B.3.1 Отбор признаков\n",
    "Выберите пять признаков, у которых наибольшая взаимосвязь с целевой переменной (с помощью корреляции). Отметьте отобранные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ram\n",
      "battery_power\n",
      "px_width\n",
      "px_height\n",
      "touch_screen\n"
     ]
    }
   ],
   "source": [
    "for feat in abs(data.corr().price_range).sort_values(ascending=False).index.drop('price_range')[:5]: print (feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ШАГ 2\n",
    "Теперь необходимо обучить алгоритм.  Для начала разбейте выборку на тестовую и обучающую, размер тестовой задайте `0.2`. Параметр `random_state=31`. В качестве модели возьмите логистическую регрессию. В качестве предикторов возьмите пять ранее отобранных признаков.\n",
    "\n",
    "Рассчитайте метрику, которая покажет, какая доля телефонов, обозначенных классификатором как дорогие, действительно относится к этой категории. \n",
    "\n",
    "### Задание 3B.3.2 Выбор метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "data = pd.read_csv('./Unit_5_data/train_mobile.csv', sep =';')\n",
    "\n",
    "columns_to_fit = abs(data.corr().price_range).sort_values(ascending=False).index[1:6]\n",
    "\n",
    "y = data.price_range\n",
    "X = data[columns_to_fit]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=31)\n",
    "\n",
    "model = LogisticRegression(random_state=31)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test,y_pred)\n",
    "round(precision,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B.3.3 Значение метрики\n",
    "Введите полученное значение, округлите до четырех знаков после запятой. Целую и десятичную часть разделите точкой. Пример ввода: 5.5555."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(precision,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.5.3\n",
    "Посчитайте $logloss$ для данных в таблице (без нормализации). Укажите число с точностью до сотых:  \n",
    "\n",
    " | | | | | |\n",
    " |-|-|-|-|-|\n",
    " |Предсказанное значение |0.2|0.8|1|0.6|\n",
    " |Истинное значение      |0|0|1|1 |\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.34, 2.34)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series([0,0,1,1])\n",
    "y_pred = pd.Series([0.2,0.8,1,0.6])\n",
    "n = 4\n",
    "\n",
    "logloss = -(y*np.log(y_pred) + (1-y)*np.log(1-y_pred)).sum()\n",
    "\n",
    "round(log_loss(y,y_pred)*n,2), round(logloss,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.223144\n",
       "1    1.609438\n",
       "2         NaN\n",
       "3    0.510826\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(y*np.log(y_pred) + (1-y)*np.log(1-y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.5.4\n",
    "Посчитайте $logloss$ для данных в таблице. Необходимо найти среднюю ошибку. Классификация на три класса:\n",
    "\n",
    "| | | | |\n",
    "|-|-|-|-|\n",
    "|Предсказанное значение|0.2|0|0.1|\n",
    "| |0.3|0 |0  |\n",
    "| |0.5|1 |0.9|\n",
    "|Истинное значение     |0|0|1|\n",
    "|  |0|0|0|\n",
    "|  |1|1|0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.998577424517998, 0.9985774245179969)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([0.2,0.3,0.5,0,0,1,0.1,0,0.9]).reshape((3,3))\n",
    "y = np.array([0,0,1,0,0,1,1,0,0]).reshape((3,3))\n",
    "n = 3\n",
    "\n",
    "logloss = -np.nan_to_num(y*np.log(y_pred)).sum()/n\n",
    "\n",
    "log_loss(y,y_pred), logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B.6. Логистическая регрессия. Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае с логистической регрессией мы можем использовать только градиентный спуск, так как нет явного матричного способа найти оптимальные коэффициенты. В качестве функции потерь будем использовать бинарную кросс-энтропию, Log Loss. Она записывается так:\n",
    "\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i)))$$\n",
    "Градиент ошибки:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}$$\n",
    "Будем использовать другой датасет с задачей классификации, где нужно определить зарплату меньше и больше определённого значения. Убираем в данных лишние признаки, конвертируем целевой столбец в бинарные значения и нормализуем данные.\n",
    "\n",
    "Реализуем функцию `sigmoid` и функцию, вычисляющую градиент бинарной кросс-энтропии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПОДВАЛ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate data\n",
    "X, y = make_blobs(n_samples=1000, random_state=42, cluster_std=5.0)\n",
    "X_train, y_train = X[:600], y[:600]\n",
    "X_valid, y_valid = X[600:800], y[600:800]\n",
    "X_train_valid, y_train_valid = X[:800], y[:800]\n",
    "X_test, y_test = X[800:], y[800:]\n",
    "\n",
    "# Train uncalibrated random forest classifier on whole train and validation\n",
    "# data and evaluate on test data\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train_valid, y_train_valid)\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "score = log_loss(y_test, clf_probs)\n",
    "\n",
    "# Train random forest classifier, calibrate on validation data and evaluate\n",
    "# on test data\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf.fit(X_valid, y_valid)\n",
    "sig_clf_probs = sig_clf.predict_proba(X_test)\n",
    "sig_score = log_loss(y_test, sig_clf_probs)\n",
    "\n",
    "# Plot changes in predicted probabilities via arrows\n",
    "plt.figure()\n",
    "colors = [\"r\", \"g\", \"b\"]\n",
    "for i in range(clf_probs.shape[0]):\n",
    "    plt.arrow(clf_probs[i, 0], clf_probs[i, 1],\n",
    "              sig_clf_probs[i, 0] - clf_probs[i, 0],\n",
    "              sig_clf_probs[i, 1] - clf_probs[i, 1],\n",
    "              color=colors[y_test[i]], head_width=1e-2)\n",
    "\n",
    "# Plot perfect predictions\n",
    "plt.plot([1.0], [0.0], 'ro', ms=20, label=\"Class 1\")\n",
    "plt.plot([0.0], [1.0], 'go', ms=20, label=\"Class 2\")\n",
    "plt.plot([0.0], [0.0], 'bo', ms=20, label=\"Class 3\")\n",
    "\n",
    "# Plot boundaries of unit simplex\n",
    "plt.plot([0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], 'k', label=\"Simplex\")\n",
    "\n",
    "# Annotate points on the simplex\n",
    "plt.annotate(r'($\\frac{1}{3}$, $\\frac{1}{3}$, $\\frac{1}{3}$)',\n",
    "             xy=(1.0/3, 1.0/3), xytext=(1.0/3, .23), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.plot([1.0/3], [1.0/3], 'ko', ms=5)\n",
    "plt.annotate(r'($\\frac{1}{2}$, $0$, $\\frac{1}{2}$)',\n",
    "             xy=(.5, .0), xytext=(.5, .1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($0$, $\\frac{1}{2}$, $\\frac{1}{2}$)',\n",
    "             xy=(.0, .5), xytext=(.1, .5), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($\\frac{1}{2}$, $\\frac{1}{2}$, $0$)',\n",
    "             xy=(.5, .5), xytext=(.6, .6), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($0$, $0$, $1$)',\n",
    "             xy=(0, 0), xytext=(.1, .1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($1$, $0$, $0$)',\n",
    "             xy=(1, 0), xytext=(1, .1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($0$, $1$, $0$)',\n",
    "             xy=(0, 1), xytext=(.1, 1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "# Add grid\n",
    "plt.grid(False)\n",
    "for x in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    plt.plot([0, x], [x, 0], 'k', alpha=0.2)\n",
    "    plt.plot([0, 0 + (1-x)/2], [x, x + (1-x)/2], 'k', alpha=0.2)\n",
    "    plt.plot([x, x + (1-x)/2], [0, 0 + (1-x)/2], 'k', alpha=0.2)\n",
    "\n",
    "plt.title(\"Change of predicted probabilities after sigmoid calibration\")\n",
    "plt.xlabel(\"Probability class 1\")\n",
    "plt.ylabel(\"Probability class 2\")\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "print(\"Log-loss of\")\n",
    "print(\" * uncalibrated classifier trained on 800 datapoints: %.3f \"\n",
    "      % score)\n",
    "print(\" * classifier trained on 600 datapoints and calibrated on \"\n",
    "      \"200 datapoint: %.3f\" % sig_score)\n",
    "\n",
    "# Illustrate calibrator\n",
    "plt.figure()\n",
    "# generate grid over 2-simplex\n",
    "p1d = np.linspace(0, 1, 20)\n",
    "p0, p1 = np.meshgrid(p1d, p1d)\n",
    "p2 = 1 - p0 - p1\n",
    "p = np.c_[p0.ravel(), p1.ravel(), p2.ravel()]\n",
    "p = p[p[:, 2] >= 0]\n",
    "\n",
    "calibrated_classifier = sig_clf.calibrated_classifiers_[0]\n",
    "prediction = np.vstack([calibrator.predict(this_p)\n",
    "                        for calibrator, this_p in\n",
    "                        zip(calibrated_classifier.calibrators_, p.T)]).T\n",
    "prediction /= prediction.sum(axis=1)[:, None]\n",
    "\n",
    "# Plot modifications of calibrator\n",
    "for i in range(prediction.shape[0]):\n",
    "    plt.arrow(p[i, 0], p[i, 1],\n",
    "              prediction[i, 0] - p[i, 0], prediction[i, 1] - p[i, 1],\n",
    "              head_width=1e-2, color=colors[np.argmax(p[i])])\n",
    "# Plot boundaries of unit simplex\n",
    "plt.plot([0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], 'k', label=\"Simplex\")\n",
    "\n",
    "plt.grid(False)\n",
    "for x in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    plt.plot([0, x], [x, 0], 'k', alpha=0.2)\n",
    "    plt.plot([0, 0 + (1-x)/2], [x, x + (1-x)/2], 'k', alpha=0.2)\n",
    "    plt.plot([x, x + (1-x)/2], [0, 0 + (1-x)/2], 'k', alpha=0.2)\n",
    "\n",
    "plt.title(\"Illustration of sigmoid calibrator\")\n",
    "plt.xlabel(\"Probability class 1\")\n",
    "plt.ylabel(\"Probability class 2\")\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "\n",
    "plt.show()\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
