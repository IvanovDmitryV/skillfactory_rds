{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем реализовать классификацию и вычислить разобранные метрики.\n",
    "Для начала подгружаем библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # функция, чтобы разбить данные на трейн и тест\n",
    "from sklearn.linear_model import LogisticRegression # наша модель для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся встроенным датасетом, который содержит информацию об опухолях груди:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer # подгружаем датасет\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь зададим зависимую и независимые переменные:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = breast_cancer.target ## Наша целевая переменная, 0 — если рака нет, 1 — если есть \n",
    "X = breast_cancer.data # X - признаки, по которым мы будем предсказывать рак "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем выборку на обучающую и тестовую и обучаем нашу модель:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GANSOR-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.3)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готово! Теперь осталось только вычислить необходимые метрики:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9707602339181286\n",
      "0.9803921568627451\n",
      "0.970873786407767\n",
      "0.975609756097561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "Y_predicted = model.predict(X_val)\n",
    "print(accuracy_score(Y_val,Y_predicted))\n",
    "print(precision_score(Y_val,Y_predicted))\n",
    "print(recall_score(Y_val,Y_predicted))\n",
    "print(f1_score(Y_val,Y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.2.1\n",
    "Вы создали классификатор, который разделяет экономические и политические новости на два разных Telegram-канала, и хотите проверить его качество. За день вышло 15 политических новостей и 20 экономических.  \n",
    "Ваш алгоритм из 15 политических новостей отметил 9 как экономические, а из 20 экономических — 6 как политические.  \n",
    "Найдите метрику $Accuracy$ .  \n",
    "Ответ округлите до сотых. Пример ввода: 5.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (6+14)/(15+20)\n",
    "round(accuracy,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B2.2\n",
    "Загрузите встроенный в библиотеку `sklearn` датасет про ирисы с помощью функции `load_iris`. Обучите модель логистической регрессии (random_state=50, размер тестовой выборки 0.3) и укажите полученное значение метрики $Accuracy$.  \n",
    "Ответ округлите до сотых. Пример ввода: 5.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=50)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(round(accuracy_score(y_pred, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B.3. Классификация. Практика\n",
    "У вас есть датасет с параметрами мобильных телефонов. Переменная `price_range` отвечает за то, к какой категории относится телефон: 1 — дорогие, 0 — дешевые.  \n",
    "Ваша задача состоит в том, чтобы наиболее точно научиться классифицировать телефоны по этим двум категориям на основании других параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Unit_5_data/train_mobile.csv', sep =';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1\n",
    "Для начала нам надо отобрать признаки, с помощью которых мы будем предсказывать категорию телефона.\n",
    "\n",
    "### Задание 3B.3.1 Отбор признаков\n",
    "Выберите пять признаков, у которых наибольшая взаимосвязь с целевой переменной (с помощью корреляции). Отметьте отобранные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ram\n",
      "battery_power\n",
      "px_width\n",
      "px_height\n",
      "touch_screen\n"
     ]
    }
   ],
   "source": [
    "for feat in abs(data.corr().price_range).sort_values(ascending=False).index.drop('price_range')[:5]: print (feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ШАГ 2\n",
    "Теперь необходимо обучить алгоритм.  Для начала разбейте выборку на тестовую и обучающую, размер тестовой задайте `0.2`. Параметр `random_state=31`. В качестве модели возьмите логистическую регрессию. В качестве предикторов возьмите пять ранее отобранных признаков.\n",
    "\n",
    "Рассчитайте метрику, которая покажет, какая доля телефонов, обозначенных классификатором как дорогие, действительно относится к этой категории. \n",
    "\n",
    "### Задание 3B.3.2 Выбор метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "data = pd.read_csv('./Unit_5_data/train_mobile.csv', sep =';')\n",
    "\n",
    "columns_to_fit = abs(data.corr().price_range).sort_values(ascending=False).index[1:6]\n",
    "\n",
    "y = data.price_range\n",
    "X = data[columns_to_fit]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=31)\n",
    "\n",
    "model = LogisticRegression(random_state=31)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test,y_pred)\n",
    "round(precision,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.3.3 Значение метрики\n",
    "Введите полученное значение, округлите до четырех знаков после запятой. Целую и десятичную часть разделите точкой. Пример ввода: 5.5555."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(precision,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.5.3\n",
    "Посчитайте $logloss$ для данных в таблице (без нормализации). Укажите число с точностью до сотых:  \n",
    "\n",
    " | | | | | |\n",
    " |-|-|-|-|-|\n",
    " |Предсказанное значение |0.2|0.8|1|0.6|\n",
    " |Истинное значение      |0|0|1|1 |\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.34, 2.34)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series([0,0,1,1])\n",
    "y_pred = pd.Series([0.2,0.8,1,0.6])\n",
    "n = 4\n",
    "\n",
    "logloss = -(y*np.log(y_pred) + (1-y)*np.log(1-y_pred)).sum()\n",
    "\n",
    "round(log_loss(y,y_pred)*n,2), round(logloss,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.223144\n",
       "1    1.609438\n",
       "2         NaN\n",
       "3    0.510826\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(y*np.log(y_pred) + (1-y)*np.log(1-y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.5.4\n",
    "Посчитайте $logloss$ для данных в таблице. Необходимо найти среднюю ошибку. Классификация на три класса:\n",
    "\n",
    "| | | | |\n",
    "|-|-|-|-|\n",
    "|Предсказанное значение|0.2|0|0.1|\n",
    "| |0.3|0 |0  |\n",
    "| |0.5|1 |0.9|\n",
    "|Истинное значение     |0|0|1|\n",
    "|  |0|0|0|\n",
    "|  |1|1|0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.998577424517998, 0.9985774245179969)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([0.2,0.3,0.5,0,0,1,0.1,0,0.9]).reshape((3,3))\n",
    "y = np.array([0,0,1,0,0,1,1,0,0]).reshape((3,3))\n",
    "n = 3\n",
    "\n",
    "logloss = -np.nan_to_num(y*np.log(y_pred)).sum()/n\n",
    "\n",
    "log_loss(y,y_pred), logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B.6. Логистическая регрессия. Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае с логистической регрессией мы можем использовать только градиентный спуск, так как нет явного матричного способа найти оптимальные коэффициенты. В качестве функции потерь будем использовать бинарную кросс-энтропию, Log Loss. Она записывается так:\n",
    "\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i)))$$\n",
    "Градиент ошибки:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}$$\n",
    "Будем использовать другой датасет с задачей классификации, где нужно определить зарплату меньше и больше определённого значения. Убираем в данных лишние признаки, конвертируем целевой столбец в бинарные значения и нормализуем данные.\n",
    "\n",
    "Реализуем функцию `sigmoid` и функцию, вычисляющую градиент бинарной кросс-энтропии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./Unit_5_data/adult.data',\n",
    "                    names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                           'education-num', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'capital-gain',\n",
    "                           'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "\n",
    "# Избавиться от лишних признаков\n",
    "adult.drop(['native-country'], axis=1, inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', \n",
    "                                       'relationship', 'race', 'sex'])\n",
    "\n",
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "\n",
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X, theta):\n",
    "    return 1. / (1. + np.exp(-X.dot(theta)))\n",
    "\n",
    "def calc_binary_cross_entropy_grad(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(sigmoid(X, theta) - y)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_logisitc_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f'acc = {acc:.2f} F1-score = {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.65\n"
     ]
    }
   ],
   "source": [
    "y_pred = sigmoid(X, theta) > 0.5\n",
    "print_logisitc_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.6.1\n",
    "Постройте модель логистической регрессии при помощи sklearn. Используйте параметры по умолчанию, обучите на всей выборке и посчитайте F1 score.\n",
    "\n",
    "Ответ округлите до сотых. Пример ввода: 5.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./Unit_5_data/adult.data',\n",
    "                    names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                           'education-num', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'capital-gain',\n",
    "                           'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "\n",
    "# Избавиться от лишних признаков\n",
    "adult.drop(['native-country'], axis=1, inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', \n",
    "                                       'relationship', 'race', 'sex'])\n",
    "\n",
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "\n",
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "\n",
    "LR.fit(X,y)\n",
    "\n",
    "y_pred = LR.predict(X)\n",
    "\n",
    "round(f1_score(y,y_pred),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.6.2\n",
    "Посчитайте confusion matrix для классификатора из задачи 3.6.1. Введите значения получившейся матрицы в соответствующие ячейки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23028,  1692],\n",
       "       [ 3125,  4716]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23028,  1692],\n",
       "       [ 3125,  4716]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = ((y==y_pred) & (y == 0)).sum()\n",
    "TN = ((y==y_pred) & (y == 1)).sum()\n",
    "FP = ((y!=y_pred) & (y == 1)).sum()\n",
    "FN = ((y!=y_pred) & (y == 0)).sum()\n",
    "\n",
    "np.array([[TP,FN],[FP,TN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.6.3\n",
    "Постройте ROC-кривую и посчитайте  для классификатора из задачи 3.6.1.\n",
    "Ответ округлите до сотых. Пример ввода: 5.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = LR.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2127d438e48>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y, y_pred_proba[:,1])\n",
    "roc_auc = roc_auc_score(y, y_pred_proba[:,1])\n",
    "    \n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.title('ROC & ROC-AUC', fontsize=15)\n",
    "plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.6.4\n",
    "Постройте модель логистической регрессии при помощи sklearn без регуляризации. Чему равен $F1$-$score$ ?\n",
    "\n",
    "Ответ округлите до сотых. Пример ввода: 5.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./Unit_5_data/adult.data',\n",
    "                    names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                           'education-num', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'capital-gain',\n",
    "                           'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "\n",
    "# Избавиться от лишних признаков\n",
    "adult.drop(['native-country'], axis=1, inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', \n",
    "                                       'relationship', 'race', 'sex'])\n",
    "\n",
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "\n",
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(C=10**5)\n",
    "LR.fit(X,y)\n",
    "\n",
    "y_pred = LR.predict(X)\n",
    "\n",
    "round(f1_score(y,y_pred),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.6.5\n",
    "Переберите коэффициенты $l2$-регуляризации от $0.01$ до $1$ с шагом $0.01$ и определите, на каком из них модель логистической регрессии из sklearn даёт наибольший $F1$-$score$ .\n",
    "\n",
    "Ответ округлите до сотых. Пример ввода: 5.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = pd.Series()\n",
    "for C in np.linspace(0.01,1,100):\n",
    "    LR = LogisticRegression(C=C)\n",
    "    LR.fit(X,y)\n",
    "    y_pred = LR.predict(X)\n",
    "    scores[C] = f1_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91, 0.6620350877192983)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.idxmax(), scores.max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.6.6\n",
    "Замените в столбце `native-country` страны, у которых меньше ста записей, на `other`, поменяйте этот столбец на dummy-переменные, обучите классификатор на всей выборке и посчитайте $F1$$score$  .\n",
    "\n",
    "Ответ округлите до сотых. Пример ввода: 5.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as ps\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./Unit_5_data/adult.data',\n",
    "                    names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                           'education-num', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'capital-gain',\n",
    "                           'capital-loss', 'hours-per-week', 'native-country', 'salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменить  страны, у которых меньше ста записей, на `other`\n",
    "native_country = adult['native-country']\n",
    "mask_to_unite = native_country.value_counts()<100\n",
    "to_unite = native_country.value_counts().index[mask_to_unite].tolist()\n",
    "adult['native-country'].replace(to_unite, 'other',inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', \n",
    "                                       'relationship', 'race', 'sex','native-country'])\n",
    "\n",
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "\n",
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(C=10**5)\n",
    "LR.fit(X,y)\n",
    "\n",
    "y_pred = LR.predict(X)\n",
    "\n",
    "round(f1_score(y,y_pred),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПОДВАЛ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate data\n",
    "X, y = make_blobs(n_samples=1000, random_state=42, cluster_std=5.0)\n",
    "X_train, y_train = X[:600], y[:600]\n",
    "X_valid, y_valid = X[600:800], y[600:800]\n",
    "X_train_valid, y_train_valid = X[:800], y[:800]\n",
    "X_test, y_test = X[800:], y[800:]\n",
    "\n",
    "# Train uncalibrated random forest classifier on whole train and validation\n",
    "# data and evaluate on test data\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train_valid, y_train_valid)\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "score = log_loss(y_test, clf_probs)\n",
    "\n",
    "# Train random forest classifier, calibrate on validation data and evaluate\n",
    "# on test data\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf.fit(X_valid, y_valid)\n",
    "sig_clf_probs = sig_clf.predict_proba(X_test)\n",
    "sig_score = log_loss(y_test, sig_clf_probs)\n",
    "\n",
    "# Plot changes in predicted probabilities via arrows\n",
    "plt.figure()\n",
    "colors = [\"r\", \"g\", \"b\"]\n",
    "for i in range(clf_probs.shape[0]):\n",
    "    plt.arrow(clf_probs[i, 0], clf_probs[i, 1],\n",
    "              sig_clf_probs[i, 0] - clf_probs[i, 0],\n",
    "              sig_clf_probs[i, 1] - clf_probs[i, 1],\n",
    "              color=colors[y_test[i]], head_width=1e-2)\n",
    "\n",
    "# Plot perfect predictions\n",
    "plt.plot([1.0], [0.0], 'ro', ms=20, label=\"Class 1\")\n",
    "plt.plot([0.0], [1.0], 'go', ms=20, label=\"Class 2\")\n",
    "plt.plot([0.0], [0.0], 'bo', ms=20, label=\"Class 3\")\n",
    "\n",
    "# Plot boundaries of unit simplex\n",
    "plt.plot([0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], 'k', label=\"Simplex\")\n",
    "\n",
    "# Annotate points on the simplex\n",
    "plt.annotate(r'($\\frac{1}{3}$, $\\frac{1}{3}$, $\\frac{1}{3}$)',\n",
    "             xy=(1.0/3, 1.0/3), xytext=(1.0/3, .23), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.plot([1.0/3], [1.0/3], 'ko', ms=5)\n",
    "plt.annotate(r'($\\frac{1}{2}$, $0$, $\\frac{1}{2}$)',\n",
    "             xy=(.5, .0), xytext=(.5, .1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($0$, $\\frac{1}{2}$, $\\frac{1}{2}$)',\n",
    "             xy=(.0, .5), xytext=(.1, .5), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($\\frac{1}{2}$, $\\frac{1}{2}$, $0$)',\n",
    "             xy=(.5, .5), xytext=(.6, .6), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($0$, $0$, $1$)',\n",
    "             xy=(0, 0), xytext=(.1, .1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($1$, $0$, $0$)',\n",
    "             xy=(1, 0), xytext=(1, .1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "plt.annotate(r'($0$, $1$, $0$)',\n",
    "             xy=(0, 1), xytext=(.1, 1), xycoords='data',\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "# Add grid\n",
    "plt.grid(False)\n",
    "for x in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    plt.plot([0, x], [x, 0], 'k', alpha=0.2)\n",
    "    plt.plot([0, 0 + (1-x)/2], [x, x + (1-x)/2], 'k', alpha=0.2)\n",
    "    plt.plot([x, x + (1-x)/2], [0, 0 + (1-x)/2], 'k', alpha=0.2)\n",
    "\n",
    "plt.title(\"Change of predicted probabilities after sigmoid calibration\")\n",
    "plt.xlabel(\"Probability class 1\")\n",
    "plt.ylabel(\"Probability class 2\")\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "print(\"Log-loss of\")\n",
    "print(\" * uncalibrated classifier trained on 800 datapoints: %.3f \"\n",
    "      % score)\n",
    "print(\" * classifier trained on 600 datapoints and calibrated on \"\n",
    "      \"200 datapoint: %.3f\" % sig_score)\n",
    "\n",
    "# Illustrate calibrator\n",
    "plt.figure()\n",
    "# generate grid over 2-simplex\n",
    "p1d = np.linspace(0, 1, 20)\n",
    "p0, p1 = np.meshgrid(p1d, p1d)\n",
    "p2 = 1 - p0 - p1\n",
    "p = np.c_[p0.ravel(), p1.ravel(), p2.ravel()]\n",
    "p = p[p[:, 2] >= 0]\n",
    "\n",
    "calibrated_classifier = sig_clf.calibrated_classifiers_[0]\n",
    "prediction = np.vstack([calibrator.predict(this_p)\n",
    "                        for calibrator, this_p in\n",
    "                        zip(calibrated_classifier.calibrators_, p.T)]).T\n",
    "prediction /= prediction.sum(axis=1)[:, None]\n",
    "\n",
    "# Plot modifications of calibrator\n",
    "for i in range(prediction.shape[0]):\n",
    "    plt.arrow(p[i, 0], p[i, 1],\n",
    "              prediction[i, 0] - p[i, 0], prediction[i, 1] - p[i, 1],\n",
    "              head_width=1e-2, color=colors[np.argmax(p[i])])\n",
    "# Plot boundaries of unit simplex\n",
    "plt.plot([0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], 'k', label=\"Simplex\")\n",
    "\n",
    "plt.grid(False)\n",
    "for x in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    plt.plot([0, x], [x, 0], 'k', alpha=0.2)\n",
    "    plt.plot([0, 0 + (1-x)/2], [x, x + (1-x)/2], 'k', alpha=0.2)\n",
    "    plt.plot([x, x + (1-x)/2], [0, 0 + (1-x)/2], 'k', alpha=0.2)\n",
    "\n",
    "plt.title(\"Illustration of sigmoid calibrator\")\n",
    "plt.xlabel(\"Probability class 1\")\n",
    "plt.ylabel(\"Probability class 2\")\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "\n",
    "plt.show()\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
