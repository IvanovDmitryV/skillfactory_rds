{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "\n",
    "columns_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "\n",
    "iris_data = pd.DataFrame(np.hstack([data.data, data.target[:, np.newaxis]]), columns = columns_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть четыре признака, относящиеся к размерам цветка, и классы. На первом этапе мы разобьём выборку на две части: тренировочную и валидационную, а позже рассмотрим, как добавить тестовую. Воспользуемся методом train_test_split() из библиотеки sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер исходной выборки: (150, 5)\n",
      "Размер тренировочной выборки: (127, 5)\n",
      "Размер валидационной выборки: (23, 5)\n"
     ]
    }
   ],
   "source": [
    "train, valid = train_test_split(iris_data, test_size=0.15, shuffle=True)\n",
    "\n",
    "print('Размер исходной выборки: {}\\nРазмер тренировочной выборки: {}\\nРазмер валидационной выборки: {}'\n",
    "      .format(iris_data.shape, train.shape, valid.shape)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь визуализируем наше разбиение с помощью специального метода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_valid_counts(init_data, train, valid):\n",
    "    x = np.array([0, 1, 2])\n",
    "    width = 0.2\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    classes = list(init_data['class'].value_counts().index)\n",
    "\n",
    "    ax.bar(x - width, list(init_data['class'].value_counts()[classes]), width, color='r', label='Исходные данные')\n",
    "    ax.bar(x, list(train['class'].value_counts()[classes]), width, color='g', label='Тренировочная выборка')\n",
    "    ax.bar(x, list(valid['class'].value_counts()[classes]), width, bottom=list(train['class'].value_counts()[classes]), color='b', label='Валидационная выборка')\n",
    "\n",
    "    ax.set_ylim([0, 70])\n",
    "    plt.xticks(x - width / 2, classes, fontsize=20)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylabel('Кол-во примеров', fontsize=20)\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(which='major', color='r')\n",
    "    plt.grid(which='minor', linestyle=':', color='k')\n",
    "    plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас три класса цветков, в каждом из которых получилось разное количество примеров с выборками, в третьем примере значительно больше примеров на валидационной выборке. Получилось **неравномерное распределение классов** после разбиения, так как мы не учли доли классов.\n",
    "\n",
    "Проблема решается с помощью **stratified разбиения** или стратифицированного разбиения. В библиотеке sklearn есть нужный нам класс `StratifiedShuffleSplit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15)\n",
    "train_indices, valid_indices = [split for split in sss.split(iris_data.iloc[:, :4], iris_data.iloc[:, 4])][0]\n",
    "s_train = iris_data.iloc[train_indices]\n",
    "s_valid = iris_data.iloc[valid_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.3.1\n",
    "Загрузите данные [train.csv](https://drive.google.com/file/d/1wbB8sqdz667_SUDISF57qSaSAUhtwlmP/view), разделите выборку на обучающую и тестовую части в соотношении 70% на 30% без перемешивания. Найдите среднее значение для признака `payment_amount` и запишите его в переменную `result`. Обратите внимание, что среднее нужно считать по тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "vis_data = pd.read_csv(\"./Unit_5_data/train.csv\", encoding = 'ISO-8859-1', low_memory = False)\n",
    "# Напишите ваш код ниже\n",
    "\n",
    "train, test = train_test_split(vis_data, test_size=0.3,shuffle=False)\n",
    "result = test.payment_amount.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.4.5\n",
    "Допустим, у вас есть выборки `y_true = [1.23, 2.35, 2.75]` и `y_pred = [1.01, 12.3, 2.74]`. Посчитайте метрику `RMSE`, округлите до сотых и запишите результат. Например, 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([1.23, 2.35, 2.75])\n",
    "y_pred = np.array([1.01, 12.3, 2.74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.75"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = np.sqrt(((y_true-y_pred)**2).sum()/3)\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.75"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans2 = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "ans2\n",
    "round(ans2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.5.1\n",
    "Загрузите данные `train.csv`, оставьте в данных только признаки `'fine_amount', 'state_fee', 'late_fee', 'discount_amount', 'balance_due'`, затем избавьтесь от пропусков. Целевой переменной будет `'balance_due'`, разделите данные на обучающую и тестовую выборки в соотношении 70% / 30% без перемешивания. Обучите линейную регрессию из `scikit-learn` и запишите в переменную `result` значение метрики **RMSE** на тестовой выборке. **RMSE** означает Rooted Mean Squared Error. Rooted означает, что из значения метрики был взят корень."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "# vis_data = pd.read_csv(\"./train.csv\", encoding = 'ISO-8859-1', low_memory = False)\n",
    "vis_data = pd.read_csv(\"./Unit_5_data/train.csv\", encoding = 'ISO-8859-1', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_study = ['fine_amount', 'state_fee', 'late_fee', 'discount_amount', 'balance_due']\n",
    "vis_data = vis_data[columns_to_study]\n",
    "vis_data.dropna(inplace = True)\n",
    "X,y  = vis_data.drop(columns='balance_due'), vis_data.balance_due\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7,shuffle=False)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "result = np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.6.2\n",
    "Используя библиотеку `sklearn`, найдите метод для подсчёта метрики . Создайте два одинаковых списка, состоящих из одинаковых 100 чисел. Замените в одном списке одно число на любое другое, отправьте эти списки в метод для подсчёта $accuracy$ . Что выдаст алгоритм на выходе? Ответ запишите с точностью до сотых, в качестве разделителя используйте точку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true,y_pred = [1]*100,[1]*100\n",
    "y_pred[99] = 0\n",
    "ans = accuracy_score(y_true,y_pred)\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.6.7\n",
    "На этапе вычисления метрик вы получили результаты precision = 0.75 и recall = 0.6. Посчитайте значение метрики $f1$. Округлите до сотых и запишите результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 0.75\n",
    "recall = 0.6\n",
    "ans = 2*precision*recall/(precision+recall)\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.6.8\n",
    "Допустим, у вас есть выборки `y_true = [0, 0, 1, 1, 1, 1, 0, 1]` и `y_pred = [0, 1, 0, 0, 1, 1, 0, 1]`. Посчитайте значение метрики $f1$. Округлите до сотых и запишите результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_true = np.array([0, 0, 1, 1, 1, 1, 0, 1])\n",
    "y_pred = np.array([0, 1, 0, 0, 1, 1, 0, 1])\n",
    "ans = f1_score(y_true,y_pred)\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.6.9\n",
    "Допустим, у вас есть выборки `y_true = [0, 0, 1, 1, 1, 1, 0, 1]` и `y_pred = [0, 1, 0, 0, 1, 1, 0, 1]`. Посчитайте значение метрики $precision$ . Округлите до сотых и запишите результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "y_true = np.array([0, 0, 1, 0, 0, 1, 0])\n",
    "y_pred = np.array([1, 1, 1, 0, 1, 1, 0])\n",
    "ans = precision_score(y_true,y_pred)\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_true*y_pred).sum()/y_pred.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.6.10\n",
    "Допустим, у вас есть выборки `y_true = [0, 0, 1, 0, 0, 1, 0]` и `y_pred = [1, 1, 1, 0, 1, 1, 0]`. Посчитайте значение метрики $recall$. Округлите до сотых и запишите результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_true = np.array([0, 0, 1, 0, 0, 1, 0])\n",
    "y_pred = np.array([1, 1, 1, 0, 1, 1, 0])\n",
    "ans = recall_score(y_true,y_pred)\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика для метрик классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предложенном датасете есть ряд свойств, определенных по аудиозаписям:\n",
    "\n",
    "**meanfreq**: средняя частота голоса (в кГц)  \n",
    "**sd**: стандартное отклонение частоты голоса  \n",
    "**median**: медианная частота (в кГц)  \n",
    "**Q25**: значение в первом квартиле (в кГц)  \n",
    "**Q75**: значение в третьем квартиле (в кГц)  \n",
    "**IQR**: интерквартильный размах (в кГц)  \n",
    "**skew**: ассиметрия  \n",
    "**kurt**: эксцесс  \n",
    "**sp.ent**: спектральная энтропия  \n",
    "**sfm**: энтропия Винера  \n",
    "**mode**: мода частоты  \n",
    "**centroid**: частотный центроид  \n",
    "**meanfun**: средняя основная частота, измеренная по акустическому сигналу  \n",
    "**minfun**:  минимальная основная частота, измеренная по акустическому сигналу  \n",
    "**maxfun**: максимальная основная частота, измеренная в акустическом сигнале  \n",
    "**meandom**: среднее значение доминирующей частоты, измеренной по акустическому сигналу  \n",
    "**mindom**: минимум доминирующей частоты, измеренной в акустическом сигнале  \n",
    "**maxdom**: максимум доминирующей частоты, измеренной в акустическом сигнале  \n",
    "**dfrange**: диапазон доминантных частот, измеренное на звуковой сигнал  \n",
    "**modindx**: индекс модуляции голоса  \n",
    "\n",
    "## Задание\n",
    "Попробуйте построить модель, предсказывающую пол обладателя записи голоса.\n",
    "\n",
    "Для этого:\n",
    "\n",
    "- Разделите выборку на обучающую и тренировочную с параметрами `test_size=0.3`, `random_state=42`.\n",
    "\n",
    "- Нормализуйте признаки с помощью функции `StandardScaler()`. Учитывайте, что нормализация тестовой выборки производится по среднему и отклонению тренировочной, которую мы считаем репрезентативной относительно генеральной совокупности.\n",
    "\n",
    "- Обучите модель логистической регрессии на подготовленных данных.\n",
    "\n",
    "***Пояснение***\n",
    "Тестовые данные не должны влиять на параметры нормализации. Нужно использовать `SCALER.TRANSFORM` вместо `SCALER.FIT_TRANSFORM`, чтобы применять параметры нормализации, рассчитанные для тренировочных данных. Иначе данные в трейне и в тесте будут нормализованы по - разному."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('./Unit_5_data/voiceDataSet.csv')\n",
    "\n",
    "X, y = data.drop(columns='label'),(data.label=='male').astype('int')\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scl = scaler.fit_transform(X_train)\n",
    "X_test_scl = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scl,y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_scl)\n",
    "y_pred_proba = lr.predict_proba(X_test_scl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.7.1\n",
    "Вычислите значение метрики $accuracy$ и введите полученное значение. Запишите ответ, округлив его до третьего знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = accuracy_score(y_test,y_pred)\n",
    "round(ans,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мультиклассовая классификация \n",
    "Теперь познакомимся с новым алгоритмом классификации, а также снова потренируемся делить выборку и осуществлять кросс-валидацию. Кроме того, посмотрим, как можно оценить качество классификации для случая, когда наша классификация не бинарная, т.е. у нас несколько классов.\n",
    "\n",
    "В этом кейсе мы попробуем определять типы стекла по его характеристикам.\n",
    "\n",
    "Наша классификация мультиклассовая, поэтому мы должны посмотреть, сколько у нас классов. Если вы вообще ничего не знаете о задаче в плане количества классов, обязательно начинайте с этого, поскольку это повлияет на ход решения. Особенно важно понять, бинарная классификация или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Unit_5_data/glass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data.drop(columns='Type'),data.Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.7.2\n",
    "Сколько классов стекла представлено в этой задаче?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Type.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь воспользуемся k-fold валидацией на пяти разбиениях и обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44186047, 0.65116279, 0.3255814 , 0.34883721, 0.07142857])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "model=KNeighborsClassifier(n_neighbors=3)\n",
    "kf = KFold(n_splits=5)\n",
    "cross_val_score(model, X, y, cv=kf, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.7.3\n",
    "Измените количество разбиений на 10. Вычислите среднее значение метрики $accuracy$ по 10 разбиениям и введите ниже, округлите до сотых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "model=KNeighborsClassifier(n_neighbors=3)\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "metrics = cross_val_score(model, X, y, cv=kf, scoring=\"accuracy\")\n",
    "ans = metrics.mean()\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующей задаче мы будем диагностировать болезни сердца по различным медицинским параметрам пациентов.\n",
    "\n",
    "Избавьтесь от выбросов, чтобы они не ухудшили качество нашей модели.  \n",
    "Для того, чтобы избавиться от выбросов, уберите все данные, значения признаков которых отстают от первого или третьего квартиля более, чем на 1.5 межквартильного размаха."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Unit_5_data/heart_fin1.csv',delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   restecg   303 non-null    int64  \n",
      " 6   thalach   303 non-null    int64  \n",
      " 7   exang     303 non-null    int64  \n",
      " 8   oldpeak   303 non-null    float64\n",
      " 9   target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 23.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data.drop(columns='target'),data.target\n",
    "\n",
    "first_quartiles = np.quantile(X,0.25,axis=0)\n",
    "third_quartiles = np.quantile(X,0.75,axis=0)\n",
    "interquart = third_quartiles - first_quartiles\n",
    "l_bounds = first_quartiles - 1.5*interquart\n",
    "r_bounds = third_quartiles + 1.5*interquart\n",
    "\n",
    "row_mask = ((X<l_bounds) | (X>r_bounds)).any(axis=1)\n",
    "\n",
    "rows_to_drop = X.index[row_mask]\n",
    "\n",
    "X,y  = X.drop(index=rows_to_drop),y.drop(index=rows_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.7.4\n",
    "Сколько наблюдений осталось после удаления выбросов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.7.5-4.7.6\n",
    "Теперь разбейте выборку на тестовую и обучающую с параметрами test_size=0.15, random_state=5.\n",
    "\n",
    "Обучите модели логистической регрессии ( c параметром max_iter=1000) и KNN (с количеством соседей, равным 3) на этих данных. Вычислите метрики качества $ROC AUC$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82, 0.65)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.15, random_state=5)\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred_lr = lr.predict_proba(X_test)\n",
    "y_pred_knn = knn.predict_proba(X_test)\n",
    "\n",
    "lr_auc = roc_auc_score(y_test,y_pred_lr[:,1])\n",
    "knn_auc = roc_auc_score(y_test,y_pred_knn[:,1])\n",
    "\n",
    "round(lr_auc,2), round(knn_auc,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.9.1\n",
    "Загрузите данные `train.csv`, оставьте в данных только признаки `'fine_amount', 'state_fee', 'late_fee', 'discount_amount', 'balance_due', 'compliance'`, затем избавьтесь от пропусков.\n",
    "\n",
    "Целевой переменной будет `'compliance'`, разделите данные на обучающую и тестовую выборки в соотношении 70%/30% без перемешивания.\n",
    "\n",
    "Обучите `DecisionTreeClassifier` из `scikit-learn` с параметром `random_state=23`. Посчитайте значения метрики $F1$  на тренировочной выборке и на тестовой выборке. Вычтите из значения метрики на тренировочной выборки значение метрики на тестовой выборке и запишите результат в переменную `result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manych\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (11,12,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "# vis_data = pd.read_csv(\"./train.csv\", encoding = 'ISO-8859-1', low_memory = False)\n",
    "vis_data = pd.read_csv('./Unit_5_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08055341409051786"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_to_study = ['fine_amount', 'state_fee', 'late_fee', 'discount_amount', 'balance_due', 'compliance']\n",
    "vis_data = vis_data[column_to_study]\n",
    "\n",
    "vis_data = vis_data.dropna()\n",
    "X,y = vis_data.drop(columns = 'compliance'),vis_data.compliance\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,shuffle=False)\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=23)\n",
    "dtc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train = dtc.predict(X_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "score_train = f1_score(y_train,y_pred_train)\n",
    "score_test = f1_score(y_test,y_pred)\n",
    "\n",
    "result = score_train - score_test\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.11.1\n",
    "Загрузите данные `train.csv`, оставьте в данных только признаки `'fine_amount', 'state_fee', 'late_fee', 'discount_amount', 'balance_due', 'compliance'`, затем избавьтесь от пропусков.\n",
    "\n",
    "Обучим модель на несбалансированных данных. Целевой переменной будет `'compliance'`, разделите данные на обучающую и тестовую выборки в соотношении 70%/30% без перемешивания.\n",
    "\n",
    "Обучите `DecisionTreeClassifier` из `scikit-learn` с параметром `random_state=23`. Посчитайте значения метрики  на тренировочной выборке и на тестовой выборке.\n",
    "\n",
    "Затем сделайте эту же выборку сбалансированной с помощью **undersampling**.\n",
    "\n",
    "Для этого посчитайте количество примеров (`n`) класса-меньшинства, затем из класса-большинства возьмите `n` первых примеров.\n",
    "\n",
    "То есть, в терминологии `Python`, возьмите срез (`slice`) от начала и до `n`, где `n` — количество примеров класса, которого в выборке представлено меньше.\n",
    "\n",
    "Соедините две части выборки (с уменьшенным классом-большинством и с изначальным классом-меньшинством), сделайте точно такое же разбиение, как в задаче выше, и обучите такую же модель.\n",
    "\n",
    "Посчитайте значение метрики  на новой тестовой выборке с помощью новой модели. Вычтите из значения метрики на тестовой части сбалансированной выборки значение метрики на тестовой части несбалансированной выборки и запишите результат в переменную `result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manych\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (11,12,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "vis_data = pd.read_csv('./Unit_5_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_study = ['fine_amount', 'state_fee', 'late_fee', 'discount_amount', 'balance_due', 'compliance']\n",
    "vis_data = vis_data[column_to_study]\n",
    "vis_data = vis_data.dropna()\n",
    "X,y = vis_data.drop(columns = 'compliance'),vis_data.compliance\n",
    "# unbalanced\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,shuffle=False)\n",
    "dtc = DecisionTreeClassifier(random_state=23)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred_unbal = dtc.predict(X_test)\n",
    "score_test_unbal = f1_score(y_test,y_pred_unbal)\n",
    "# balanced\n",
    "index_pos = y[(y == 1)].index\n",
    "index_neg = y[(y == 0)].index\n",
    "n = len(index_pos)\n",
    "index_downsempl = index_neg.append(index_pos[:n])\n",
    "X_downsempl = X.loc[index_downsempl, :]\n",
    "y_downsempl = y[index_downsempl]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_downsempl, y_downsempl, test_size=0.3, shuffle=False)\n",
    "dtc = DecisionTreeClassifier(random_state=23)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred_bal = dtc.predict(X_test)\n",
    "score_test_bal = f1_score(y_test,y_pred_bal)\n",
    "\n",
    "result = score_test_bal - score_test_unbal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.580226904376013"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18272749967696011"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_data_small = vis_data[['fine_amount', 'state_fee', 'late_fee', \n",
    "                           'discount_amount', 'balance_due', 'compliance']].dropna()\n",
    "X = vis_data_small[['fine_amount', 'state_fee', 'late_fee', 'discount_amount', 'balance_due']]\n",
    "y = vis_data_small['compliance']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "clf = DecisionTreeClassifier(random_state=23)\n",
    "clf.fit(X_train, y_train)\n",
    "f1_imbalanced = f1_score(y_test, clf.predict(X_test))\n",
    "zeros = y[y == 0.0]\n",
    "ones = y[y == 1.0]\n",
    "down_index = list(zeros.index[:len(ones)]) + list(ones.index)\n",
    "X_down = X.loc[down_index, :]\n",
    "y_down = y[down_index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_down, y_down, test_size=0.3, shuffle=False)\n",
    "clf = DecisionTreeClassifier(random_state=23)\n",
    "clf.fit(X_train, y_train)\n",
    "f1_balanced = f1_score(y_test, clf.predict(X_test))\n",
    "result = f1_balanced - f1_imbalanced\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
