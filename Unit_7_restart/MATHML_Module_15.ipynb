{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46e33ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b394bdb7",
   "metadata": {},
   "source": [
    "Например, мы можем представить те же самые фильмы как набор из трёх вещественных чисел:\n",
    "\n",
    "фильм $A = (1.1, 2.3, 5.1)$;   \n",
    "фильм $B = (1.3, 2.1, 4.9)$;   \n",
    "фильм $C = (5.1, 6.2, 1.1)$.\n",
    "\n",
    "Чтобы вычислить косинусную близость, нам понадобится следующая формула:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/19ae75390814099a1aaf8a660888b0d6/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/DST_MATH_ML_15_2_5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44167b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fa1aa04",
   "metadata": {},
   "source": [
    "### Задание 2.1\n",
    "Вычислите косинусную близость между векторами А и С. Результат округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a624aa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.551"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([1.1,2.3,5.1])\n",
    "C = np.array([5.1,6.2,1.1])\n",
    "\n",
    "ans = A@C/(np.linalg.norm(A)*np.linalg.norm(C))\n",
    "round(ans,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a2de3b",
   "metadata": {},
   "source": [
    "Итак, чтобы построить рекомендательную систему на основе контента, необходимо:\n",
    "\n",
    "* Для каждого продукта создать характеризующие его признаки.\n",
    "* Найти показатель близости между всеми продуктами.\n",
    "* Порекомендовать пользователю продукты, которые показывают наибольшую близость с теми продуктами, которые он высоко оценил.    \n",
    "    \n",
    "Давайте реализуем подобную рекомендательную систему на практике. Будем работать с \n",
    "[датасетом](https://lms.skillfactory.ru/assets/courseware/v1/747dae7bf99b18ce3b24bd34aa7bc29b/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/netflix_titles.zip), содержащим информацию об оценивании фильмов на платформе ***Netflix***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7fc424",
   "metadata": {},
   "source": [
    "Признаки в данных\n",
    "* show_id — id фильма,\n",
    "* type — его тип (фильм или сериал),\n",
    "* title — название,\n",
    "* director — режиссер,\n",
    "* cast — актерский состав,\n",
    "* country — страна,\n",
    "* date_added — дата добавления,\n",
    "* release_year — год выхода на экраны,\n",
    "* rating — рейтинг,\n",
    "* duration — продолжительность,\n",
    "* listened_in — жанр(-ы),\n",
    "* description — описание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9256c8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>João Miguel, Bianca Comparato, Michel Gomes, R...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>August 14, 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>4 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Sci-Fi &amp;...</td>\n",
       "      <td>In a future where the elite inhabit an island ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>Movie</td>\n",
       "      <td>7:19</td>\n",
       "      <td>Jorge Michel Grau</td>\n",
       "      <td>Demián Bichir, Héctor Bonilla, Oscar Serrano, ...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>December 23, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>93 min</td>\n",
       "      <td>Dramas, International Movies</td>\n",
       "      <td>After a devastating earthquake hits Mexico Cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>Movie</td>\n",
       "      <td>23:59</td>\n",
       "      <td>Gilbert Chan</td>\n",
       "      <td>Tedd Chan, Stella Chung, Henley Hii, Lawrence ...</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>December 20, 2018</td>\n",
       "      <td>2011</td>\n",
       "      <td>R</td>\n",
       "      <td>78 min</td>\n",
       "      <td>Horror Movies, International Movies</td>\n",
       "      <td>When an army recruit is found dead, his fellow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>Movie</td>\n",
       "      <td>9</td>\n",
       "      <td>Shane Acker</td>\n",
       "      <td>Elijah Wood, John C. Reilly, Jennifer Connelly...</td>\n",
       "      <td>United States</td>\n",
       "      <td>November 16, 2017</td>\n",
       "      <td>2009</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>80 min</td>\n",
       "      <td>Action &amp; Adventure, Independent Movies, Sci-Fi...</td>\n",
       "      <td>In a postapocalyptic world, rag-doll robots hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>Movie</td>\n",
       "      <td>21</td>\n",
       "      <td>Robert Luketic</td>\n",
       "      <td>Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...</td>\n",
       "      <td>United States</td>\n",
       "      <td>January 1, 2020</td>\n",
       "      <td>2008</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>123 min</td>\n",
       "      <td>Dramas</td>\n",
       "      <td>A brilliant group of students become card-coun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type  title           director  \\\n",
       "0      s1  TV Show     3%                NaN   \n",
       "1      s2    Movie   7:19  Jorge Michel Grau   \n",
       "2      s3    Movie  23:59       Gilbert Chan   \n",
       "3      s4    Movie      9        Shane Acker   \n",
       "4      s5    Movie     21     Robert Luketic   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0  João Miguel, Bianca Comparato, Michel Gomes, R...         Brazil   \n",
       "1  Demián Bichir, Héctor Bonilla, Oscar Serrano, ...         Mexico   \n",
       "2  Tedd Chan, Stella Chung, Henley Hii, Lawrence ...      Singapore   \n",
       "3  Elijah Wood, John C. Reilly, Jennifer Connelly...  United States   \n",
       "4  Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...  United States   \n",
       "\n",
       "          date_added  release_year rating   duration  \\\n",
       "0    August 14, 2020          2020  TV-MA  4 Seasons   \n",
       "1  December 23, 2016          2016  TV-MA     93 min   \n",
       "2  December 20, 2018          2011      R     78 min   \n",
       "3  November 16, 2017          2009  PG-13     80 min   \n",
       "4    January 1, 2020          2008  PG-13    123 min   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0  International TV Shows, TV Dramas, TV Sci-Fi &...   \n",
       "1                       Dramas, International Movies   \n",
       "2                Horror Movies, International Movies   \n",
       "3  Action & Adventure, Independent Movies, Sci-Fi...   \n",
       "4                                             Dramas   \n",
       "\n",
       "                                         description  \n",
       "0  In a future where the elite inhabit an island ...  \n",
       "1  After a devastating earthquake hits Mexico Cit...  \n",
       "2  When an army recruit is found dead, his fellow...  \n",
       "3  In a postapocalyptic world, rag-doll robots hi...  \n",
       "4  A brilliant group of students become card-coun...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/netflix_titles.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e145883",
   "metadata": {},
   "source": [
    "В первую очередь нам необходимо определить, на основании чего мы будем рассматривать близость фильмов. Выберем для этой задачи описание фильма, ведь в нём, скорее всего, содержится много информации. Однако описание — это текст. Есть много подходов к преобразованию текста в вектор, и мы будем использовать подход **TF-IDF** (Term Frequency-Inverse Document Frequency).\n",
    ">Показатель **TD-IDF** — это индикатор того, насколько релевантно слово в контексте документа.\n",
    "\n",
    "Его можно определить следующим образом:\n",
    "$$\\text{TF-IDF(слова) = TF(слова) * IDF (слова)}$$\n",
    "$\\text{TF слова} = \\frac{\\text{Количество раз, когда слово встретилось в тексте}}{\\text{Количество всех слов в тексте}}$   \n",
    "$\\text{IDF слова} = log \\left (\\frac{\\text{Общее кол-во документов}}{\\text{Кол-во документов, в которых встречается слово}}\\right )$   \n",
    "    \n",
    "Этот показатель возрастает пропорционально количеству раз, когда слово встречается в тексте, и уменьшается пропорционально количеству слов во всех текстах в целом.\n",
    "\n",
    "Таким образом:\n",
    "\n",
    "* Коэффициент будет выше, если слово характерно именно для этого текста, то есть встречается в данном тексте часто, но не встречается в других текстах.\n",
    "* Коэффициент будет ниже, если слово не встречается почти нигде или встречается одинаковое количество раз во всех текстах, то есть не характеризует никакой текст в отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13ea247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы преобразовать текст по этому принципу, нам понадобится соответствующая функция \n",
    "# из библиотеки sklearn — импортируем её:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Далее учтём стоп-слова, т. е. предлоги и другие служебные части речи, которые не несут \n",
    "# содержательной информации, и с учётом этого определим нашу модель:\n",
    "model = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Заполним пропуски пустыми строками:\n",
    "df['description'] = df['description'].fillna('')\n",
    "\n",
    "# Трансформируем наши описания в матрицу:\n",
    "feature_matrix = model.fit_transform(df['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419d871",
   "metadata": {},
   "source": [
    "### Задание 2.2\n",
    "Сколько столбцов в получившейся матрице?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec197b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17905"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d882e319",
   "metadata": {},
   "source": [
    "Теперь необходимо вычислить косинусную близость. Можно сделать это так:\n",
    "```python\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_sim = linear_kernel(feature_matrix, feature_matrix)\n",
    "```\n",
    ">Обратите внимание! Мы используем здесь linear_kernel(), а не cosine_similarity(), так как в косинусном расстоянии в знаменателе реализуется нормировка векторов, а **TF-IDF** создаёт уже нормализованные векторы.\n",
    "\n",
    "Вернём индексацию и уберём дубликаты из данных:\n",
    "```python\n",
    "indices = pd.Series(df.index,index=df['title']).drop_duplicates()\n",
    "```\n",
    "Теперь пропишем функцию для создания рекомендаций:\n",
    "```python\n",
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    #вычисляем попарные коэффициенты косинусной близости\n",
    "    scores = list(enumerate(cosine_sim[idx]))\n",
    "    #сортируем фильмы на основании коэффициентов косинусной близости по убыванию\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    #выбираем десять наибольших значений косинусной близости; нулевую не берём, т. к. это тот же фильм\n",
    "    scores =   scores[1:11]\n",
    "    #забираем индексы\n",
    "    ind_movie = [i[0] for i in scores]\n",
    "    #возвращаем названия по индексам\n",
    "    return df['title'].iloc[ind_movie]\n",
    "```\n",
    "Например, если мы хотим найти рекомендации по фильму \"Star Trek\", то функция будет выдавать следующий результат:\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "<img src=\"https://lms.skillfactory.ru/assets/courseware/v1/bd77bbe01c25390b5e2d2aa3a3731fad/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/DST_MATH_ML_15_2_6.png\"  width=\"450\" height=\"450\" align=\"left\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ace5ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_sim = linear_kernel(feature_matrix, feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "664a7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(df.index,index=df['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "611f4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    #вычисляем попарные коэффициенты косинусной близости\n",
    "    scores = list(enumerate(cosine_sim[idx]))\n",
    "    #сортируем фильмы на основании коэффициентов косинусной близости по убыванию\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    #выбираем десять наибольших значений косинусной близости; нулевую не берём, т. к. это тот же фильм\n",
    "    scores =   scores[1:11]\n",
    "    #забираем индексы\n",
    "    ind_movie = [i[0] for i in scores]\n",
    "    #возвращаем названия по индексам\n",
    "    return df['title'].iloc[ind_movie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d5c3d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5788             Star Trek: The Next Generation\n",
       "5787                      Star Trek: Enterprise\n",
       "5786                 Star Trek: Deep Space Nine\n",
       "5557                     She's Out of My League\n",
       "134                                  7 Days Out\n",
       "6664                        The Midnight Gospel\n",
       "6023                                     Teresa\n",
       "4863    Pinkfong & Baby Shark's Space Adventure\n",
       "5104                                       Rats\n",
       "5970                             Tales by Light\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"Star Trek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b817d",
   "metadata": {},
   "source": [
    "### Задание 2.3\n",
    "Найдите вторую рекомендацию для детского фильма \"Balto\", вышедшего на экраны в 1995 году:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "294f536e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708    s709\n",
       "Name: show_id, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.title == \"Balto\"].show_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab0a2b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vroomiz'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"Balto\").iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc16840a",
   "metadata": {},
   "source": [
    "## 3. Коллаборативная фильтрация\n",
    "Мы рассмотрели несколько вариантов коллаборативной фильтрации на простейших примерах, и теперь пришло время практики с настоящими данными. Сначала мы будем использовать подход memory-based в модификации item-based, а затем SVD. В результате применения обоих алгоритмов мы сможем сравнить получившееся качество.   \n",
    "В нашей задаче мы будем использовать датасет [movielens](https://lms.skillfactory.ru/assets/courseware/v1/6e47046882bad158b0efbb84cd5cb987/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/u.data.txt), который содержит информацию о фильмах и выставленных рейтингах с сайта https://movielens.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2c3481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые нам компоненты и считаем данные с помощью специального метода Reader:\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.dataset import BUILTIN_DATASETS # с помощью данного объекта мы можем использовать \n",
    "                                              # встроенные датасеты\n",
    "\n",
    "data = Dataset.load_from_file(\n",
    "    \"./data/u.data.txt\",\n",
    "    reader=Reader(line_format=\"user item rating timestamp\", sep=\"\\t\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59165847",
   "metadata": {},
   "source": [
    "Чтобы обучать рекомендательные системы с помощью `surprise`, мы создали объект `Dataset`. Объект `surprise.dataset` — это набор данных, который содержит следующие поля в указанном порядке:\n",
    "* идентификаторы пользователей,\n",
    "* идентификаторы элементов,\n",
    "* соответствующая оценка.   \n",
    "Преобразуем данные к формату `pandas.DataFrame` для удобной работы с ними:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "407658e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.raw_ratings, columns=['userId', 'movieId', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd829f7f",
   "metadata": {},
   "source": [
    "В данных присутствуют следующие признаки:\n",
    "* userId — идентификаторы пользователей сайта movielens;\n",
    "* movieId — идентификаторы фильмов;\n",
    "* rating — оценки фильмов, выставленные пользователями по шкале от 1 до 5;\n",
    "* timestamp — время оценки фильма пользователем. Данный формат представления времени показывает, сколько секунд прошло с 1 января 1970 года."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d4a88",
   "metadata": {},
   "source": [
    "### Задание 3.1\n",
    "Сколько уникальных фильмов в наборе данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "905edc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.movieId.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f0b0c",
   "metadata": {},
   "source": [
    "### Задание 3.2\n",
    "Сколько уникальных пользователей в наборе данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72747565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.userId.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7297f1e4",
   "metadata": {},
   "source": [
    "### Задание 3.3\n",
    "Какая оценка встречается в наборе данных чаще всего? Введите ответ в виде целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02a2d7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating.mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c90f792",
   "metadata": {},
   "source": [
    "Библиотека surprise очень похожа на библиотеку sklearn, и тоже позволяет разбить данные на обучающую и тестовую выборки всего одной функцией — `train_test_split()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4455329",
   "metadata": {},
   "source": [
    "### Задание 3.4\n",
    "Разбейте данные на обучающую и тестовую выборки. Объём тестовой выборки должен составлять 25 % от общего объёма данных. В качестве значения параметра `random_state` возьмите число `13`.\n",
    "\n",
    "Сколько объектов попало в тестовую выборку?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e206f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.25,random_state=13)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd0a27",
   "metadata": {},
   "source": [
    "Импортируем функции для построения рекомендательных систем (`SVD` — для **model-based**-подхода и `KNNBasic` — для **memory-basic**-подхода) и для оценки качества результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "320d94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, KNNBasic, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af22ef50",
   "metadata": {},
   "source": [
    "Теперь реализуем обычную коллаборативную фильтрацию. Выберем оценку схожести через **косинусную близость** и **item-based**-подход:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0140b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False}\n",
    " \n",
    "knn = KNNBasic(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fec94c",
   "metadata": {},
   "source": [
    "Обучим алгоритм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b248927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x2785eb11b20>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c3270",
   "metadata": {},
   "source": [
    "Теперь давайте посмотрим, какие рекомендации мы получили, с помощью следующей программы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d094e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='7', iid='633', r_ui=5.0, est=4.199452349030111, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid='422', iid='287', r_ui=3.0, est=3.4703437660463736, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid='804', iid='163', r_ui=3.0, est=3.5716736533692854, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid='189', iid='480', r_ui=5.0, est=4.222825780855538, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid='238', iid='546', r_ui=3.0, est=3.473417286928204, details={'actual_k': 17, 'was_impossible': False})]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = knn.test(test)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af6dd98",
   "metadata": {},
   "source": [
    "Информация о каждой паре будет содержать следующие характеристики:\n",
    "\n",
    "* uid — id пользователя;\n",
    "* iid — id элемента;\n",
    "* r_ui (float) — реальный рейтинг, который этот пользователь поставил этому элементу;\n",
    "* est (float) — предсказанный рейтинг.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b618a7",
   "metadata": {},
   "source": [
    "### Задание 3.5\n",
    "1. Каков реальный рейтинг, выставленный пользователем с **ID** ***500*** для фильма с **ID** ***699***?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "901512f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.r_ui for x in predictions if (x.uid,x.iid) ==('500','699')][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d8530",
   "metadata": {},
   "source": [
    "2. Каков прогнозируемый рейтинг для пользователя с **ID** ***500*** и фильма с **ID** ***699***? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3aec137f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.47"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = [x.est for x in predictions if (x.uid,x.iid) ==('500','699')][0]\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565389f6",
   "metadata": {},
   "source": [
    "Теперь необходимо вычислить RMSE для получившихся предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4de4dfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0271678039029761"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9bfed",
   "metadata": {},
   "source": [
    "Если округлить результат до сотых, получаем 1.03.\n",
    ">Итак, мы построили систему рекомендаций и даже оценили её качество. Но как же вывести рекомендации для конкретного пользователя?\n",
    "\n",
    "Для начала давайте оформим наши предсказания в таблицу и отсортируем их по прогнозируемому рейтингу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cce055ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],inplace=True,ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260a787c",
   "metadata": {},
   "source": [
    "Теперь мы можем вывести рекомендуемые для конкретного пользователя фильмы, начиная от наиболее релевантного (с точки зрения рекомендаций) и заканчивая наименее релевантным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86313114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['234', '427', '568', '174']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom = pred[pred.uid =='849']['iid'].to_list()\n",
    "recom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13015b59",
   "metadata": {},
   "source": [
    "### Задание 3.6\n",
    "Реализуйте **user-based**-алгоритм. Какое значение **RMSE** получилось для коллаборативной фильтрации типа **user-based**? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81af4c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.02"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True}\n",
    " \n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "knn.fit(train)\n",
    "predictions = knn.test(test)\n",
    "ans = accuracy.rmse(predictions)\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3041341",
   "metadata": {},
   "source": [
    "### Задание 3.7\n",
    "Теперь давайте сравним полученные результаты с результатами **SVD**-алгоритма. Реализуйте **SVD** с параметрами по умолчанию.\n",
    "\n",
    "Какое значение **RMSE** получилось для **SVD**? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66281fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD()\n",
    "\n",
    "svd.fit(train)\n",
    "predictions = svd.test(test)\n",
    "ans = accuracy.rmse(predictions)\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9331fd",
   "metadata": {},
   "source": [
    "## 4. Гибридные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8db3f946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manych\\anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf8118",
   "metadata": {},
   "source": [
    "Работать мы будем с датасетом [goodreads_book](https://lms.skillfactory.ru/assets/courseware/v1/c977535583bf2f85a2d15617e672d8f4/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/Gooddreadbooks.zip).\n",
    "\n",
    "***Goodreads*** — это сайт, на котором люди могут добавлять книги в каталоги, искать их, изучать аннотации и отзывы. Пользователи также могут создавать сообщества, в которых они рекомендуют друг другу различную литературу, ведут блоги и устраивают обсуждения.\n",
    "\n",
    "Подгрузим все файлы, относящиеся к этому набору данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a32af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('./data/ratings.csv') #поставленные оценки\n",
    "books = pd.read_csv('./data/books.csv') #информация о книгах\n",
    "tags = pd.read_csv('./data/tags.csv') #информация о тегах\n",
    "book_tags = pd.read_csv('./data/book_tags.csv') #книги с тегами "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1849f2",
   "metadata": {},
   "source": [
    "Сначала посмотрим на набор данных **books**: в этих данных есть обычный **id** книги, а есть **id** книги в системе **Goodreads** — этот **id** отображён в признаке `goodreads_book_id`. В других данных (**book_tags**) указан только **id** книги в системе **Goodreads**, поэтому нам необходимо добавить туда обычный **id**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa48497a",
   "metadata": {},
   "source": [
    "### Задание 4.1\n",
    "Добавьте в набор данных **book_tags** признак с обычным **id** книги, используя соответствие обычного **id** и **id** в системе **Goodreads**.\n",
    "\n",
    "Какой обычный **id** у книги, которая имеет **id** 5 в системе **Goodreads**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32952194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# book_tags = book_tags.merge(books[[\"book_id\",\"goodreads_book_id\"]],on=\"goodreads_book_id\")\n",
    "to_map = dict(zip(books.goodreads_book_id, books.book_id))\n",
    "book_tags[\"book_id\"] = book_tags.goodreads_book_id.map(to_map)\n",
    "\n",
    "to_map[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b853f616",
   "metadata": {},
   "source": [
    "### Задание 4.2\n",
    "Далее нам необходимо оставить в наборе данных **book_tags** только те записи, теги для которых есть в данных **tags**.\n",
    "\n",
    "Отфильтруйте данные таким образом, чтобы в наборе данных **book_tag**s остались только те строки, в которых находятся теги, информация о которых есть в наборе данных **tags**.\n",
    "\n",
    "Сколько объектов осталось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "113fa68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300738"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_tags = book_tags[book_tags.tag_id.isin(tags.tag_id)]\n",
    "book_tags.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef073cb",
   "metadata": {},
   "source": [
    "Отлично, мы подготовили информацию о тегах книг — это будет метаинформацией для построения рекомендательной системы. Теперь нам необходимо подготовить данные о взаимодействии пользователей и книг. Для этого нам понадобится файл **ratings**.\n",
    "\n",
    "Оба набора данных (и про взаимодействия, и про метаинформацию) необходимо преобразовать в разрежённые матрицы. Это можно сделать с помощью специальной функции из модуля `scipy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88fb1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35bcdd",
   "metadata": {},
   "source": [
    "Осуществляем преобразование следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3caba849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# передаём в качестве аргументов в функцию выставленный рейтинг (это будут значения матрицы), \n",
    "# а также id пользователя и id книги (это будут индексы для строк и столбцов матрицы)\n",
    "ratings_matrix = csr_matrix((ratings.rating,(ratings.user_id,ratings.book_id))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4198ff",
   "metadata": {},
   "source": [
    "Теперь нам необходимо составить матрицу с метаданными. В качестве индексов будут выступать id книги и id тега, и если у этой книги есть рассматриваемый тег, то на пересечении соответствующих строки и столбца будет выставлена единица."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8315f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_matrix  = csr_matrix(([1]*len(book_tags),(book_tags.book_id,book_tags.tag_id))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b4c857",
   "metadata": {},
   "source": [
    "### Задание 4.4\n",
    "Давайте проверим, что всё получилось правильно.\n",
    "\n",
    "Каково среднее арифметическое значений разрежённой матрицы с рейтингами? Ответ округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "998417db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = ratings_matrix.mean()\n",
    "round(ans,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29429014",
   "metadata": {},
   "source": [
    "Отлично, данные подготовлены — теперь настало время определить модель, которую мы будем использовать. Сделаем это следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ded96a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(loss='warp', #определяем функцию потерь\n",
    "                random_state=13, #фиксируем случайное разбиение\n",
    "                learning_rate=0.05, #темп обучения\n",
    "                no_components=100) #размерность вектора для представления данных в модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9155f2",
   "metadata": {},
   "source": [
    "В качестве функции потерь мы выбрали значение 'warp', хотя, разумеется, это не единственный вариант. В модуле LightFM представлены следующие функции потерь:\n",
    "\n",
    "* 'logistic' — логистическая функция. Полезна в случаях, когда есть как положительные, так и отрицательные взаимодействия, например 1 и -1.\n",
    "* 'bpr' — байесовский персонализированный рейтинг. Можно применять, когда присутствуют только положительные взаимодействия.\n",
    "* 'warp' — парный взвешенный приблизительный ранг. Используется, если необходимо повысить качество именно в верхней части списка рекомендаций.\n",
    "* 'warp-kos' — модификация warp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16226dd5",
   "metadata": {},
   "source": [
    "Разобьём данные на обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba603c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = random_train_test_split(ratings_matrix, test_percentage=0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c177f9",
   "metadata": {},
   "source": [
    "Теперь обучим модель на наших данных о взаимодействии, также используя метаданные о книгах:\n",
    ">Обратите внимание: из-за трудоёмкости вычислений обучение модели и оценка качества могут занимать вплоть до 15-20 минут (зависит от мощности компьютера). Не волнуйтесь, это нормальная ситуация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fee118c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = model.fit(train, item_features = meta_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef15d64",
   "metadata": {},
   "source": [
    "### Задание 4.5\n",
    "Оцените качество полученной модели с помошью функции `precision_at_k`, передав в неё три аргумента: **модель**, **тестовые данные** и **обозначение метаданных** `(item_features = meta_matrix)`.\n",
    "\n",
    "Выведите среднее арифметическое и округлите его до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64041d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prec_k = precision_at_k(model,\n",
    "                        test,\n",
    "                        item_features = meta_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37a7b29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017568793"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = prec_k.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea92795",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d49016",
   "metadata": {},
   "source": [
    "## 5. Современные методы: глубокое обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cfd9f7",
   "metadata": {},
   "source": [
    "Мы будем использовать модуль tensorflow, в котором реализовано много полезных методов для имплементации (внедрения) нейронных сетей.\n",
    "\n",
    "Для начала импортируем из него функции, которые понадобятся нам для решения задачи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc0c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe23dbd",
   "metadata": {},
   "source": [
    "Мы будем использовать данные из предыдущего юнита, но лишь те, которые содержат информацию об оценках, выставленных книгам пользователями. Загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1f921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526fa29",
   "metadata": {},
   "source": [
    "### Задание 5.1\n",
    "Разбейте данные на обучающую и тестовую выборки в отношении 4:1. В качестве значения параметра `random_state` возьмите число `42`.\n",
    "\n",
    "Сколько объектов теперь находится в обучающей выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a36a036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785404"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b2e18",
   "metadata": {},
   "source": [
    "### Задание 5.2\n",
    "Сколько в наборе данных уникальных книг?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72135b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_books = df.book_id.nunique()\n",
    "n_books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085bcc29",
   "metadata": {},
   "source": [
    "### Задание 5.3\n",
    "Сколько в наборе данных уникальных пользователей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "116428a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53424"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = df.user_id.nunique()\n",
    "n_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf8522",
   "metadata": {},
   "source": [
    "В первую очередь нам необходимо создать эмбеддинги для книг и пользователей. Создаём эмбеддинги для книг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "582d3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_input = Input(shape=[1], name=\"Book-Input\")\n",
    "book_embedding = Embedding(n_books+1, 5, name=\"Book-Embedding\")(book_input)\n",
    "book_vec = Flatten(name=\"Flatten-Books\")(book_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5324b15",
   "metadata": {},
   "source": [
    "Сначала мы задаём [размерность входного слоя][1]. После этого определяем размер эмбеддинга — в данном случае снижаем размерность до 5. Далее мы разворачиваем результат в массив с одним измерением с помощью слоя `Flatten()`.\n",
    "\n",
    "[1]:: \"В этом параметре максимальное значение всегда равно длинне вектора + 1\"\n",
    "\n",
    "Делаем то же самое для пользователей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24416061",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users+1, 5, name=\"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e6c72",
   "metadata": {},
   "source": [
    "Теперь, когда мы создали представления как для книг, так и для пользователей, нам необходимо соединить их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3f48f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = Concatenate()([book_vec, user_vec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b369cb9a",
   "metadata": {},
   "source": [
    "Далее начинаем «собирать» нашу нейронную сеть из слоёв. `Dense` обозначает полносвязный слой. Также мы обозначаем для него [количество нейронов][1] и [данные][2], которые идут на вход.\n",
    "\n",
    "[1]:: \"В первом слое будет 128 нейронов, на втором - 32, на последенм(выходном) -1\"\n",
    "[2]:: \"На первом слое принимаются данные от соединенных эмбендингов, на втором данные от первого слоя, на последнем - данные от второго\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d120a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = Dense(128, activation='relu')(conc)\n",
    "fc2 = Dense(32, activation='relu')(fc1)\n",
    "out = Dense(1)(fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6d23c",
   "metadata": {},
   "source": [
    "Собираем модель — передаём входные данные для книг и пользователей, а также архитектуру нейронной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1534934",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model([user_input, book_input], out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0851625a",
   "metadata": {},
   "source": [
    "Также нам необходимо задать алгоритм оптимизации и метрику, которую мы будем оптимизировать. В данном случае будем использовать метод [adam][1] и хорошо известную вам среднеквадратичную ошибку:\n",
    "\n",
    "[1]:: \"Это одна из вариаций градиентного спуска\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06378d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer = 'adam',loss =  'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1f465",
   "metadata": {},
   "source": [
    "Теперь будем обучать нашу модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf7738fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24544/24544 [==============================] - 123s 5ms/step - loss: 0.7950\n",
      "Epoch 2/5\n",
      "24544/24544 [==============================] - 128s 5ms/step - loss: 0.6865\n",
      "Epoch 3/5\n",
      "24544/24544 [==============================] - 142s 6ms/step - loss: 0.6549\n",
      "Epoch 4/5\n",
      "24544/24544 [==============================] - 136s 6ms/step - loss: 0.6314\n",
      "Epoch 5/5\n",
      "24544/24544 [==============================] - 145s 6ms/step - loss: 0.6127\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit([train.user_id, train.book_id], train.rating, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff85dd5",
   "metadata": {},
   "source": [
    "В параметр эпох передаём значение 5: у нас будет реализовано пять эпох — пять обучений нейронной сети. На каждой из эпох обновляются веса для минимизации ошибки.\n",
    "\n",
    "Теперь можно оценить качество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9b067de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136/6136 [==============================] - 15s 2ms/step - loss: 0.7091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7090549468994141"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate([test.user_id, test.book_id], test.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d707e6d6",
   "metadata": {},
   "source": [
    ">Примечание. К сожалению, результаты этого алгоритма нельзя зафиксировать стандартным ramdom_state, к которому мы привыкли: применяемые методы не используют такой параметр. Поэтому мы опустим здесь сравнение результатов, однако посмотрим, как можно настроить нейронную сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d19ce45",
   "metadata": {},
   "source": [
    "Обычно для улучшения качества модели каким-то образом модифицируют нейронную сеть: дополняют её, увеличивают время обучения. Добавим ещё один полносвязный слой с восемью нейронами после полносвязного слоя с 32 нейронами. Обучим нейронную сеть, реализовав десять эпох:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f9c6f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24544/24544 [==============================] - 123s 5ms/step - loss: 0.6247\n",
      "Epoch 2/10\n",
      "24544/24544 [==============================] - 146s 6ms/step - loss: 0.5843\n",
      "Epoch 3/10\n",
      "24544/24544 [==============================] - 150s 6ms/step - loss: 0.5638\n",
      "Epoch 4/10\n",
      "24544/24544 [==============================] - 148s 6ms/step - loss: 0.5449\n",
      "Epoch 5/10\n",
      "24544/24544 [==============================] - 148s 6ms/step - loss: 0.5292\n",
      "Epoch 6/10\n",
      "24544/24544 [==============================] - 132s 5ms/step - loss: 0.5160\n",
      "Epoch 7/10\n",
      "24544/24544 [==============================] - 125s 5ms/step - loss: 0.5051\n",
      "Epoch 8/10\n",
      "24544/24544 [==============================] - 125s 5ms/step - loss: 0.4962\n",
      "Epoch 9/10\n",
      "24544/24544 [==============================] - 138s 6ms/step - loss: 0.4809\n",
      "6136/6136 [==============================] - 21s 3ms/step - loss: 0.7755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7754535675048828"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1 = Dense(128, activation='relu')(conc)\n",
    "fc2 = Dense(32, activation='relu')(fc1)\n",
    "fc3 = Dense(8, activation='relu')(fc2)\n",
    "out = Dense(1)(fc3)\n",
    "\n",
    "model2 = Model([user_input, book_input], out)\n",
    "model2.compile('adam', 'mean_squared_error')\n",
    "result = model2.fit([train.user_id, train.book_id], train.rating, epochs=10, verbose=1)\n",
    "model2.evaluate([test.user_id, test.book_id], test.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd543a63",
   "metadata": {},
   "source": [
    "## 6. Практика\n",
    "Итак, вы познакомились с основными методами построения рекомендательных систем, и теперь настало время закрепить полученные знания на практике. В предыдущем модуле мы начали строить РС для сервиса чтения статей **CI&T DeskDrop**. В этом юните мы продолжим работу над ней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c88df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.read_csv(\"./data/shared_articles.csv\")\n",
    "df_interactions = pd.read_csv(\"./data/users_interactions.csv\")\n",
    "# приведем id к типу str - экономим память.\n",
    "df_interactions.personId = df_interactions.personId.astype(str)\n",
    "df_interactions.contentId = df_interactions.contentId.astype(str)\n",
    "df_articles.contentId = df_articles.contentId.astype(str)\n",
    "# Отфильтруем данные так, чтобы остались только объекты с типом события CONTENT SHARED.\n",
    "shared_mask = df_articles.eventType == 'CONTENT SHARED'\n",
    "df_shar_articles = df_articles[shared_mask]\n",
    "# признак, который будет отражать числовой вес для взаимодействия со статьёй в соответствии \n",
    "# с приведёнными весами)\n",
    "event_type = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}\n",
    "df_interactions['weighted_eventType'] = df_interactions.eventType.map(event_type)\n",
    "# оставим только тех пользователей, которые взаимодействовали хотя бы с пятью статьями\n",
    "activity_mask = df_interactions.groupby('personId').contentId.nunique()>4\n",
    "active_person = df_interactions.groupby('personId').contentId.count().index[activity_mask].to_list()\n",
    "df_interactions = df_interactions[df_interactions.personId.isin(active_person)]\n",
    "# логарифмирование суммы весов для взаимодействия пользователя с каждой конкретной статьёй\n",
    "# также сохраним для каждой пары «пользователь — статья» значение времени последнего взаимодействия\n",
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "cum_weighted_event = df_interactions.groupby(['personId','contentId']).\\\n",
    "                        weighted_eventType.sum().apply(smooth_user_preference).reset_index()\n",
    "last_interaction = df_interactions.groupby(['personId','contentId']).timestamp.last().\\\n",
    "                        reset_index().rename(columns={'timestamp':'last_timestamp'})\n",
    "cum_weighted_event = cum_weighted_event.merge(last_interaction,on=['personId','contentId'])\n",
    "# разделим данные на обучающую и тестовую выборки\n",
    "split_timestamp = 1475519545\n",
    "split_mask = cum_weighted_event.last_timestamp < split_timestamp\n",
    "\n",
    "train = cum_weighted_event[split_mask].copy()\n",
    "test = cum_weighted_event[~split_mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1599a022",
   "metadata": {},
   "source": [
    "Для начала необходимо построить матрицу, в которой по столбцам будут находиться `id статей`, по строкам — `id пользователей`, а на пересечениях строк и столбцов — оценка взаимодействия пользователя со статьёй. Если взаимодействия не было, в соответствующей ячейке должен стоять ноль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac805a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.pivot_table(\n",
    "    train,\n",
    "    values='weighted_eventType',\n",
    "    index='personId',\n",
    "    columns='contentId').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ada639",
   "metadata": {},
   "source": [
    "### Задание 6.1\n",
    "Найдите оценку взаимодействия пользователя с `ID` -1032019229384696495 со статьёй с `ID` 943818026930898372. Результат округлите до двух знаков после точки-разделителя.\n",
    "\n",
    ">Примечание. Здесь и далее (пока не будет указано иное) необходимо работать с обучающей выборкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36271a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = interactions.loc[\"-1032019229384696495\",\"943818026930898372\"]\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa2c7c",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем применить memory-based-подход коллаборативной фильтрации.\n",
    "\n",
    ">Примечание. Данных достаточно много, поэтому для увеличения скорости работы преобразуйте таблицу в массив numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d2c1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_np = interactions.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe556f0",
   "metadata": {},
   "source": [
    "### Задание 6.2\n",
    "Найдите среднее арифметическое всех чисел в получившемся массиве. Результат округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1464a860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = interactions_np.mean()\n",
    "round(ans,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa5ec5",
   "metadata": {},
   "source": [
    ">Перейдём к реализации коллаборативной фильтрации. Ранее мы делали это с помощью библиотеки surprise, однако это не всегда удобно, так как эта библиотека имеет ограниченное количество метрик для оценки качества и небольшой потенциал для более тонкой настройки алгоритма. Поэтому давайте попробуем реализовать алгоритмы коллаборативной фильтрации «с нуля». Такая практика применяется, если необходимо выстроить более сложную систему, чем могут предложить готовые модули. Кроме того, «ручная» реализация алгоритмов позволит лучше понять принцип их работы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936d607",
   "metadata": {},
   "source": [
    "### Задание 6.3\n",
    "Постройте матрицу схожести. Для этого вычислите все попарные коэффициенты корреляции для матрицы, полученной в предыдущем задании. Для каждой пары учитывайте только ненулевые значения (так как нулевые обозначают отсутствие взаимодействия и не интересуют нас). Выведите результат, полученный в ячейке с третьим индексом по строкам и сороковым — по столбцам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28901b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manych\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\Manych\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.33"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "size = len(interactions_np)\n",
    "similarity_users = np.zeros((size, size))\n",
    "\n",
    "for i in (range(size-1)):\n",
    "    for j in range(i+1, size):\n",
    "        mask_uv = (interactions_np[i] != 0) & (interactions_np[j] != 0)\n",
    "        if mask_uv.sum() > 1:\n",
    "            interactions_v = interactions_np[i, mask_uv]\n",
    "            interactions_u = interactions_np[j, mask_uv]\n",
    "            similarity_users[i,j] = np.corrcoef(interactions_v, interactions_u)[0, 1]\n",
    "            similarity_users[j,i] = similarity_users[i,j]\n",
    "\n",
    "ans = similarity_users[3,40]\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0405d83",
   "metadata": {},
   "source": [
    "Теперь у нас есть матрицы схожести пользователей. Их можно использовать для построения рекомендаций. Чтобы это сделать, надо реализовать следующий алгоритм.\n",
    "\n",
    ">Для каждого пользователя:   \n",
    ">    \n",
    ">1. Найти пользователей с похожестью больше 0.   \n",
    "2. Для каждой статьи вычислить долю пользователей (среди выделенных на первом шаге), которые взаимодействовали со статьёй.   \n",
    "3. Порекомендовать статьи с наибольшими долями со второго шага (среди тех, которые пользователь ещё не видел)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25212351",
   "metadata": {},
   "source": [
    "### Задание 6.4\n",
    "Постройте рекомендательную систему по алгоритму, описанному выше. Найдите первую рекомендацию для строки 35 (если считать с нуля)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8490be5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>contentId</th>\n",
       "      <th>-1006791494035379303</th>\n",
       "      <th>-1021685224930603833</th>\n",
       "      <th>-1022885988494278200</th>\n",
       "      <th>-1024046541613287684</th>\n",
       "      <th>-1033806831489252007</th>\n",
       "      <th>-1038011342017850</th>\n",
       "      <th>-1039912738963181810</th>\n",
       "      <th>-1046621686880462790</th>\n",
       "      <th>-1051830303851697653</th>\n",
       "      <th>-1055630159212837930</th>\n",
       "      <th>...</th>\n",
       "      <th>9217155070834564627</th>\n",
       "      <th>921770761777842242</th>\n",
       "      <th>9220445660318725468</th>\n",
       "      <th>9222265156747237864</th>\n",
       "      <th>943818026930898372</th>\n",
       "      <th>957332268361319692</th>\n",
       "      <th>966067567430037498</th>\n",
       "      <th>972258375127367383</th>\n",
       "      <th>980458131533897249</th>\n",
       "      <th>98528655405030624</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1007001694607905623</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1032019229384696495</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-108842214936804958</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1130272294246983140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1160159014793528221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "contentId             -1006791494035379303  -1021685224930603833  \\\n",
       "personId                                                           \n",
       "-1007001694607905623                   0.0                   0.0   \n",
       "-1032019229384696495                   1.0                   0.0   \n",
       "-108842214936804958                    0.0                   0.0   \n",
       "-1130272294246983140                   0.0                   0.0   \n",
       "-1160159014793528221                   0.0                   0.0   \n",
       "\n",
       "contentId             -1022885988494278200  -1024046541613287684  \\\n",
       "personId                                                           \n",
       "-1007001694607905623                   0.0                   0.0   \n",
       "-1032019229384696495                   0.0                   0.0   \n",
       "-108842214936804958                    0.0                   0.0   \n",
       "-1130272294246983140                   0.0                   0.0   \n",
       "-1160159014793528221                   0.0                   0.0   \n",
       "\n",
       "contentId             -1033806831489252007  -1038011342017850  \\\n",
       "personId                                                        \n",
       "-1007001694607905623                   0.0                0.0   \n",
       "-1032019229384696495                   0.0                0.0   \n",
       "-108842214936804958                    0.0                0.0   \n",
       "-1130272294246983140                   0.0                0.0   \n",
       "-1160159014793528221                   0.0                0.0   \n",
       "\n",
       "contentId             -1039912738963181810  -1046621686880462790  \\\n",
       "personId                                                           \n",
       "-1007001694607905623                   0.0                   0.0   \n",
       "-1032019229384696495                   1.0                   0.0   \n",
       "-108842214936804958                    0.0                   0.0   \n",
       "-1130272294246983140                   0.0                   0.0   \n",
       "-1160159014793528221                   0.0                   0.0   \n",
       "\n",
       "contentId             -1051830303851697653  -1055630159212837930  ...  \\\n",
       "personId                                                          ...   \n",
       "-1007001694607905623                   0.0                   0.0  ...   \n",
       "-1032019229384696495                   0.0                   0.0  ...   \n",
       "-108842214936804958                    0.0                   0.0  ...   \n",
       "-1130272294246983140                   0.0                   0.0  ...   \n",
       "-1160159014793528221                   0.0                   0.0  ...   \n",
       "\n",
       "contentId             9217155070834564627  921770761777842242  \\\n",
       "personId                                                        \n",
       "-1007001694607905623                  0.0                 0.0   \n",
       "-1032019229384696495                  3.0                 0.0   \n",
       "-108842214936804958                   0.0                 0.0   \n",
       "-1130272294246983140                  0.0                 0.0   \n",
       "-1160159014793528221                  0.0                 0.0   \n",
       "\n",
       "contentId             9220445660318725468  9222265156747237864  \\\n",
       "personId                                                         \n",
       "-1007001694607905623                  0.0                  0.0   \n",
       "-1032019229384696495                  0.0                  0.0   \n",
       "-108842214936804958                   0.0                  0.0   \n",
       "-1130272294246983140                  0.0                  0.0   \n",
       "-1160159014793528221                  0.0                  0.0   \n",
       "\n",
       "contentId             943818026930898372  957332268361319692  \\\n",
       "personId                                                       \n",
       "-1007001694607905623            0.000000                 0.0   \n",
       "-1032019229384696495            2.321928                 0.0   \n",
       "-108842214936804958             0.000000                 0.0   \n",
       "-1130272294246983140            1.000000                 0.0   \n",
       "-1160159014793528221            0.000000                 0.0   \n",
       "\n",
       "contentId             966067567430037498  972258375127367383  \\\n",
       "personId                                                       \n",
       "-1007001694607905623                 0.0                 0.0   \n",
       "-1032019229384696495                 0.0                 0.0   \n",
       "-108842214936804958                  2.0                 0.0   \n",
       "-1130272294246983140                 0.0                 0.0   \n",
       "-1160159014793528221                 0.0                 0.0   \n",
       "\n",
       "contentId             980458131533897249  98528655405030624  \n",
       "personId                                                     \n",
       "-1007001694607905623                 0.0                0.0  \n",
       "-1032019229384696495                 0.0                0.0  \n",
       "-108842214936804958                  0.0                0.0  \n",
       "-1130272294246983140                 0.0                0.0  \n",
       "-1160159014793528221                 0.0                0.0  \n",
       "\n",
       "[5 rows x 2366 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_user_based = []\n",
    "for i in range(len(similarity_users)):\n",
    "    users_similarity_mask = similarity_users[i]>0\n",
    "    \n",
    "    \n",
    "    aa = interactions_np[users_similarity_mask].sum(axis=1)[::-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e89ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_similar = np.zeros_like(interactions_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "99de5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# j = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b8f8178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([943.15154013, 320.8590133 , 169.85288121,  86.6795587 ,\n",
       "       176.77799869, 312.17977974, 358.08546689, 104.7695987 ])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4\n",
    "users_similarity_mask = similarity_users[i]>0\n",
    "interactions_np[users_similarity_mask].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "98d81bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1.0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_similarity_mask = similarity_users[i]>0\n",
    "popularity_similar[i,j] = (interactions_np[users_similarity_mask,j]>0).sum()\n",
    "(interactions_np[users_similarity_mask,j]>0).sum(),popularity_similar[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9e4196d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_similar[i,j] = (interactions_np[users_similarity_mask,j]>0).sum()\n",
    "aa = np.array(\n",
    "    [(interactions_np[users_similarity_mask,x]>0).sum() \n",
    "    for x in range(interactions_np.shape[1])])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "00c6f4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([943.15154013, 320.8590133 , 169.85288121,  86.6795587 ,\n",
       "       176.77799869, 312.17977974, 358.08546689, 104.7695987 ])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa#.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff99db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e955a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar_users = interactions.index[similarity_mask]\n",
    "# similar_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aceb163",
   "metadata": {},
   "source": [
    "## =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db992dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://more.tv/gosti_iz_proshlogo/1_sezon/9_seriya"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
