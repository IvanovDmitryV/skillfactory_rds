{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1644f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import ndcg_score, dcg_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32df05",
   "metadata": {},
   "source": [
    "## 4. Метрики в рекомендательных системах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa38a65",
   "metadata": {},
   "source": [
    "### Задание 4.5\n",
    "Пусть у нас есть реальные оценки, выставленные пользователем, и предсказанные оценки:\n",
    "\n",
    "Реальные оценки: [2, 4, 1, 1, 1]    \n",
    "Предсказанные оценки: [2, 5, 2, 3, 1]    \n",
    "Вычислите коэффициент **NDCG**. Округлите результат до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df2fbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = np.asarray([[2, 4, 1, 1, 1] ])\n",
    "relevance = np.asarray([[2, 5, 2, 3, 1]])\n",
    "\n",
    "ans = ndcg_score(true, relevance)\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611e232",
   "metadata": {},
   "source": [
    "## 5. Проблема холодного старта и popularity-based model\n",
    "    \n",
    "Мы будем работать с набором данных Movie Lens. Он содержит идентификаторы для каждого фильма и пользователя, который его смотрел, а также оценку, которую пользователь поставил фильму. В датасете представлено 25 000 095 оценок фильмов от 162 541 пользователя со шкалой оценок от 0.5 до 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a8ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('./data/dst-3.0_mathml_14_5_rating.csv')\n",
    "movies = pd.read_csv('./data/movie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b962ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "      <td>City of Lost Children, The (Cité des enfants p...</td>\n",
       "      <td>Adventure|Drama|Fantasy|Mystery|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "      <td>Twelve Monkeys (a.k.a. 12 Monkeys) (1995)</td>\n",
       "      <td>Mystery|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp  \\\n",
       "0       1        2     3.5  2005-04-02 23:53:47   \n",
       "1       1       29     3.5  2005-04-02 23:31:16   \n",
       "2       1       32     3.5  2005-04-02 23:33:39   \n",
       "3       1       47     3.5  2005-04-02 23:32:07   \n",
       "4       1       50     3.5  2005-04-02 23:29:40   \n",
       "\n",
       "                                               title  \\\n",
       "0                                     Jumanji (1995)   \n",
       "1  City of Lost Children, The (Cité des enfants p...   \n",
       "2          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n",
       "3                        Seven (a.k.a. Se7en) (1995)   \n",
       "4                         Usual Suspects, The (1995)   \n",
       "\n",
       "                                   genres  \n",
       "0              Adventure|Children|Fantasy  \n",
       "1  Adventure|Drama|Fantasy|Mystery|Sci-Fi  \n",
       "2                 Mystery|Sci-Fi|Thriller  \n",
       "3                        Mystery|Thriller  \n",
       "4                  Crime|Mystery|Thriller  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.merge(ratings,movies, how='left',on='movieId')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc7acfa",
   "metadata": {},
   "source": [
    "Признаки в данных\n",
    "- userId — id пользователя;\n",
    "- movieId — id фильма;\n",
    "- rating — выставленный пользователем рейтинг для фильма;\n",
    "- timestamp — время выставления рейтинга;\n",
    "- title — название фильма;\n",
    "- genres — жанры, к которым относится фильм."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d315ca",
   "metadata": {},
   "source": [
    "### Задание 5.1\n",
    "Подсчитайте, сколько раз каждый фильм встречается в наборе данных. Отметьте среди перечисленных ниже фильмов те, что встречаются в топ-5 по популярности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2de5368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulp Fiction (1994)\n",
      "Forrest Gump (1994)\n",
      "Shawshank Redemption, The (1994)\n",
      "Silence of the Lambs, The (1991)\n",
      "Jurassic Park (1993)\n"
     ]
    }
   ],
   "source": [
    "print(*df.title.value_counts().index[:5],sep='\\n')\n",
    "# cnt = Counter(df.title)\n",
    "# cnt.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027ea5e0",
   "metadata": {},
   "source": [
    "### Задание 5.2\n",
    "Отлично, мы нашли самые востребованные фильмы. Однако если фильм посмотрело много людей, это ещё не значит, что он им понравился. Чтобы понять, как зритель на самом деле относится к фильму, нужны более чёткие данные. К счастью, в наборе данных Movie Lens есть оценки каждого из зрителей.\n",
    "\n",
    "- Найдите средний рейтинг для каждого из фильмов.\n",
    "- Найдите фильмы с наивысшим средним рейтингом.\n",
    "- Введите в качестве ответа фильм, занимающий последнее место среди фильмов с наивысшим рейтингом, если предварительно отсортировать их по алфавитному порядку.   \n",
    "    \n",
    "Впишите только название фильма, без кавычек и без года выхода на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0fca45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yonkers Joe (2008)\n"
     ]
    }
   ],
   "source": [
    "sorted_by_rating = df.groupby('title').rating.mean().sort_values(ascending=False)\n",
    "top_films_title = sorted_by_rating[sorted_by_rating==5].index\n",
    "ans = top_films_title.sort_values()[-1]\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8638b1",
   "metadata": {},
   "source": [
    "### Задание 5.3\n",
    "В двух предыдущих заданиях вы использовали два самых простых метода для создания неперсонализированных рекомендаций. Однако у них обоих есть свои недостатки: поиск наиболее часто просматриваемых фильмов не учитывает того, насколько фильм нравится аудитории, а поиск среднего рейтинга может вывести в рекомендуемые фильмы малоизвестные специфические картины с одной-двумя оценками.\n",
    "\n",
    "Чтобы решить эти проблемы, объединим два подхода и будем искать средний рейтинг только для фильмов, которые были оценены более 50 раз.\n",
    "\n",
    "Сколько таких фильмов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caab164e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10472"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (df.movieId.value_counts()>50).sum()\n",
    "(df.title.value_counts()>50).sum()\n",
    "\n",
    "# mask = (df.groupby('title').movieId.nunique() > 1)\n",
    "# df.groupby('title').movieId.unique()[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aebf997",
   "metadata": {},
   "source": [
    "### Задание 5.4\n",
    "Постройте простейшую рекомендацию: возьмите фильмы, которые смотрели более 50 раз, и найдите среди них фильм с наивысшей оценкой. В качестве ответа запишите название этого фильма без артикля и года выхода на экран.\n",
    "Если название фильма состоит из двух и более слов, между отдельными словами должен быть только один пробел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22edf5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shawshank Redemption, The (1994)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_films = df.title.value_counts().index[df.title.value_counts()>50].tolist()\n",
    "pop_films_mask = df.title.isin(pop_films)\n",
    "df[pop_films_mask].groupby('title').rating.mean().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c779cc",
   "metadata": {},
   "source": [
    "## 6. Практика\n",
    "В этом юните мы построим систему рекомендаций, основываясь именно на этом методе. Вы сможете усовершенствовать её в следующем модуле, после того как освоите другие алгоритмы.   \n",
    "    \n",
    "Для начала загрузим датасет [\"Articles sharing and reading from CI&T DeskDrop\"](https://www.kaggle.com/datasets/gspmoreira/articles-sharing-reading-from-cit-deskdrop), включающий в себя собранные за один год логи ***DeskDrop*** — платформы для внутренних коммуникаций, разработанной ***CI&T*** и ориентированной на компании, использующие ***Google Workspace*** (***Google G Suite***). Среди прочего, эта платформа позволяет сотрудникам компаний делиться актуальными статьями со своими коллегами.\n",
    "\n",
    "В датасете содержится около 73 тысяч записей о взаимодействии пользователей с более чем тремя тысячами публичных статей, размещённых на платформе.\n",
    "\n",
    "Информация в наборе данных:\n",
    "- Оригинальный URL, название и текст статьи.\n",
    "- Контекст посещений пользователей, например дата/время, клиент (мобильное приложение/браузер) и геолокация.\n",
    "- Различные типы взаимодействия, что позволяет сделать вывод об уровне заинтересованности пользователя в статьях, например комментарии → лайки → просмотры.    \n",
    "    \n",
    "Данные включают в себя два файла:   \n",
    "   \n",
    "[shared_articles.csv](https://lms.skillfactory.ru/assets/courseware/v1/9f0e8eb4ddd03415fdd4db4a89a2b0d3/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/shared_articles.zip);   \n",
    "[users_interactions.csv.](https://lms.skillfactory.ru/assets/courseware/v1/186647c8bd3fdb43b78fbc84ace97aed/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/users_interactions.zip)    \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8b8e46",
   "metadata": {},
   "source": [
    "Начнём работать с файлом `shared_articles.csv`. Он содержит информацию о статьях, опубликованных на платформе ***DeskDrop***.\n",
    "\n",
    "Для каждой статьи есть:\n",
    "* дата публикации (временная метка),\n",
    "* исходный URL-адрес,\n",
    "* заголовок,\n",
    "* содержание в виде обычного текста,\n",
    "* язык статьи (португальский — pt или английский — en),\n",
    "* информация о пользователе, который поделился статьёй (автор).   \n",
    "    \n",
    "Для временной метки существует два возможных типа событий:   \n",
    "CONTENT SHARED — статья была опубликована на платформе и доступна для пользователей;\n",
    "CONTENT REMOVED — статья была удалена с платформы и недоступна для дальнейших рекомендаций.   \n",
    "    \n",
    "Для простоты мы рассматриваем здесь только тип события **CONTENT SHARED**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41b45ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.read_csv(\"./data/shared_articles.csv\")\n",
    "df_interactions = pd.read_csv(\"./data/users_interactions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1b992",
   "metadata": {},
   "source": [
    "### Задание 6.1\n",
    "Отфильтруйте данные так, чтобы остались только объекты с типом события CONTENT SHARED. Сколько таких объектов в получившейся таблице?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f914ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3047"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_mask = df_articles.eventType == 'CONTENT SHARED'\n",
    "df_shar_articles = df_articles[shared_mask]\n",
    "\n",
    "df_shar_articles.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c7583",
   "metadata": {},
   "source": [
    "Теперь откроем второй файл — `users_interactions.csv`.\n",
    "\n",
    "В колонке `eventType` описаны действия, которые могли совершать пользователи при взаимодействии со статьёй:\n",
    "* VIEW — просмотр,\n",
    "* LIKE — лайк,\n",
    "* COMMENT CREATED — комментарий,\n",
    "* FOLLOW — подписка,\n",
    "* BOOKMARK — добавление в закладки.   \n",
    "    \n",
    "В первую очередь нам необходимо понять, как определить, что какая-то статья популярнее других. Если бы из возможных реакций у нас были только лайки или только просмотры, то статьи было бы легко ранжировать в соответствии с этими значениями. Однако у нас есть информация о различных действиях пользователя, и на её основе мы должны создать некий универсальный индекс популярности. Составим его из реакций пользователей, придав им разные веса:\n",
    "```python\n",
    "event_type = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}\n",
    "```\n",
    "Веса здесь подобраны исходя из важности каждого действия: оставить комментарий — значит, показать наибольшую вовлечённость, а обычный просмотр, напротив, демонстрирует наименьшую вовлечённость."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c01bee5",
   "metadata": {},
   "source": [
    "### Задание 6.2\n",
    "Создайте признак, который будет отражать числовой вес для взаимодействия со статьёй (в соответствии с приведёнными выше весами). Вычислите среднее значение для полученного признака. Округлите его до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aba67454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.24"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_type = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}\n",
    "\n",
    "df_interactions['weighted_eventType'] = df_interactions.eventType.map(event_type)\n",
    "ans = df_interactions.weighted_eventType.mean()\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f270f1",
   "metadata": {},
   "source": [
    "Ранее мы говорили, что рекомендательные системы подвержены проблеме холодного старта — в таких случаях создавать рекомендации намного сложнее.\n",
    "\n",
    "### Задание 6.3\n",
    "Чтобы получить хоть какую-то информацию, на которую можно будет опираться, оставьте только тех пользователей, которые взаимодействовали хотя бы с пятью статьями. Сколько всего таких пользователей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "347238f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_mask = df_interactions.groupby('personId').contentId.nunique()>4\n",
    "active_person = df_interactions.groupby('personId').contentId.count().index[activity_mask].to_list()\n",
    "\n",
    "len(active_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b3607",
   "metadata": {},
   "source": [
    "### Задание 6.4\n",
    "Теперь оставим только те взаимодействия, которые касаются только отфильтрованных пользователей (то есть тех, которые взаимодействовали как минимум с пятью статьями). Сколько всего таких взаимодействий?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a5898a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69868"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interactions = df_interactions[df_interactions.personId.isin(active_person)]\n",
    "\n",
    "df_interactions.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f332abdd",
   "metadata": {},
   "source": [
    "Сейчас каждое отдельное взаимодействие пользователя со статьёй выделено в отдельную запись, то есть пользователь мог просмотреть статью, лайкнуть и прокомментировать её, и всё это отразилось в трёх действиях. Давайте для удобства соединим все эти действия в некоторый коэффициент, который будет отражать интерес пользователя к статье. Так как каждому возможному действию мы ранее уже присвоили вес, то, по сути, нам нужно просто сложить все действия. Однако полученное число будет увеличиваться с количеством действий, и будет очень большой разброс возможных значений. В таких случаях обычно логарифмируют полученный результат с помощью следующей функции:\n",
    "```python\n",
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21aff4",
   "metadata": {},
   "source": [
    "### Задание 6.5\n",
    "Примените упомянутое выше преобразование для логарифмирования к сумме весов для взаимодействия пользователя с каждой конкретной статьёй. Также сохраните для каждой пары «пользователь — статья» значение времени последнего взаимодействия.\n",
    "\n",
    "Найдите среднее по признаку с получившимися временными отсечками. Округлите результат до двух знаков после точки-разделителя.\n",
    ">Чтобы выбрать последнее взаимодействие, необходимо использовать метод `last()`.\n",
    "\n",
    ">В этом задании необходимо работать с данными, полученными в задании 6.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "938cc684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470587338.35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "\n",
    "cum_weighted_event = df_interactions.groupby(['personId','contentId']).\\\n",
    "                        weighted_eventType.sum().apply(smooth_user_preference).reset_index()\n",
    "\n",
    "last_interaction = df_interactions.groupby(['personId','contentId']).timestamp.last().\\\n",
    "                        reset_index().rename(columns={'timestamp':'last_timestamp'})\n",
    "\n",
    "cum_weighted_event = cum_weighted_event.merge(last_interaction,on=['personId','contentId'])\n",
    "\n",
    "ans = cum_weighted_event.last_timestamp.mean()\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208de3aa",
   "metadata": {},
   "source": [
    "Разумеется, для того чтобы впоследствии оценить качество построенной рекомендательной системы, нам нужно разделить выборку на обучающую и тестовую. Так как в реальности рекомендации строятся на основе исторических данных о пользователе и контенте, сделаем в нашей задаче разбиение на обучающую и тестовую выборки по временной отсечке.   \n",
    "\n",
    "### Задание 6.6\n",
    "Разделите данные на обучающую и тестовую выборки, выбрав в качестве временной отсечки значение `1475519545`. Значение отсечки включите в тестовую выборку. Сколько объектов попало в обучающую выборку?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30b07f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29329"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_timestamp = 1475519545\n",
    "spli_mask = cum_weighted_event.last_timestamp < split_timestamp\n",
    "\n",
    "train = cum_weighted_event[spli_mask].copy()\n",
    "test = cum_weighted_event[~spli_mask].copy()\n",
    "\n",
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa1cf1",
   "metadata": {},
   "source": [
    "Для удобства дальнейшего измерения качества рекомендаций преобразуйте данные так, чтобы получить таблицу в формате, где строка соответствует пользователю, а столбцы будут истинными предпочтениями и рекомендациями в формате списков. На место пустых ячеек поместите пустые списки.\n",
    "```python\n",
    "final_df = (\n",
    "    train_df.reset_index()\n",
    "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
    "    .reset_index()\n",
    "    .rename(columns={'contentId': 'true_train'})\n",
    "    .set_index('personId')\n",
    ")\n",
    "\n",
    "final_df['true_test'] = (\n",
    "    test_df.reset_index()\n",
    "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
    ")\n",
    "\n",
    "final_df['true_test'] = [ [] if x is np.NaN else x for x in final_df['true_test'] ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cddf93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train = train.groupby('personId').contentId.apply(lambda x: list(x))\n",
    "true_test = test.groupby('personId').contentId.apply(lambda x: list(x))\n",
    "\n",
    "final_df = pd.DataFrame(data = {'true_train':true_train,'true_test':true_test},\n",
    "                                 index = true_train.index)\n",
    "final_df.true_test = final_df.true_test.apply(lambda x: x if x==x else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580c1f7",
   "metadata": {},
   "source": [
    "### Задание 6.7\n",
    "Осталось совсем немного — скоро вы получите свою первую систему рекомендаций! Мы будем строить *popular-based*-модель, а значит, нам необходимо найти самые популярные статьи.\n",
    "\n",
    "Посчитайте популярность каждой статьи как сумму всех логарифмических «оценок» взаимодействий с ней (используя только обучающую выборку). Выберите ID самой популярной статьи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43c0e56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6783772548752091658"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_popularity = train.groupby('contentId').weighted_eventType.sum()\n",
    "content_popularity.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba836c99",
   "metadata": {},
   "source": [
    "Теперь необходимо сформировать рекомендации для каждого пользователя. Будем рекомендовать десять самых популярных статей. Также необходимо помнить, что следует предлагать пользователю только то, что он ещё не читал.\n",
    "\n",
    "### Задание 6.8\n",
    "Постройте систему рекомендаций. Оцените качество с помощью `precision@10` для каждого пользователя (доля угаданных рекомендаций). После этого усредните результат по всем пользователям.   \n",
    "    \n",
    "Для вычисления `precision@10` воспользуйтесь следующей функцией:\n",
    "\n",
    "```python\n",
    "def precision(column):\n",
    "    return (final_df.apply(lambda row:\n",
    "            len(set(row['true_test']).intersection(set(row[column]))) /\n",
    "            min(len(row['true_test']) + 0.001, 10.0),axis=1)).mean()\n",
    "```\n",
    "Итоговый результат округлите до трёх знаков после точки-разделителя.\n",
    "\n",
    ">В этом задании необходимо использовать данные, полученные в задании 6.6 (для которых приведён скриншот выше)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c3d1bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision(column):\n",
    "    return (\n",
    "        final_df\n",
    "        .apply(\n",
    "            lambda row:\n",
    "            len(set(row['true_test']).intersection(\n",
    "                set(row[column]))) /\n",
    "            min(len(row['true_test']) + 0.001, 10.0),\n",
    "            axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "21c3ea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_top = 10\n",
    "ranged_content = content_popularity.sort_values(ascending=False).index\n",
    "unviewed_mask = lambda x: ~ranged_content.isin(list(x))\n",
    "\n",
    "final_df['recommended'] = final_df.true_train.apply(\n",
    "    lambda x: ranged_content[unviewed_mask(x)][:n_top].tolist())\n",
    "\n",
    "ans = calc_precision('recommended')\n",
    "round(ans,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
