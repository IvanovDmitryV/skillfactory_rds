{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание задачи\n",
    "## В задачи пректа входит:\n",
    "\n",
    " - Обработка предоставленных данных: нахождение и заполнение пропусков, кодировка, нормализация признаков.\n",
    " - Привлечение дополнительных данных для обогащения датасета.\n",
    " - Создание новых признаков с использованием для этого как предоставленных данные так и дополнительно привлченных.\n",
    " - Обучение и тестирование модели на полученных признаках с применением обучающей и валидационной части данных\n",
    " - Отбор полезных признаков с использованием обученной модели, обучение модели на отобранных признаках\n",
    " - Получение предсказанных моделью значений, подготовка и отправка submission. \n",
    "\n",
    "## Описание датасета\n",
    "Первоначальная версия датасета состоит из десяти столбцов, содержащих следующую информацию:\n",
    "\n",
    " - **Restaurant_id** — идентификационный номер ресторана / сети ресторанов;\n",
    " - **City** — город, в котором находится ресторан;\n",
    " - **Cuisine Style** — кухня или кухни, к которым можно отнести блюда, предлагаемые в ресторане;\n",
    " - **Ranking** — место, которое занимает данный ресторан среди всех ресторанов своего города;\n",
    " - **Rating** — рейтинг ресторана по данным TripAdvisor (именно это значение должна будет предсказывать модель);\n",
    " - **Price Range** — диапазон цен в ресторане;\n",
    " - **Number of Reviews** — количество отзывов о ресторане;\n",
    " - **Reviews** — данные о двух отзывах, которые отображаются на сайте ресторана;\n",
    " - **URL_TA** — URL страницы ресторана на TripAdvosor;\n",
    " - **ID_TA** — идентификатор ресторана в базе данных TripAdvisor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек, установка параметров, определение функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции используемые в ноутбуке\n",
    "def pre_process(df):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    df = pd.concat([df,pd.get_dummies(df.City)],axis=1)\n",
    "\n",
    "    df['Cuisine_Style_NaN'] = df.Cuisine_Style.isna().astype(int8)\n",
    "    df.Cuisine_Style = df.Cuisine_Style.fillna(\"['Nan_Style']\").str[2:-2].str.split(\"', '\")\n",
    "    cuisine_styles = sorted(set(df.Cuisine_Style.sum()))\n",
    "    for style in cuisine_styles:\n",
    "        df[style] = df.Cuisine_Style.apply(lambda x: int(style in x))\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    grouped_by_City = df.groupby('City')\n",
    "    for group in grouped_by_City.groups:\n",
    "        index = grouped_by_City.groups[group]\n",
    "        scaled_values = scaler.fit_transform(df[['Ranking']].loc[index])\n",
    "        df.Ranking.loc[index] = pd.Series(scaled_values.flatten(), index=index)\n",
    "    \n",
    "    df['Price_Range_NaN'] = df.Price_Range.isna().astype(int8)\n",
    "    price_range_encod = {'$': 1, '$$ - $$$': 2, '$$$$': 3}\n",
    "    df['Price_Range_enc'] = df.Price_Range.map(price_range_encod)\n",
    "    df.Price_Range_enc.fillna(df.Price_Range_enc.mean(),inplace=True)\n",
    "\n",
    "    df['NoR_NaN'] = df.Number_of_Reviews.isna().astype(int8)\n",
    "    df.Number_of_Reviews.fillna(1,inplace=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    for group in grouped_by_City.groups:\n",
    "        index = grouped_by_City.groups[group]\n",
    "        scaled_values = scaler.fit_transform(df[['Number_of_Reviews']].loc[index])\n",
    "        df.Number_of_Reviews.loc[index] = pd.Series(scaled_values.flatten(), index=index)\n",
    "\n",
    "    df.ID_TA = df.ID_TA.str[1:].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# установка параметров\n",
    "%pylab inline\n",
    "\n",
    "pd.set_option('display.max_rows', 50) # выведем больше строк\n",
    "pd.set_option('display.max_columns', 30) # выведем больше колонок\n",
    "\n",
    "path = './Project_3_data/'\n",
    "# path = '/kaggle/input/sf-dst-restaurant-rating/'\n",
    "\n",
    "pos_url = \\\n",
    "'https://gist.githubusercontent.com/mkulakowski2/4289437/raw/1bb4d7f9ee82150f339f09b5b1a0e6823d633958/positive-words.txt'\n",
    "neg_url = \\\n",
    "'https://gist.githubusercontent.com/mkulakowski2/4289441/raw/dad8b64b307cd6df8068a379079becbb3f91101a/negative-words.txt'\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Project_3_data/kaggle_task.csv\n",
      "./Project_3_data/sample_submission.csv\n",
      "./Project_3_data/train.csv\n"
     ]
    }
   ],
   "source": [
    "# проверка пути и имен файлов\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение данных\n",
    "df_train = pd.read_csv(f'{path}main_task.csv')\n",
    "df_test = pd.read_csv(f'{path}kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(f'{path}sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ознакомление с данными\n",
    "\n",
    "Для корректной обработки признаков объединяем трейн и тест в один датасет ***data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на полученный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 11 columns):\n",
      "Restaurant_id        50000 non-null object\n",
      "City                 50000 non-null object\n",
      "Cuisine Style        38410 non-null object\n",
      "Ranking              50000 non-null float64\n",
      "Price Range          32639 non-null object\n",
      "Number of Reviews    46800 non-null float64\n",
      "Reviews              49998 non-null object\n",
      "URL_TA               50000 non-null object\n",
      "ID_TA                50000 non-null object\n",
      "sample               50000 non-null int64\n",
      "Rating               50000 non-null float64\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>City</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "      <th>sample</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>id_7189</td>\n",
       "      <td>Milan</td>\n",
       "      <td>['Italian', 'Mediterranean', 'Vegetarian Frien...</td>\n",
       "      <td>174.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>888.0</td>\n",
       "      <td>[['The best Milanese veal cutlet ever', 'Fanta...</td>\n",
       "      <td>/Restaurant_Review-g187849-d1753674-Reviews-Os...</td>\n",
       "      <td>d1753674</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41195</th>\n",
       "      <td>id_2947</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>['Bar', 'European', 'Central European', 'Veget...</td>\n",
       "      <td>2949.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>177.0</td>\n",
       "      <td>[['Lovely setting with view of Graben', 'Basic...</td>\n",
       "      <td>/Restaurant_Review-g190454-d11592254-Reviews-G...</td>\n",
       "      <td>d11592254</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20530</th>\n",
       "      <td>id_1451</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>['Pizza']</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g4505479-d6868910-Reviews-P...</td>\n",
       "      <td>d6868910</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10245</th>\n",
       "      <td>id_2961</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>['German', 'Cafe', 'European', 'Fusion', 'Medi...</td>\n",
       "      <td>2963.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>59.0</td>\n",
       "      <td>[['much the same as last time', 'Horrible expe...</td>\n",
       "      <td>/Restaurant_Review-g187323-d5822584-Reviews-Un...</td>\n",
       "      <td>d5822584</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47069</th>\n",
       "      <td>id_35</td>\n",
       "      <td>Helsinki</td>\n",
       "      <td>['Moroccan', 'Mediterranean', 'Middle Eastern'...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>383.0</td>\n",
       "      <td>[['Good place for lunch', 'Very good lunch and...</td>\n",
       "      <td>/Restaurant_Review-g189934-d4419446-Reviews-Sa...</td>\n",
       "      <td>d4419446</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Restaurant_id      City  \\\n",
       "7189        id_7189     Milan   \n",
       "41195       id_2947    Vienna   \n",
       "20530       id_1451      Lyon   \n",
       "10245       id_2961    Berlin   \n",
       "47069         id_35  Helsinki   \n",
       "\n",
       "                                           Cuisine Style  Ranking Price Range  \\\n",
       "7189   ['Italian', 'Mediterranean', 'Vegetarian Frien...    174.0    $$ - $$$   \n",
       "41195  ['Bar', 'European', 'Central European', 'Veget...   2949.0    $$ - $$$   \n",
       "20530                                          ['Pizza']   1515.0         NaN   \n",
       "10245  ['German', 'Cafe', 'European', 'Fusion', 'Medi...   2963.0    $$ - $$$   \n",
       "47069  ['Moroccan', 'Mediterranean', 'Middle Eastern'...     36.0    $$ - $$$   \n",
       "\n",
       "       Number of Reviews                                            Reviews  \\\n",
       "7189               888.0  [['The best Milanese veal cutlet ever', 'Fanta...   \n",
       "41195              177.0  [['Lovely setting with view of Graben', 'Basic...   \n",
       "20530                2.0                                           [[], []]   \n",
       "10245               59.0  [['much the same as last time', 'Horrible expe...   \n",
       "47069              383.0  [['Good place for lunch', 'Very good lunch and...   \n",
       "\n",
       "                                                  URL_TA      ID_TA  sample  \\\n",
       "7189   /Restaurant_Review-g187849-d1753674-Reviews-Os...   d1753674       0   \n",
       "41195  /Restaurant_Review-g190454-d11592254-Reviews-G...  d11592254       1   \n",
       "20530  /Restaurant_Review-g4505479-d6868910-Reviews-P...   d6868910       1   \n",
       "10245  /Restaurant_Review-g187323-d5822584-Reviews-Un...   d5822584       1   \n",
       "47069  /Restaurant_Review-g189934-d4419446-Reviews-Sa...   d4419446       1   \n",
       "\n",
       "       Rating  \n",
       "7189      0.0  \n",
       "41195     3.0  \n",
       "20530     5.0  \n",
       "10245     3.5  \n",
       "47069     4.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Restaurant_id        <class 'str'>\n",
      "City                 <class 'str'>\n",
      "Cuisine Style        <class 'str'>\n",
      "Ranking              <class 'numpy.float64'>\n",
      "Price Range          <class 'str'>\n",
      "Number of Reviews    <class 'numpy.float64'>\n",
      "Reviews              <class 'str'>\n",
      "URL_TA               <class 'str'>\n",
      "ID_TA                <class 'str'>\n",
      "sample               <class 'numpy.int64'>\n",
      "Rating               <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "display(data.sample(5))\n",
    "print()\n",
    "for col in data.columns: print('{:20} {}'.format(col, type(data.loc[0][col])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски в явном виде *(NaN)* наблюдаются в четырех признаках: `Cuisine Style`, `Price Range`, `Number of Reviews` и `Reviews`. Кроме трех числовых признаков `Ranking`, `Rating` и `Number of Reviews`(один из них, `Rating` - целевая переменная) и одного вспомогательного временного столбца `sample` признаки представлены строками.\n",
    "\n",
    "Изменеим имена колонок для возможности обращения к колонкам как к атрибутам DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с предоставленными данными\n",
    "\n",
    "Сначала рассмотрим существующие признаки, выберем способы их предобработки, извлечем из существующих признаков информацию для создания новых.  \n",
    "Затем предобработаем существующие признаки согласно выбранным способам.  \n",
    "После этого создадим новые, при необходимости предобработаем и их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant_id\n",
    "Согласно описанию - идентификационный номер ресторана / сети ресторанов   \n",
    "\n",
    "Посмотрим на значения признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32217    id_2259\n",
       "27590      id_57\n",
       "13299    id_1127\n",
       "17129     id_769\n",
       "16743     id_799\n",
       "Name: Restaurant_id, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Restaurant_id.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения признака строковые, формата **'id_ЧИСЛО'**, где **ЧИСЛО** - некоторое целое число.\n",
    "Проверим, все ли значения выглядит подобным образом, для этого убедимся что первые три символа везде **'id_'** и что все значения после первых 3-х симвлов содержат только цифры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.Restaurant_id.str[:3] == 'id_').all(), data.Restaurant_id.str[3:].str.isnumeric().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё так и есть. Можно отбросить первые три символа(они везде одинаковые и потому не несут никакой информации) и в качестве значения признака принять приведенное к числовому виду **ЧИСЛО**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сопоставление `Restaurant id` с другими признаками из набора данных для обучения показало что как правило `Ranking` и **ЧИСЛО** в `Restaurant id` либо совпадают с точностью до 1 либо очень близки (возможно **ЧИСЛО** это `Ranking` в момент внесения ресторана в набор данных). Это наблюдение делает информативным казалось бы бесполезный признак.  \n",
    "UPD: Однако изучение набора данных для получения предсказания (Submission) показало, что в этих данных такая взаимосвязь отсутсвует. Вероятно оригигальные значения `Restaurant_id` были заменены. \"Казалось бы бесполезный признак\" не кажется таковым, он и вправду бесполезен для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков в признаке нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City\n",
    "Согласно описанию - город, в котором находится ресторан   \n",
    "\n",
    "Посмотрим на значения признака и заодно проверим, есть ли пропуски в неявном виде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Paris', 'Helsinki', 'Edinburgh', 'London', 'Bratislava', 'Lisbon',\n",
       "       'Budapest', 'Stockholm', 'Rome', 'Milan', 'Munich', 'Hamburg',\n",
       "       'Prague', 'Vienna', 'Dublin', 'Barcelona', 'Brussels', 'Madrid',\n",
       "       'Oslo', 'Amsterdam', 'Berlin', 'Lyon', 'Athens', 'Warsaw',\n",
       "       'Oporto', 'Krakow', 'Copenhagen', 'Luxembourg', 'Zurich', 'Geneva',\n",
       "       'Ljubljana'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.City.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков, выбросов нет. Остается привести признак в числовой вид, применив dummy-кодирование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuisine_Style\n",
    "согласно описанию - кухня или кухни, к которым можно отнести блюда, предлагаемые в ресторане.  \n",
    "\n",
    "Посмотрим как устроен признак:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33553                                          ['Italian']\n",
       "9427                                                   NaN\n",
       "199      ['Middle Eastern', 'Vegetarian Friendly', 'Veg...\n",
       "12447                                                  NaN\n",
       "39489                                                  NaN\n",
       "Name: Cuisine_Style, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Cuisine_Style.sample(5,random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала создадим признак `Cuisine_Style_NaN` - наличие/отсутствие пропуска в признаке.\n",
    "\n",
    "Затем заполним пропуски в признаке строковым значением *['Nan_Style']* и после этого преобразуем строковое представление списков непосредственно в списки.\n",
    "\n",
    "После чего мы создадим dummy-признаки по значениям в списках полученных из строковых значений в `Cuisine_Style` \n",
    "\n",
    "Сохраним список всех таких значений(наименований кухни), встречающихся в в `Cuisine_Style`, этот список нам понадобится в дальнейшем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cuisine_styles = sorted(set(data.Cuisine_Style.fillna(\"['Nan_Style']\").str[2:-2].str.split(\"', '\").sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, не было ли в признаке пропусков в неявном виде (т.е. в виде пустых строк, строкового представления пустого списка и т.д.). Если это так, то в `cuisine_styles` должна оказаться пустая строка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'' in cuisine_styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking\n",
    "Согласно описанию - место, которое занимает данный ресторан среди всех ресторанов своего города\n",
    "\n",
    "Признак числовой.  \n",
    "Пропусков нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каждом городе разное количество ресторанов, поэтому и диапозон `Ranking` в каждом городе различный (что приводит к тому что наихудший ресторан в маленьком городе будет иметь такой же `Ranking` как и отличный ресторан в мегаполисе). Такая разница масштабов может помешать модели, имеет смысл отнормировать  Ranking в каждом городе отдельно, что мы и сделаем. \n",
    "\n",
    "Так же можно использовать как оценку количества ресторанов в городе максимальную величину `Ranking` для каждого города. Эта величина будет использована как самостоятельный признак и будет участвовать в создании других новых признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним оценку количества ресторанов в городе, она нам понадобится при создании новых признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rest_estimate = data.groupby('City').Ranking.max() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price_Range\n",
    "Согласно описанию - диапазон цен в ресторане   \n",
    "\n",
    "Посмотрим на значения признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$$ - $$$', '$$$$', '$', nan], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Price_Range.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала создадим бинарный признак `Price_Range_NaN` -  наличие (1) или отсутствие (0) пропуска в признаке.\n",
    "\n",
    "Затем приведем признак к числовому виду, сперва закодировав каждый из трех вариантов не-NaN значений соответствующим числом от 1 (для низкого ценового диапозона) до 3 (для высокого ценового диапзона), а затем заполнив пропуски средним арифметическим уже закодированных непустых ячеек."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number_of_Reviews\n",
    "Согласно описанию - количество отзывов о ресторане  \n",
    "\n",
    "Признак в числовой форме.\n",
    "Пропуски в признаке есть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Number_of_Reviews.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение признака в области 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.Number_of_Reviews[data.Number_of_Reviews<10].hist(bins = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед заполнением пропуска создадим бинарный признак наличия/отсутствия значения в признаке , обозначим его `NoR_NaN`. \n",
    "\n",
    "Если сопоставить количество пропусков и распределение, то может возникнуть предположение, что пропуски подразумевают значение 0 или 1. Такая версия не испортит общий вид распределения. Заполнение пропусков 1 в отличии от заполнения 0 упростит использование данного признака при создании признаков новых (на случай если вдруг появится идея поделить на `Number_of_Reviews`) .Поэтому заполним пропуски 1. Этим обработка признака и ограничится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID_TA\n",
    "Согласно описанию - идентификатор ресторана в базе данных TripAdvisor\n",
    "\n",
    "Посмотрим на значения признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    d10746918\n",
       "1     d6674944\n",
       "2    d13129638\n",
       "3      d680417\n",
       "4     d1112354\n",
       "Name: ID_TA, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ID_TA[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения признака строковые, формата **'dЧИСЛО'**, где **ЧИСЛО** - некоторое целое число. Проверим, все ли значения выглядит подобным образом, для этого убедимся что первый символ везде 'd' и что все символы кроме первого - только цифры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.ID_TA.str[0] == 'd').all(), (data.ID_TA.str[1:].str.isnumeric()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем признак -  примем в качесвте значения приведенную к числовому виду его цифровая часть (т.е. **ЧИСЛО**).  \n",
    "В работе будет использоваться гипотеза о том что цифровая часть отражает хронологический порядок появления ресторана в базе данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews\n",
    "Согласно описанию - данные о не более чем двух последних отзывах, которые отображаются на сайте ресторана  \n",
    "\n",
    "Посмотрим на значения признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             [[], []]\n",
       "1    [['Very good reviews!', 'Fine dining in Hakani...\n",
       "2    [['Better than the Links', 'Ivy Black'], ['12/...\n",
       "3    [['Most exquisite', 'Delicious and authentic']...\n",
       "4    [['Always the best in bratislava', 'Very good ...\n",
       "Name: Reviews, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Reviews[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признак строковый,в нем есть неявные пропуски (значения \"[[], []]\"), при работе с признаком надо будет учитывать их наличие. Удалять наблюдения с такими значениями не следует ввиду их значительного количества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8112"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.Reviews == '[[], []]').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В признаке пропусков в явном виде 2, заполним их строковым значением \"[[], []]\"\n"
     ]
    }
   ],
   "source": [
    "print('В признаке пропусков в явном виде {}, заполним их строковым значением \"[[], []]\"'.format(data.Reviews.isna().sum()))\n",
    "data.Reviews.fillna('[[], []]',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с  признаком:\n",
    " - отделим и сохраним текстовую составляющую (собственно отзывы)\n",
    " - получим список дат отзывовов.   \n",
    " На основе этой информации позднее создадим новые признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Review_texts = data.Reviews.apply(lambda x:x[: x.find('], [')+1]).str.replace(\"[\\[\\]]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_data = lambda x: datetime.datetime.strptime(x, '%m/%d/%Y').date() # функция перевода str в datetime\n",
    "today = datetime.datetime.today().date()\n",
    "# Получим pd.Series содержащую списки дат отзывов\n",
    "review_date_lists = data.Reviews.apply(lambda x:x[ x.find('], [')+3:]).str.replace(\"[\\[\\]' ]\", \"\").str.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL_TA\n",
    "Согласно описанию - URL страницы ресторана на TripAdvosor  \n",
    "\n",
    "Посмотрим на значения признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Restaurant_Review-g187147-d10746918-Reviews-Le_Perchoir-Paris_Ile_de_France.html\n",
      "/Restaurant_Review-g189934-d6674944-Reviews-Ravintola_Kolmon3n-Helsinki_Uusimaa.html\n",
      "/Restaurant_Review-g186525-d13129638-Reviews-Black_Ivy-Edinburgh_Scotland.html\n",
      "/Restaurant_Review-g186338-d680417-Reviews-Quirinale-London_England.html\n",
      "/Restaurant_Review-g274924-d1112354-Reviews-Massimo_Ristorante-Bratislava_Bratislava_Region.html\n"
     ]
    }
   ],
   "source": [
    "for s in data.URL_TA[:5]: print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения строковые, в строке присутсвует индентификатор формата 'g123456'(сопоставление с другими признаками показало что это ID города), затем ID_TA, название ресторана, город/регион.  \n",
    "Получим название и попытаемся такой признак обработать и применить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_names = data.URL_TA.apply(lambda x: x[x.find('Reviews-')+8: x.find('-',x.find('Reviews-')+8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['g_id'] = data.URL_TA.apply(lambda x: int(x[x.find('-g')+2: x.find('-',x.find('-g')+2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация предобработки.\n",
    "Проведем кодирование существующих признаков в соотвтетсвии с принятыми решениями о способах предобработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pre_process(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `population` - население города, в которм расположен ресторан. Признак возможно интресен и сам по себе, но с большей вероятнотью интересен в сочетании с другими признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.Series({\n",
    "    'Paris':2140526, 'Stockholm':961609, 'London': 8787892, 'Berlin':3601131, 'Munich':1456039, \n",
    "    'Oporto':240000,'Milan':1366180, 'Bratislava': 425923, 'Vienna':1840573, 'Rome': 2872800, \n",
    "    'Barcelona':1620343, 'Madrid':3223334,'Dublin':553165, 'Brussels':1198726, 'Zurich': 428000, \n",
    "    'Warsaw':1758143, 'Budapest':1749734, 'Copenhagen':615993,'Amsterdam':859732, 'Lyon':515695, \n",
    "    'Hamburg':1830584, 'Lisbon':506654, 'Prague':1280508, 'Oslo':673469,'Helsinki':643272, \n",
    "    'Edinburgh':524900 ,'Geneva':499000, 'Ljubljana':258900, 'Athens':655780, 'Luxembourg':115227, \n",
    "    'Krakow':766739\n",
    "})\n",
    "\n",
    "data['City_population'] = data.City.map(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `tourist_arrival` количество постивших город туритсов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourist_arrival = pd.Series({\n",
    "    'London': 19059500, 'Paris': 13926300,'Rome':  9353900,'Prague':  8200600,'Amsterdam':  6898600, \n",
    "    'Barcelona':  6515500, 'Milan':  6175000,'Vienna':  5867600,'Berlin':  5559600,'Madrid':  5131700,\n",
    "    'Dublin':  4810000,'Athens':  4526000,'Munich':  3389300,'Budapest':  3511400,'Lisbon':  3136100,\n",
    "    'Brussels':  2511500,'Copenhagen':  2887700,'Warsaw':  2733000,'Krakow':  2650000,\n",
    "    'Stockholm':  2327000,'Oporto':  1969300,'Bratislava': 986201,'Lyon': 1700000,'Hamburg': 2713200,\n",
    "    'Luxembourg': 1018000,'Ljubljana':  1022862,'Edinburgh': 3300000,'Helsinki': 1700000,'Oslo': 1352112,\n",
    "    'Zurich': 2000000,'Geneva': 2200000\n",
    "})\n",
    "\n",
    "data['tourist_arrival'] = data.City.map(tourist_arrival)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `tourist_population_prop` - отношение прибывших туристов к населению города"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourist_population_prop = tourist_arrival/population\n",
    "data['tourist_population_prop'] = data.City.map(tourist_population_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `styles_num` - количество стилей кухни, представленных в ресторане."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['styles_num'] = data.apply(lambda x: 0 if x.Nan_Style else len(x.Cuisine_Style),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `num_rest_estimate` оценка количества ресторанов в городе (оценкой служит Ranking.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_rest_estimate'] = data.apply(lambda x: num_rest_estimate[x.City], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `rest_per_capita` -  оценочное (по Ranking.max()) количество ресторанов на душу населения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ['rest_per_capita'] = data.apply(lambda x: num_rest_estimate[x.City]/x.City_population, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `reviews_per_capita` - количество отзывов на душу населения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews_per_capita']=data.Number_of_Reviews/data.City_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `since_review` - время прошедшее с даты последнего отзыва"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['since_review'] = review_date_lists.apply(lambda x: (today - str_to_data(x[-1])).days if x[-1] \n",
    "                                             else -999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `review_date_range` временной интервал между отзывами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review_date_range'] = review_date_lists.apply(lambda x: (str_to_data(x[0]) - str_to_data(x[1])).days if len(x) == 2 \n",
    "                                                  else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `rank_dif_NoR` - разница в рангах отранжированного количества отзывов ***Number_of_Reviews*** и отранжированных по цифрой части ***ID_TA***, основан на предположении, что ***ID_TA*** заполнялся в хронологическом порядке и предположении, что чем дольше ресторан работает, тем больше должно быть отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoR_index = data.Number_of_Reviews[data.Number_of_Reviews != 0].index\n",
    "\n",
    "ID_TA_with_NoR = data.loc[NoR_index].ID_TA\n",
    "\n",
    "NoR_rank_dict = {val: rank for rank, val in enumerate(sorted(data.Number_of_Reviews[NoR_index],reverse=True))}\n",
    "NoR_rank = data.Number_of_Reviews[NoR_index].map(NoR_rank_dict)\n",
    "\n",
    "ID_TA_NoR_rank_dict = {val: rank for rank, val in enumerate(sorted(ID_TA_with_NoR))}\n",
    "ID_TA_NoR_rank = ID_TA_with_NoR.map(ID_TA_NoR_rank_dict)\n",
    "\n",
    "data['rank_dif_NoR'] = ID_TA_NoR_rank - NoR_rank\n",
    "data.rank_dif_NoR.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `rev_text_length` - длинна извлеченного из `Reviews` текста отзыва(-ов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rev_text_length'] = Review_texts.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `rev_on_website` - количество отзывов на сайте, согласно признаку `Reviews`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rev_on_website'] = Review_texts.apply(lambda x: len(x.split(', ')) if x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `punct_in_review` - бинарный признак наличия/отсутствия знаков пунктуации в тектсе отзыва(-ов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"!;:?.,\"\n",
    "data['punct_in_review'] = Review_texts.apply(lambda x: int(bool(set(list(punct)) & set(list(x.replace(', ',''))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `Name_lenght` длина названия в символах. Предположительно хорошие рестораны имеют более претенциозные названия, вероятно - более длинные, чем названия простецких забегаловок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Name_lenght'] = rest_names.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `words_in_name` длина названия в словах. Идея признака та же, что и у `Name_lenght`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['words_in_name'] = rest_names.str.split('_').apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `is_capital`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_capital_dict = {\n",
    "    'Paris':1, 'Stockholm':1, 'London': 1, 'Berlin':1, 'Munich':0, \n",
    "    'Oporto':0,'Milan':0, 'Bratislava': 1, 'Vienna':1, 'Rome': 1, \n",
    "    'Barcelona':0, 'Madrid':1,'Dublin':1, 'Brussels':1, 'Zurich': 0, \n",
    "    'Warsaw':1, 'Budapest':1, 'Copenhagen':1,'Amsterdam':1, 'Lyon':0, \n",
    "    'Hamburg':0, 'Lisbon':1, 'Prague':1, 'Oslo':1,'Helsinki':1, \n",
    "    'Edinburgh':0 ,'Geneva':0, 'Ljubljana':1, 'Athens':1, 'Luxembourg':1, \n",
    "    'Krakow':0\n",
    "}\n",
    "\n",
    "data['is_capital'] = data.City.map(is_capital_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем величину `uniqueness_of_cuisine` - это величина обратная тому, сколько раз кухня встречается в наборе данных.  \n",
    "`uniqueness_of_cuisine` принимает значения в интервале (0, 1] (значения стремящиеся к 0 - кухня встречается очень часто, 1 - кухня встречется всего 1 раз)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cuistyle_list = data.Cuisine_Style.sum()    \n",
    "uniqueness_of_cuisine = 1/pd.Series(total_cuistyle_list).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `sum_uniqueness` - сумма уникальностей стилей кухни ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_uniqueness = lambda x: uniqueness_of_cuisine[x].sum()\n",
    "data['sum_uniqueness'] = data.Cuisine_Style.apply(sum_uniqueness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `max_uniqueness` - максимальная уникальность кухни в ресторане"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_uniqueness = lambda x: uniqueness_of_cuisine[x].max()\n",
    "data['max_uniqueness'] = data.Cuisine_Style.apply(max_uniqueness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `min_uniqueness` - минимальная уникальность (т.е. максимальная распрстранненность, популярность) кухни в ресторане"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_uniqueness = lambda x: uniqueness_of_cuisine[x].min()\n",
    "data['min_uniqueness'] = data.Cuisine_Style.apply(min_uniqueness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем величину `city_uniqueness_of_cuisine` - аналогично `uniqueness_of_cuisine`, только применительно к каждому городу отдельно. С помощью этой величины создадим три новых признака `city_sum_uniqueness` ,`city_max_uniqueness` и `city_min_uniqueness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grouped_by_City = data.groupby('City')\n",
    "\n",
    "city_sum_uniqueness = lambda x: city_uniqueness_of_cuisine[x].sum()\n",
    "city_max_uniqueness = lambda x: city_uniqueness_of_cuisine[x].max()\n",
    "city_min_uniqueness = lambda x: city_uniqueness_of_cuisine[x].min()\n",
    "\n",
    "temp_city_sum = pd.Series()\n",
    "temp_city_max = pd.Series()\n",
    "temp_city_min = pd.Series()\n",
    "\n",
    "for group in grouped_by_City.groups:\n",
    "    index = grouped_by_City.groups[group]\n",
    "    \n",
    "    city_cuistyle_list = data.Cuisine_Style.loc[index].sum()    \n",
    "    city_uniqueness_of_cuisine = 1/pd.Series(city_cuistyle_list).value_counts()\n",
    "    \n",
    "    temp_city_sum = temp_city_sum.append(data.Cuisine_Style.loc[index].apply(city_sum_uniqueness)) \n",
    "    temp_city_max = temp_city_max.append(data.Cuisine_Style.loc[index].apply(city_max_uniqueness))  \n",
    "    temp_city_min = temp_city_min.append(data.Cuisine_Style.loc[index].apply(city_min_uniqueness))\n",
    "    \n",
    "data['city_sum_uniqueness'] = temp_city_sum\n",
    "data['city_max_uniqueness'] = temp_city_max\n",
    "data['city_min_uniqueness'] = temp_city_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем новую величину распрастранненость/популярность кухни `prevalence_of_cuisine` определим её как ***1 - uniqueness_of_cuisine***.  \n",
    "`prevalence_of_cuisine` принимает значения в интервале [0, 1) (0 - кухня встречается всего  1 раз, значения стремящиеся к 1 - кухня крайне распространена)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence_of_cuisine = 1 - uniqueness_of_cuisine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `sum_prevalence` - сумма распрастраннености стилей кухни ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prevalence = lambda x: prevalence_of_cuisine[x].sum()\n",
    "data['sum_prevalence'] = data.Cuisine_Style.apply(sum_prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим анологичный признак для каждого города - `city_sum_prevalence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grouped_by_City = data.groupby('City')\n",
    "\n",
    "city_sum_prevalence = lambda x: city_prevalence_of_cuisine[x].sum()\n",
    "\n",
    "temp_city_sum = pd.Series()\n",
    "\n",
    "for group in grouped_by_City.groups:\n",
    "    index = grouped_by_City.groups[group]\n",
    "    \n",
    "    city_cuistyle_list = data.Cuisine_Style.loc[index].sum()    \n",
    "    city_prevalence_of_cuisine = 1 - 1/pd.Series(city_cuistyle_list).value_counts()\n",
    "    \n",
    "    temp_city_sum = temp_city_sum.append(data.Cuisine_Style.loc[index].apply(city_sum_prevalence)) \n",
    "    \n",
    "data['city_sum_prevalence'] = temp_city_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак - тональность отзыва/-ов `review_sentiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_req = requests.get(pos_url)\n",
    "neg_req = requests.get(neg_url)\n",
    "\n",
    "pos_words = pos_req.text[pos_req.text.find('abound'):].strip().split('\\n')\n",
    "neg_words = neg_req.text[neg_req.text.find('abnormal'):].strip().split('\\n')\n",
    "\n",
    "Review_words = Review_texts.replace(to_replace=r'\\W',value = ' ',regex=True).str.lower().str.split()\n",
    "\n",
    "review_sentiment = lambda x: sum([int(w in pos_words) for w in x]) - sum([int(w in neg_words) for w in x])\n",
    "\n",
    "data['review_sentiment']    = Review_words.apply(review_sentiment).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передадим модели некоторые особенности распределений целевой переменной в каждом городе \n",
    "(потенциально чревато переобучением, проверим на валидационной части выборки не просело ли качество)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['city_median_rating'] = data.City.map(grouped_by_City.Rating.median())\n",
    "\n",
    "data['city_mean_rating'] = data.City.map(grouped_by_City.Rating.mean())\n",
    "\n",
    "data['city_rating_skewness'] = data['city_mean_rating'] - data['city_median_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завершение подготовки данных для обучения модели\n",
    "\n",
    "Удалим те столбцы что более не нужны для создания новых признаков и при этом мы не собираемся их передавать модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "coltodrop = ['Restaurant_id','City', 'Reviews', 'URL_TA', 'Price_Range','Cuisine_Style']\n",
    "enrichmented_data = data.drop(columns=coltodrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько строк проверки корректности обработки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrichmented_data.dtypes[enrichmented_data.dtypes == object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrichmented_data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 195)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrichmented_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В самом начале мы для корректной обработки признаков объединили два исходных датсета в один. Теперь обратно разделим данные на часть для обучения и тестирования модели и часть для получения предсказания (Submission)  и удалим внесенные нами для удобства обработки колонки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = enrichmented_data.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = enrichmented_data.query('sample == 0').drop(['sample','Rating'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
    "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще раз проверяем размерности полученных датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 193), (40000, 194), (40000, 193), (32000, 193), (8000, 193))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаём, обучаем и тестируем модель\n",
    "## Первичное обучение и тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Создаём модель\n",
    "regr = RandomForestRegressor(n_estimators=100, random_state = RANDOM_SEED)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются  \n",
    "Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.19693937499999997\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Искомые значения рейтинга дискретны - от 1 до 5 с шагом 0.5, наверное имеет смысл округлить полученные результаты \n",
    "до этих значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.16175\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error((y_pred*2).round()/2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ж, мы получили уже неплохой результат. Но не станем останавливаться и попробуем еще хоть немного продвинуться вперед ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор неполезных признаков\n",
    "Обучив модель, мы теперь можем попытаться улучшить наш датасет отбросив те признаки , которые ухудшают метрику на валидационной части выборки, расчитывая на то что это улучшит точность работы модели на данных для Submission.  \n",
    "Мы последовательно будем изымать по одному признаку из датасета и проверять как изменилась метрика (будем сравнивать с MAE при полном датасете). Если значение MAE улучшилось в отсутсвии признака, то признак будет отнесен к неполезным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 193/193 [4:32:01<00:00, 84.57s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "MAE_threshold = metrics.mean_absolute_error(y_pred, y_test)\n",
    "\n",
    "unuseful_features = pd.Series([])\n",
    "\n",
    "for col in tqdm(X.columns):\n",
    "    X_tmp = X.drop(columns=col)\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X_tmp, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "    regr.fit(X_trn, y_trn)\n",
    "    \n",
    "    y_pr = regr.predict(X_tst)\n",
    "    \n",
    "    MAE_tmp = metrics.mean_absolute_error(y_pr, y_tst) \n",
    "    \n",
    "    if MAE_tmp < MAE_threshold : \n",
    "        unuseful_features[col] = MAE_threshold - MAE_tmp\n",
    "\n",
    "unuseful_features = unuseful_features.sort_values(ascending = False)\n",
    "# unuseful_features.to_csv('unuseful_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате мы получили pd.Series `unuseful_features` c индексами - наименованием признака и значениями - уменьшением метрики МАЕ в отсутствии признака (т.е \"вредом\" от признака)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор оптимального количества исключаемых из датасета признаков\n",
    "Получив неполезные признаки вместо того чтобы просто удалить их из датасета постараемся подобрать оптимальное количество удалямых признаков. Для этого станем удалять признаки по одному, начиная с признака с наибольшим \"вредом\" и будем следить за значениеми обычного МАЕ и МАЕ с использованием округдения предсказания до 0,5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                   | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▊                                        | 1/49 [01:34<1:15:45, 94.70s/it]\u001b[A\n",
      "  4%|█▋                                       | 2/49 [03:09<1:14:09, 94.66s/it]\u001b[A\n",
      "  6%|██▌                                      | 3/49 [04:46<1:13:03, 95.29s/it]\u001b[A\n",
      "  8%|███▎                                     | 4/49 [06:11<1:09:09, 92.21s/it]\u001b[A\n",
      " 10%|████▏                                    | 5/49 [07:35<1:05:59, 89.99s/it]\u001b[A\n",
      " 12%|█████                                    | 6/49 [08:58<1:02:49, 87.65s/it]\u001b[A\n",
      " 14%|█████▊                                   | 7/49 [10:19<1:00:07, 85.88s/it]\u001b[A\n",
      " 16%|███████                                    | 8/49 [11:41<57:47, 84.57s/it]\u001b[A\n",
      " 18%|███████▉                                   | 9/49 [13:02<55:40, 83.52s/it]\u001b[A\n",
      " 20%|████████▌                                 | 10/49 [14:20<53:11, 81.84s/it]\u001b[A\n",
      " 22%|█████████▍                                | 11/49 [15:38<51:05, 80.67s/it]\u001b[A\n",
      " 24%|██████████▎                               | 12/49 [16:55<49:02, 79.54s/it]\u001b[A\n",
      " 27%|███████████▏                              | 13/49 [18:11<47:12, 78.69s/it]\u001b[A\n",
      " 29%|████████████                              | 14/49 [19:26<45:12, 77.50s/it]\u001b[A\n",
      " 31%|████████████▊                             | 15/49 [20:41<43:27, 76.70s/it]\u001b[A\n",
      " 33%|█████████████▋                            | 16/49 [21:56<41:56, 76.24s/it]\u001b[A\n",
      " 35%|██████████████▌                           | 17/49 [23:18<41:30, 77.82s/it]\u001b[A\n",
      " 37%|███████████████▍                          | 18/49 [24:29<39:12, 75.88s/it]\u001b[A\n",
      " 39%|████████████████▎                         | 19/49 [25:39<37:01, 74.03s/it]\u001b[A\n",
      " 41%|█████████████████▏                        | 20/49 [26:48<35:08, 72.70s/it]\u001b[A\n",
      " 43%|██████████████████                        | 21/49 [27:56<33:09, 71.07s/it]\u001b[A\n",
      " 45%|██████████████████▊                       | 22/49 [29:05<31:48, 70.68s/it]\u001b[A\n",
      " 47%|███████████████████▋                      | 23/49 [30:13<30:13, 69.77s/it]\u001b[A\n",
      " 49%|████████████████████▌                     | 24/49 [31:19<28:39, 68.78s/it]\u001b[A\n",
      " 51%|█████████████████████▍                    | 25/49 [32:26<27:13, 68.08s/it]\u001b[A\n",
      " 53%|██████████████████████▎                   | 26/49 [33:32<25:51, 67.45s/it]\u001b[A\n",
      " 55%|███████████████████████▏                  | 27/49 [34:37<24:30, 66.84s/it]\u001b[A\n",
      " 57%|████████████████████████                  | 28/49 [35:43<23:14, 66.40s/it]\u001b[A\n",
      " 59%|████████████████████████▊                 | 29/49 [36:48<22:00, 66.04s/it]\u001b[A\n",
      " 61%|█████████████████████████▋                | 30/49 [37:52<20:46, 65.62s/it]\u001b[A\n",
      " 63%|██████████████████████████▌               | 31/49 [38:57<19:33, 65.22s/it]\u001b[A\n",
      " 65%|███████████████████████████▍              | 32/49 [40:00<18:17, 64.55s/it]\u001b[A\n",
      " 67%|████████████████████████████▎             | 33/49 [41:02<17:04, 64.00s/it]\u001b[A\n",
      " 69%|█████████████████████████████▏            | 34/49 [42:05<15:52, 63.52s/it]\u001b[A\n",
      " 71%|██████████████████████████████            | 35/49 [43:07<14:43, 63.13s/it]\u001b[A\n",
      " 73%|██████████████████████████████▊           | 36/49 [44:09<13:36, 62.84s/it]\u001b[A\n",
      " 76%|███████████████████████████████▋          | 37/49 [45:11<12:29, 62.48s/it]\u001b[A\n",
      " 78%|████████████████████████████████▌         | 38/49 [46:13<11:25, 62.28s/it]\u001b[A\n",
      " 80%|█████████████████████████████████▍        | 39/49 [47:14<10:20, 62.04s/it]\u001b[A\n",
      " 82%|██████████████████████████████████▎       | 40/49 [48:16<09:18, 62.04s/it]\u001b[A\n",
      " 84%|███████████████████████████████████▏      | 41/49 [49:18<08:15, 61.90s/it]\u001b[A\n",
      " 86%|████████████████████████████████████      | 42/49 [50:19<07:12, 61.82s/it]\u001b[A\n",
      " 88%|████████████████████████████████████▊     | 43/49 [51:21<06:10, 61.71s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████▋    | 44/49 [52:20<05:04, 60.98s/it]\u001b[A\n",
      " 92%|██████████████████████████████████████▌   | 45/49 [53:20<04:01, 60.50s/it]\u001b[A\n",
      " 94%|███████████████████████████████████████▍  | 46/49 [54:18<03:00, 60.04s/it]\u001b[A\n",
      " 96%|████████████████████████████████████████▎ | 47/49 [55:17<01:59, 59.66s/it]\u001b[A\n",
      " 98%|█████████████████████████████████████████▏| 48/49 [56:17<00:59, 59.60s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████| 49/49 [57:15<00:00, 70.12s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "MAE_changes = pd.DataFrame(columns=['MAE', 'MAE_round'])\n",
    "\n",
    "for loc in tqdm(range(0,len(unuseful_features),1)):\n",
    "    to_drop = unuseful_features.index[:loc]\n",
    "    \n",
    "    X_tmp = X.drop(columns=to_drop)\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X_tmp, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "    regr.fit(X_trn, y_trn)\n",
    "    \n",
    "    y_pr = regr.predict(X_tst)\n",
    "    \n",
    "    MAE_tmp = metrics.mean_absolute_error(y_pr, y_tst) \n",
    "    MAE_round_tmp = metrics.mean_absolute_error((y_pr*2).round()/2, y_tst)\n",
    "    MAE_changes.loc[loc] = [MAE_tmp,MAE_round_tmp]\n",
    "#     print('{:3}  {:.6f}  {:.6f}'.format(loc, MAE_tmp,MAE_round_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примем в качестве оптимального результата минимум суммы `MAE` и `MAE_round` и соответсвенно удалим из датасета количество признаков `optim_count` при удалении которого достигается такой миниум."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_count = MAE_changes.sum(axis=1).idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19531125 0.15925\n"
     ]
    }
   ],
   "source": [
    "X_optim = X.drop(columns=unuseful_features.index[:optim_count])\n",
    "X_trn, X_tst, y_trn, y_tst = train_test_split(X_optim, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "regr.fit(X_trn, y_trn)\n",
    "\n",
    "y_pr = regr.predict(X_tst)\n",
    "    \n",
    "MAE_optim = metrics.mean_absolute_error(y_pr, y_tst) \n",
    "MAE_round_optim = metrics.mean_absolute_error((y_pr*2).round()/2, y_tst) \n",
    "\n",
    "print(MAE_optim,MAE_round_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Применим обученную на оптимизированом нами датасете модель для получения предсказания на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(columns=unuseful_features.index[:optim_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = regr.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_2</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_4</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id_5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id_6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id_7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id_8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id_9</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant_id  Rating\n",
       "0          id_0     3.0\n",
       "1          id_1     4.0\n",
       "2          id_2     4.5\n",
       "3          id_3     4.5\n",
       "4          id_4     4.5\n",
       "5          id_5     4.5\n",
       "6          id_6     1.5\n",
       "7          id_7     3.0\n",
       "8          id_8     4.0\n",
       "9          id_9     4.5"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['Rating'] = (predict_submission*2).round()/2\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
