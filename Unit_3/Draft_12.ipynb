{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('./Unit3_data/log.xlt', header=None)\n",
    "log.columns = ['user_id','time','bet','win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>bet</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Запись пользователя № - user_919</td>\n",
       "      <td>[2019-01-01 14:06:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Запись пользователя № - user_973</td>\n",
       "      <td>[2019-01-01 14:51:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Запись пользователя № - user_903</td>\n",
       "      <td>[2019-01-01 16:31:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Запись пользователя № - user_954</td>\n",
       "      <td>[2019-01-01 17:17:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Запись пользователя № - user_954</td>\n",
       "      <td>[2019-01-01 21:31:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id                  time  bet  win\n",
       "0  Запись пользователя № - user_919  [2019-01-01 14:06:51  NaN  NaN\n",
       "1  Запись пользователя № - user_973  [2019-01-01 14:51:16  NaN  NaN\n",
       "2  Запись пользователя № - user_903  [2019-01-01 16:31:16  NaN  NaN\n",
       "3  Запись пользователя № - user_954  [2019-01-01 17:17:51  NaN  NaN\n",
       "4  Запись пользователя № - user_954  [2019-01-01 21:31:18  NaN  NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Посчитайте количество пропусков в столбце time. Метод isna() есть не только у DataFrame, но и у Series. Это значит, что применять его можно не только ко всей таблице, но и к каждому столбцу отдельно.\n",
    "Примените этот метод, затем просуммируйте количество строк в итоговом столбце. Ответ введите в поле ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.time.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Удалите все столбцы, где есть пропуски. Запишите в поле, сколько осталось столбцов в данных после этого.\n",
    "\n",
    "Используйте оригинальный датасет log.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(log.dropna(axis=1).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "Удалите все строки, где есть пропуски. Запишите в поле, сколько осталось строк в данных после этого.\n",
    "\n",
    "Используйте оригинальный датасет log.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(log.dropna().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "Используйте оригинальный датасет log.csv.\n",
    "\n",
    "С данными в столбцах bet и win мы разберемся позже: пропуски в этих столбцах требуют особого подхода.\n",
    "\n",
    "А сейчас:\n",
    "\n",
    "если есть пропуски в столбце user_id - удалите столбец user_id,\n",
    "\n",
    "если есть пропуски в столбце time - удалите столбец time.\n",
    "\n",
    "Запишите в поле ответа, количество оставшихся столбцов в данных, после этих действий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_look = log.columns.drop(['bet','win'])\n",
    "columns_to_drop = columns_to_look[log[columns_to_look].isna().any()]\n",
    "len(log.columns.drop(columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.drop(columns_to_drop,axis =1).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************************\n",
    "# *******************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Удалите дубли среди столбцов user_id и time. Запишите в поле ниже, сколько осталось строк после удаления дублей.\n",
    "\n",
    "Используйте оригинальный датасет log.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "            ...\n",
       "            976, 977, 984, 989, 990, 991, 992, 993, 994, 995],\n",
       "           dtype='int64', length=986)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.drop_duplicates(subset=['user_id','time']).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************************\n",
    "# *******************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Уберите лишний символ, преобразуйте признак time к datetime. \n",
    "После этого найдите наибольшую дату и выведите ее без времени.\n",
    "\n",
    "Подсказка: можно применить метод max() к получившемуся столбцу со временем.\n",
    "\n",
    "Не забудьте избавиться от пропусков.\n",
    "\n",
    "Запишите ответ в формате \"YYYY-MM-DD\".  \n",
    "Например, 1993-06-08."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-04-20'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_time = log.time.dropna().apply(lambda x: x[1:])\n",
    "pd.to_datetime(new_time).max().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************************\n",
    "# *******************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, если мы хотим получить столбец, в котором каждым значением будет год из другого столбца (это и есть feature engineering - создание новых признаков из старых), мы можем сделать следующее:\n",
    "\n",
    "year_column = log['time'].apply(lambda x: x.year)  \n",
    "Библиотека pandas позволяет использовать аксессор dt для упрощения подобной работы:\n",
    "\n",
    "year_column = log['time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************************\n",
    "# *******************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Используйте оригинальные данные log.csv, столбец time.\n",
    "\n",
    "Подсказка: можно использовать value_counts().\n",
    "\n",
    "Найдите минуту, которая встречалась в данных чаще всего. Введите ответ в поле ниже.\n",
    "Например, 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(log.time.dropna().apply(lambda x: x[1:])).dt.minute.value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Используйте оригинальные данные log.csv, столбец time.\n",
    "\n",
    "Подсказка: можно использовать value_counts().\n",
    "\n",
    "Найдите месяц, который встречался в данных реже всего. Введите ответ в поле ниже.\n",
    "Например, 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(log.time.dropna().apply(lambda x: x[1:])).dt.month.value_counts().idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3*\n",
    "Используйте оригинальные данные log.csv, столбец time.\n",
    "\n",
    "Подсказка: можно использовать sum().\n",
    "\n",
    "Посчитайте, сколько дней в данных являются выходными (то есть субботой или воскресеньем). Введите ответ в поле ниже.\n",
    "Например, 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(log.time.dropna().apply(lambda x: x[1:])).dt.dayofweek.isin([5,6]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4*\n",
    "Используйте оригинальные данные log.csv, столбец time.\n",
    "\n",
    "Подсказка: можно использовать value_counts(). Кроме этого, потребуется написать функцию, которая преобразует дату во время дня.\n",
    "\n",
    "Договоримся, что с 0 до 5 часов - ночь, с 6 до 11 - утро, с 12 до 17 - день, с 18 до 23 - вечер.\n",
    "\n",
    "Важно: для выполнения задания вам нужно будет избавиться от пропусков только в столбце time. Вспомните, как избавиться от пропусков только по конкретному признаку.\n",
    "\n",
    "Посчитайте, какое время дня встречается в данных реже всего. Введите ответ в поле ниже: ночь, утро, день или вечер.\n",
    "Например, ночь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'вечер'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_of_day(hour):\n",
    "    if 0 <= hour <= 5: return 'ночь'\n",
    "    if 6 <= hour <= 11: return 'утро'\n",
    "    if 12 <= hour <= 17: return 'день'\n",
    "    if 18 <= hour <= 23: return 'вечер'\n",
    "\n",
    "pd.to_datetime(log.time.dropna().apply(lambda x: x[1:])).dt.hour.apply(time_of_day).value_counts().idxmin()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5*\n",
    "Давайте повторим то, что мы прошли в этой секции. Напишите код, который создаст признак hour из признака time в датасете log.csv. Для этого:\n",
    "\n",
    "1. загрузите датасет log.csv в переменную log, дальше работать будем с ней;\n",
    "\n",
    "2. установите имена столбцов: ['user_id', 'time', 'bet', 'win'];\n",
    "\n",
    "3. избавьтесь от пропусков в log;\n",
    "\n",
    "4. приведите переменную time к подходящему для извлечения признаков виду;\n",
    "\n",
    "5. получите значение часа для каждой строки в переменной time и запишите в столбец hour в log.\n",
    "\n",
    "Результатом будет таблица log со столбцом hour внутри."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('./Unit3_data/log.xlt', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "log.dropna(inplace=True)\n",
    "log['hour'] = pd.to_datetime(log.time.apply(lambda x: x[1:])).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************************\n",
    "# *******************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Используйте оригинальный датасет log.csv. Результат запишите числом в поле ниже.\n",
    "\n",
    "Подсказка: можно использовать value_counts().\n",
    "\n",
    "Посчитайте, сколько раз люди приходили, но не делали ставок. Для этого заполните пропуски в столбце bet значением 0 и посчитайте количество таких значений.\n",
    "Например, 66."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('./Unit3_data/log.xlt', header=None)\n",
    "log.columns = ['user_id','time','bet','win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25 ms ± 39.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "log.fillna({'bet':0}).bet.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "log.fillna({'bet':0}).bet.tolist().count(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Заполнение с помощью функции   \n",
    "Теперь поработаем с признаком win, в котором тоже есть пропуски.\n",
    "\n",
    "Иногда нужно заполнять пропуски не одним и тем же числом, а разными, в зависимости от какого-то условия. Перед нами именно этот случай.\n",
    "\n",
    "Предположим, что если в признаке win находится пропуск, то выигрыша не было. Здесь два возможных случая:\n",
    " - Человек не делал ставки и ничего не выиграл. То есть просто пришел, посмотрел и ушел.  \n",
    " - Человек делал ставку, но не выиграл. Значит, выигрыш на самом деле является отрицательным значением - это проигрыш.\n",
    "\n",
    "Предлагаем вам написать метод, который заполнит пропуски в признаке win в соответствии с предположением выше. \n",
    "\n",
    "Для этого можно применить метод apply() ко всей таблице и передать ему функцию, которая вычисляет размер выигрыша (или проигрыша) по следующей схеме:\n",
    "\n",
    " - Если значение в столбце win существует (не пропуск) - вернуть это же значение. Это значит, что человек выиграл.\n",
    " - Если вместо значения в столбце win пропуск, вернуть 0.\n",
    "На выходе получится столбец без пропусков. Следующим шагом будет замена старого столбца win на новый.\n",
    "\n",
    "Выглядеть это будет примерно так:\n",
    "\n",
    "```python\n",
    "def fillna_win(row):  \n",
    "    # Нужно дописать  \n",
    "  \n",
    "# Применяем функцию  \n",
    "new_win = log.apply(lambda row: fillna_win(row), axis=1)  \n",
    "  \n",
    "# Заменяем старый столбец с пропусками на новый без пропусков  \n",
    "log['win'] = new_win  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Используйте оригинальный датасет log.csv. Проделайте с ним действия из задания 1, расположенного выше на этой странице, и из пункта \"Заполнение с помощью функции\".\n",
    "\n",
    "Результат запишите числом в поле ниже.\n",
    "\n",
    "Подсказка: можно использовать sum().\n",
    "\n",
    "Посчитайте, сколько раз участники ставок проиграли деньги. То есть посчитайте количество строк, для которых в столбце win находится отрицательное значение.\n",
    "Например, 616."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_win_2(row):\n",
    "    row.win = row.win if row.win==row.win  else 0 - row.bet\n",
    "    return row\n",
    "\n",
    "def fillna_win(row):\n",
    "    row.win = row.win if row.win==row.win  else 0 - row.bet\n",
    "    return row.win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('./Unit3_data/log.xlt', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "log.fillna({'bet':0}, inplace=True)\n",
    "\n",
    "new_win = log.apply(lambda row: fillna_win(row), axis=1)\n",
    "log['win'] = new_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(log.win < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************************\n",
    "# *******************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Используйте модифицированный в прошлой секции датасет log.csv. Результат запишите числом в поле ниже.\n",
    "\n",
    "Подсказка - можно использовать sum().\n",
    "\n",
    "Создайте признак net, хранящий сумму выигрыша с учетом ставки. Для этого из признака win поэлементно вычтите признак bet и запишите в новый столбец. После этого посчитайте, у скольких людей выигрыш положительный.\n",
    "Например, 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv('./Unit3_data/log.xlt', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "log.fillna({'bet':0, 'win': 0}, inplace=True)\n",
    "log['net'] = log.win - log.bet\n",
    "(log.net>0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Используйте датасет log.csv, получившийся в результате выполнения предыдущего задания. Посчитайте среднее значение выигрыша (из столбца net) в тех случаях, когда выигрыш больше 0. Результат округлите до целого, отбросив дробную часть.\n",
    "\n",
    "Подсказка: можно использовать mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80253"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(log.net[log.net>0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "Используйте датасет log.csv, получившийся в результате выполнения первого задания этого блока. Посчитайте медианное значение выигрыша (из столбца net) в тех случаях, когда выигрыш больше 0. Результат округлите до целого, отбросив дробную часть.\n",
    "\n",
    "Подсказка: можно использовать median()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5347"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(log.net[log.net>0].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7 Сколько можно выиграть/проиграть?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Используйте модифицированный исходный датасет log.csv.\n",
    "\n",
    "При модификации датасета log.csv, пропущенные значения в столбцах bet и win замените на 0, cоздайте столбец net, хранящий сумму выигрыша с учетом ставки (для этого из столбца win поэлементно вычтите столбец bet и запишите в новый столбец).\n",
    "\n",
    "Посчитайте, какой процент посещений букмекерской конторы оборачивался ставкой. Для этого поделите количество ставок (значений больше 0) на общее количество посещений конторы. Результат округлите до одного знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.5"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv('./Unit3_data/log.xlt', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "log.fillna({'bet':0, 'win': 0}, inplace=True)\n",
    "log['net'] = log.win - log.bet\n",
    "\n",
    "(log.bet>0).sum()/log.bet.size * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Используйте датасет log.csv, получившийся в результате модификации при выполнении первого задания этого блока.\n",
    "\n",
    "Посчитайте среднее значение ставки (из столбца bet) в тех случаях, когда ставка была сделана. Результат округлите до целого, отбросив дробную часть.\n",
    "Подсказка: можно использовать mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6785"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(log.bet[log.bet>0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "Используйте датасет log.csv, получившийся в результате модификации при выполнении первого задания этого блока.\n",
    "\n",
    "Посчитайте средний выигрыш (из столбца net) в тех случаях, когда ставка была сделана. Результат округлите до целого, отбросив дробную часть.\n",
    "Пояснение: выигрыш в данном случае означает изменение количества денег и может быть отрицательным. В таком случае это проигрыш.\n",
    "\n",
    "Подсказка: можно использовать mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20421"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(log.net[log.bet>0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "Используйте датасет log.csv, получившийся в результате модификации при выполнении первого задания этого блока.\n",
    "\n",
    "Посчитайте среднюю сумму потерь при проигрыше (из столбца net). Результат округлите до целого, отбросив дробную часть.\n",
    "Пояснение: ответ должен быть дан в виде отрицательного числа.\n",
    "\n",
    "Подсказка: можно использовать mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3372"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(log.net[log.net<0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5\n",
    "Посчитайте, какой процент ставок заканчивается выигрышем, а какой - проигрышем. Сравните эти значения и ответьте, какое из них больше.\n",
    "\n",
    "Выберите пункт из списка ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2845360824742268, 0.7154639175257732)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(log.net>0)/sum(log.bet>0), sum(log.net<0)/sum(log.bet>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6*\n",
    "Давайте повторим то, что мы прошли в этой секции. Напишите код, который узнает, чему была равна минимальная ставка и сколько людей сделали такую ставку. Для этого:\n",
    "\n",
    "1. загрузите датасет log.csv;\n",
    "\n",
    "2. посчитайте, чему равна минимальная ставка;\n",
    "\n",
    "3. посчитайте, сколько раз была сделана минимальная ставка, и запишите результат в переменную min_bet_amount в виде целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('./Unit3_data/log.xlt', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "min_bet_amount = log.bet.tolist().count(log.bet.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.8 Повторение merge/groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что сделали до этого\n",
    "Теперь мы снова будем использовать log.csv и users.csv вместе.\n",
    "\n",
    "Повторим часть предобработки, которую мы должны были выполнить ранее:\n",
    "```python\n",
    "# Приведем признак user_id к одному формату в обоих датасетах  \n",
    "us.user_id = us.user_id.apply(lambda x: x.lower())\n",
    "\n",
    "# Избавимся от ошибок в user_id  \n",
    "log = log[log.user_id != '#error']  \n",
    "log.user_id = log.user_id.str.split(' - ').apply(lambda x: x[1]) \n",
    "```\n",
    "Это будет нужно для того, чтобы объединить оба датасета и работать с едиными данными для проведения продвинутого анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('./Unit3_data/users.xlt',sep='\\t', encoding = 'koi8_r')\n",
    "users.columns = ['user_id','email','geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.user_id = users.user_id.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = log[log.user_id != '#error']\n",
    "\n",
    "log.user_id = log.user_id.str.split(' - ').apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge\n",
    "Теперь объединим данные с помощью метода pd.merge():\n",
    "\n",
    "```python\n",
    "pd.merge(dataframe1, dataframe2, on='feature_name')  \n",
    "```\n",
    "Первые два аргумента - таблицы, которые нужно будет объединить.\n",
    "\n",
    "Третий аргумент - название признака, по которому будем объединять данные. Мы уже привели данные к одинаковому виду, и теперь их можно объединить по признаку 'user_id', чтобы получить полную информацию о пользователе. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "Объедините датасеты log.csv и users.csv по признаку user_id по примеру выше. Ответ запишите в поле ниже.\n",
    "\n",
    "Запишите количество строк в получившейся таблице.\n",
    "Например, 700."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(log, users, on='user_id')\n",
    "len(pd.merge(log, users, on='user_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby\n",
    "Теперь повторим groupby.\n",
    "\n",
    "Данный метод позволяет сгруппировать данные и применить к ним методы агрегации:\n",
    "\n",
    "```python\n",
    "df.groupby('user_id').win.median().median()  \n",
    "```\n",
    "В данном случае мы группируем данные по признаку user_id.\n",
    "\n",
    "После этого мы в каждой группе выбираем признак win.\n",
    "\n",
    "Затем мы берем медиану каждой группы по признаку win и на выходе получаем таблицу, в которой индексом является признак user_id. В этой таблице единственный столбец - медиана по каждой группе (то есть по каждому пользователю).\n",
    "\n",
    "Наконец, последний вызов median() дает нам медиану по предыдущему столбцу, то есть возвращает одно число."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5951.75"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('user_id').win.median().median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.9 Анализ по пользователям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Используйте датасет, который получился в результате всех преобразований выше (в том числе, заполнение пропусков). Ответ запишите в поле ниже в виде целого числа (отбросьте дробную часть).\n",
    "\n",
    "Посчитайте медиану баланса по каждому пользователю. Для этого сгруппируйте по пользователям, возьмите признак net, просуммируйте по каждому пользователю и получите медиану.\n",
    "Например, 10382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('./Unit3_data/users.xlt',sep='\\t', encoding = 'koi8_r')\n",
    "users.columns = ['user_id','email','geo']\n",
    "users.user_id = users.user_id.apply(lambda x: x.lower())\n",
    "\n",
    "log = pd.read_csv('./Unit3_data/log.xlt', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "\n",
    "log = log[log.user_id != '#error'] \n",
    "log.user_id = log.user_id.str.split(' - ').apply(lambda x: x[1])  \n",
    "log.time = log.time.apply(lambda x:str(x).replace(\"[\",\"\"))\n",
    "\n",
    "\n",
    "log.fillna({'bet':0, 'win': 0}, inplace=True)\n",
    "log['net'] = log.win - log.bet\n",
    "\n",
    "df = pd.merge(log, users, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1986.0, 2202.0)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by='user_id').net.sum().median(), log.groupby(by='user_id').net.sum().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(log.groupby(by='user_id').net.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_956'}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(log.user_id.unique())- set(users.user_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Используйте датасет, который получился в результате всех преобразований выше (в том числе, заполнение пропусков). Ответ запишите в поле ниже в виде целого числа (отбросьте дробную часть).\n",
    "\n",
    "Сколько раз в среднем каждый человек приходит, не делая ставок, при условии, что у этого человека все-таки есть хотя бы одна ставка? Например: Человек посетил букмекерскую контору 5 раз из них 1 раз сделал ставку, 4 раза нет - условие выполняется. Человек посетил букмекерскую контору 5 раз из них ни разу ставку не сделал - условие не выполняется. Для того, чтобы узнать это, просуммируйте в каждой группе количество записей со ставкой, равной 0, и поделите на общее количество групп. Если при этом в группе нет записей со ставкой больше 0, считаем количество записей в данной группе равным 0.\n",
    "Например, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.05"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('user_id').bet.apply(lambda x: (x==0).sum() if x.sum() else 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_1000': Int64Index([829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840], dtype='int64'),\n",
       " 'user_900': Int64Index([56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], dtype='int64'),\n",
       " 'user_901': Int64Index([512, 513, 514, 515, 516, 517, 518, 519], dtype='int64'),\n",
       " 'user_902': Int64Index([917, 918, 919, 920, 921, 922, 923, 924], dtype='int64'),\n",
       " 'user_903': Int64Index([23, 24, 25, 26, 27, 28, 29, 30, 31], dtype='int64'),\n",
       " 'user_904': Int64Index([813, 814, 815, 816, 817, 818], dtype='int64'),\n",
       " 'user_905': Int64Index([388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399], dtype='int64'),\n",
       " 'user_906': Int64Index([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], dtype='int64'),\n",
       " 'user_907': Int64Index([606, 607, 608, 609, 610, 611, 612], dtype='int64'),\n",
       " 'user_908': Int64Index([729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741], dtype='int64'),\n",
       " 'user_909': Int64Index([897, 898, 899, 900, 901], dtype='int64'),\n",
       " 'user_910': Int64Index([584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596,\n",
       "             597],\n",
       "            dtype='int64'),\n",
       " 'user_911': Int64Index([876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887], dtype='int64'),\n",
       " 'user_912': Int64Index([494, 495, 496, 497, 498, 499, 500, 501, 502, 503], dtype='int64'),\n",
       " 'user_913': Int64Index([314, 315, 316, 317, 318, 319, 320, 321, 322, 323], dtype='int64'),\n",
       " 'user_914': Int64Index([681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691], dtype='int64'),\n",
       " 'user_915': Int64Index([449, 450, 451, 452, 453], dtype='int64'),\n",
       " 'user_916': Int64Index([333, 334, 335, 336, 337, 338, 339, 340, 341, 342], dtype='int64'),\n",
       " 'user_917': Int64Index([45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], dtype='int64'),\n",
       " 'user_918': Int64Index([366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377], dtype='int64'),\n",
       " 'user_919': Int64Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64'),\n",
       " 'user_920': Int64Index([419, 420, 421, 422, 423, 424, 425, 426, 427], dtype='int64'),\n",
       " 'user_921': Int64Index([454, 455, 456, 457], dtype='int64'),\n",
       " 'user_922': Int64Index([770, 771, 772, 773, 774, 775, 776, 777, 778, 779], dtype='int64'),\n",
       " 'user_923': Int64Index([699, 700, 701, 702, 703, 704, 705, 706], dtype='int64'),\n",
       " 'user_924': Int64Index([400, 401, 402, 403, 404, 405, 406, 407, 408], dtype='int64'),\n",
       " 'user_925': Int64Index([950, 951, 952, 953, 954, 955, 956, 957], dtype='int64'),\n",
       " 'user_926': Int64Index([656, 657, 658, 659, 660, 661, 662], dtype='int64'),\n",
       " 'user_927': Int64Index([225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
       "             238],\n",
       "            dtype='int64'),\n",
       " 'user_928': Int64Index([477, 478, 479, 480, 481, 482, 483, 484, 485], dtype='int64'),\n",
       " 'user_929': Int64Index([205, 206, 207, 208, 209, 210, 211, 212, 213], dtype='int64'),\n",
       " 'user_930': Int64Index([742, 743, 744, 745, 746, 747, 748, 749, 750, 751], dtype='int64'),\n",
       " 'user_931': Int64Index([819, 820, 821, 822, 823, 824, 825, 826, 827, 828], dtype='int64'),\n",
       " 'user_932': Int64Index([970, 971, 972, 973, 974], dtype='int64'),\n",
       " 'user_933': Int64Index([530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540], dtype='int64'),\n",
       " 'user_934': Int64Index([958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969], dtype='int64'),\n",
       " 'user_935': Int64Index([437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448], dtype='int64'),\n",
       " 'user_936': Int64Index([762, 763, 764, 765, 766, 767, 768, 769], dtype='int64'),\n",
       " 'user_937': Int64Index([299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "             312, 313],\n",
       "            dtype='int64'),\n",
       " 'user_938': Int64Index([343, 344, 345, 346, 347, 348, 349, 350, 351, 352], dtype='int64'),\n",
       " 'user_939': Int64Index([858, 859, 860, 861, 862, 863, 864, 865, 866], dtype='int64'),\n",
       " 'user_940': Int64Index([359, 360, 361, 362, 363, 364, 365], dtype='int64'),\n",
       " 'user_941': Int64Index([613, 614, 615, 616, 617, 618, 619, 620], dtype='int64'),\n",
       " 'user_942': Int64Index([193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204], dtype='int64'),\n",
       " 'user_943': Int64Index([428, 429, 430, 431, 432, 433, 434, 435, 436], dtype='int64'),\n",
       " 'user_944': Int64Index([486, 487, 488, 489, 490, 491, 492, 493], dtype='int64'),\n",
       " 'user_945': Int64Index([718, 719, 720, 721, 722], dtype='int64'),\n",
       " 'user_946': Int64Index([841, 842, 843, 844, 845, 846, 847, 848, 849], dtype='int64'),\n",
       " 'user_947': Int64Index([925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935], dtype='int64'),\n",
       " 'user_948': Int64Index([324, 325, 326, 327, 328, 329, 330, 331, 332], dtype='int64'),\n",
       " 'user_949': Int64Index([249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
       "             262],\n",
       "            dtype='int64'),\n",
       " 'user_950': Int64Index([888, 889, 890, 891, 892, 893, 894, 895, 896], dtype='int64'),\n",
       " 'user_951': Int64Index([239, 240, 241, 242, 243, 244, 245, 246, 247, 248], dtype='int64'),\n",
       " 'user_952': Int64Index([90, 91, 92, 93, 94, 95, 96, 97, 98, 99], dtype='int64'),\n",
       " 'user_953': Int64Index([942, 943, 944, 945, 946, 947, 948, 949], dtype='int64'),\n",
       " 'user_954': Int64Index([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], dtype='int64'),\n",
       " 'user_955': Int64Index([632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642], dtype='int64'),\n",
       " 'user_957': Int64Index([676, 677, 678, 679, 680], dtype='int64'),\n",
       " 'user_958': Int64Index([409, 410, 411, 412, 413, 414, 415, 416, 417, 418], dtype='int64'),\n",
       " 'user_959': Int64Index([797, 798, 799, 800, 801, 802, 803], dtype='int64'),\n",
       " 'user_960': Int64Index([378, 379, 380, 381, 382, 383, 384, 385, 386, 387], dtype='int64'),\n",
       " 'user_961': Int64Index([867, 868, 869, 870, 871, 872, 873, 874, 875], dtype='int64'),\n",
       " 'user_962': Int64Index([780, 781, 782, 783, 784, 785, 786, 787, 788, 789], dtype='int64'),\n",
       " 'user_963': Int64Index([804, 805, 806, 807, 808, 809, 810, 811, 812], dtype='int64'),\n",
       " 'user_964': Int64Index([134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144], dtype='int64'),\n",
       " 'user_965': Int64Index([790, 791, 792, 793, 794, 795, 796], dtype='int64'),\n",
       " 'user_966': Int64Index([116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
       "             129, 130, 131, 132, 133],\n",
       "            dtype='int64'),\n",
       " 'user_967': Int64Index([707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717], dtype='int64'),\n",
       " 'user_968': Int64Index([153, 154, 155, 156, 157, 158, 159, 160], dtype='int64'),\n",
       " 'user_969': Int64Index([504, 505, 506, 507, 508, 509, 510, 511], dtype='int64'),\n",
       " 'user_970': Int64Index([850, 851, 852, 853, 854, 855, 856, 857], dtype='int64'),\n",
       " 'user_971': Int64Index([555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566], dtype='int64'),\n",
       " 'user_972': Int64Index([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
       "             113, 114, 115],\n",
       "            dtype='int64'),\n",
       " 'user_973': Int64Index([8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], dtype='int64'),\n",
       " 'user_974': Int64Index([161, 162, 163, 164, 165, 166, 167, 168], dtype='int64'),\n",
       " 'user_975': Int64Index([936, 937, 938, 939, 940, 941], dtype='int64'),\n",
       " 'user_976': Int64Index([214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224], dtype='int64'),\n",
       " 'user_977': Int64Index([567, 568, 569, 570, 571, 572, 573, 574, 575, 576], dtype='int64'),\n",
       " 'user_978': Int64Index([145, 146, 147, 148, 149, 150, 151, 152], dtype='int64'),\n",
       " 'user_979': Int64Index([577, 578, 579, 580, 581, 582, 583], dtype='int64'),\n",
       " 'user_980': Int64Index([70, 71, 72, 73, 74, 75, 76, 77, 78], dtype='int64'),\n",
       " 'user_981': Int64Index([752, 753, 754, 755, 756, 757, 758, 759, 760, 761], dtype='int64'),\n",
       " 'user_982': Int64Index([466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476], dtype='int64'),\n",
       " 'user_983': Int64Index([902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914,\n",
       "             915, 916],\n",
       "            dtype='int64'),\n",
       " 'user_984': Int64Index([663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675], dtype='int64'),\n",
       " 'user_985': Int64Index([275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287,\n",
       "             288],\n",
       "            dtype='int64'),\n",
       " 'user_986': Int64Index([541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553,\n",
       "             554],\n",
       "            dtype='int64'),\n",
       " 'user_987': Int64Index([263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274], dtype='int64'),\n",
       " 'user_988': Int64Index([692, 693, 694, 695, 696, 697, 698], dtype='int64'),\n",
       " 'user_989': Int64Index([621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631], dtype='int64'),\n",
       " 'user_990': Int64Index([180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192], dtype='int64'),\n",
       " 'user_991': Int64Index([643, 644, 645, 646, 647, 648, 649, 650], dtype='int64'),\n",
       " 'user_992': Int64Index([289, 290, 291, 292, 293, 294, 295, 296, 297, 298], dtype='int64'),\n",
       " 'user_993': Int64Index([723, 724, 725, 726, 727, 728], dtype='int64'),\n",
       " 'user_994': Int64Index([598, 599, 600, 601, 602, 603, 604, 605], dtype='int64'),\n",
       " 'user_995': Int64Index([520, 521, 522, 523, 524, 525, 526, 527, 528, 529], dtype='int64'),\n",
       " 'user_996': Int64Index([651, 652, 653, 654, 655], dtype='int64'),\n",
       " 'user_997': Int64Index([353, 354, 355, 356, 357, 358], dtype='int64'),\n",
       " 'user_998': Int64Index([169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], dtype='int64'),\n",
       " 'user_999': Int64Index([458, 459, 460, 461, 462, 463, 464, 465], dtype='int64')}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('user_id').groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3**\n",
    "Используйте датасет, который получился в результате всех преобразований выше (в том числе, заполнение пропусков). Ответ запишите в поле ниже в виде целого числа - количества дней.\n",
    "\n",
    "Сколько в среднем времени проходит между появлением человека в сервисе и первой ставкой? Считать нужно только тех, кто делал ставку. Для того, чтобы узнать это, напишите метод, считающий минимальное время среди ставок, равных 0, и минимальное время среди ставок больше 0. После этого верните разницу между вторым и первым числом. Пройдитесь по всем группам в цикле. Если в группе нет ставок больше 0, пропустите эту группу. Просуммируйте разницу во времени для каждой группы (с помощью метода, описанного выше) и поделите на количество групп, которые вы не пропустили.\n",
    "Например, если ваш результат Timedelta('23 days 12:24:32'), то в поле пишите 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('./Unit3_data/log.xlt', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "\n",
    "log = log[log.user_id != '#error'] \n",
    "log.user_id = log.user_id.str.split(' - ').apply(lambda x: x[1])  \n",
    "log.time = log.time.apply(lambda x:str(x).replace(\"[\",\"\"))\n",
    "log.time = pd.to_datetime(log.time)\n",
    "\n",
    "log.fillna({'bet':0, 'win': 0}, inplace=True)\n",
    "log['net'] = log.win - log.bet\n",
    "\n",
    "df = pd.merge(log, users, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('46 days 06:54:48')"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_delta(df): \n",
    "    return df.time[df.bet > 0].min() - df.time[df.bet == 0].min()\n",
    "\n",
    "group = df.groupby(by='user_id' )\n",
    "(group.apply(time_delta)[group.bet.sum() != 0]).sum() / sum(group.bet.sum() != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.10 Анализ по городам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Используйте датасет, который получился в результате всех преобразований в прошлой секции (в том числе, заполнение пропусков).\n",
    "\n",
    "Ответ запишите в поле ниже в виде одного слова, с большой буквы.\n",
    "\n",
    "Наибольший суммарный выигрыш среди всех городов имеет Москва. Посчитайте следующий за ней город. Для этого сгруппируйте по городам, возьмите признак win, просуммируйте по каждому городу, отсортируйте и получите второй город.\n",
    "Например, Иннополис."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Воронеж'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = df.groupby(by = 'geo').win.sum()\n",
    "aa.sort_values().index[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'time', 'bet', 'win', 'net', 'email', 'geo'], dtype='object')"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2*\n",
    "Используйте датасет, который получился в результате всех преобразований в прошлой секции (в том числе, заполнение пропусков).\n",
    "\n",
    "Подсказки:\n",
    "\n",
    "1. Можно использовать методы min() и max().\n",
    "\n",
    "2. Учитывайте, что минимальная ставка, это ставка, которая была сделана, т.е. если ставка равна нулю - значит ставки не было.\n",
    "\n",
    "3. Ответ запишите в поле ниже в виде целого числа (нужно отбросить дробную часть).\n",
    "\n",
    "Во сколько раз различаются максимальное и минимальное значение средней ставки по городам? Для того, чтобы это посчитать, нужно сгруппировать по городам, взять среднее от признака bet, найти максимальное и минимальное значения, затем поделить одно на другое.\n",
    "Например, 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = df[df.bet > 0].groupby(by = 'geo')\n",
    "int(group.bet.mean().max() / group.bet.mean().min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "Давайте повторим все, что мы прошли в этой секции. Напишите код, который посчитает, сколько раз пользователи приходили в букмекерскую контору в каждом городе. Для этого:\n",
    "\n",
    "1. загрузите датасеты log.csv и users.csv;\n",
    "\n",
    "2. удалите user_id с ошибкой (#error) и приведите признак user_id к одному виду в обоих датасетах;\n",
    "\n",
    "3. слейте два датасета в один по признаку user_id;\n",
    "\n",
    "4. сгруппируйте данные по правильному признаку (какому - вам нужно понять самим), затем выберите user_id и воспользуйтесь функцией count() для подсчета наблюдений в каждой группе;\n",
    "\n",
    "5. результат (таблицу) запишите в sample2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('./Unit3_data/users.xlt',sep='\\t', encoding = 'koi8_r')\n",
    "users.columns = ['user_id','email','geo']\n",
    "users.user_id = users.user_id.apply(lambda x: x.lower())\n",
    "\n",
    "log = pd.read_csv('./Unit3_data/log.xlt', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "\n",
    "log = log[log.user_id != '#error'] \n",
    "log.user_id = log.user_id.str.split(' - ').apply(lambda x: x[1])  \n",
    "log.time = log.time.apply(lambda x:str(x).replace(\"[\",\"\"))\n",
    "\n",
    "\n",
    "log.fillna({'bet':0, 'win': 0}, inplace=True)\n",
    "log['net'] = log.win - log.bet\n",
    "\n",
    "df = pd.merge(log, users, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo\n",
       "Арзангелтск         96\n",
       "Воронеж             88\n",
       "Екатеринбург        49\n",
       "Ижевск              61\n",
       "Казань              66\n",
       "Краснодар           86\n",
       "Красноярск          56\n",
       "Москва              61\n",
       "Пермь               55\n",
       "Санкт-Петербург    115\n",
       "Ставрополь          36\n",
       "Тюмень              32\n",
       "Хабаровск           60\n",
       "Ярославль           89\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2 = df.groupby('geo').user_id.count()\n",
    "sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Арзангелтск</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Воронеж</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Екатеринбург</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ижевск</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Казань</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Краснодар</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Красноярск</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Москва</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Пермь</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Санкт-Петербург</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ставрополь</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Тюмень</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Хабаровск</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ярославль</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id\n",
       "geo                     \n",
       "Арзангелтск           96\n",
       "Воронеж               88\n",
       "Екатеринбург          49\n",
       "Ижевск                61\n",
       "Казань                66\n",
       "Краснодар             86\n",
       "Красноярск            56\n",
       "Москва                61\n",
       "Пермь                 55\n",
       "Санкт-Петербург      115\n",
       "Ставрополь            36\n",
       "Тюмень                32\n",
       "Хабаровск             60\n",
       "Ярославль             89"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('geo').agg({'user_id':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('geo').agg()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
