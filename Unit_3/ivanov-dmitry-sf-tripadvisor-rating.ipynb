{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание задачи\n",
    "## В задачи пректа входит:\n",
    "\n",
    " - Обработка предоставленных данных: нахождение и заполнение пропусков, кодировка, нормализация признаков.\n",
    " - Привлечение дополнительных данных для обогащения датасета.\n",
    " - Создание новых признаков с использованием для этого как предоставленных данные так и дополнительно привлченных.\n",
    " - Обучение и тестирование модели на полученных признаках с применением обучающей и валидационной части данных\n",
    " - Отбор полезных признаков с использованием обученной модели, обучение модели на отобранных признаках\n",
    " - Получение предсказанных моделью значений, подготовка и отправка submission. \n",
    "\n",
    "## Описание датасета\n",
    "Первоначальная версия датасета состоит из десяти столбцов, содержащих следующую информацию:\n",
    "\n",
    " - **Restaurant_id** — идентификационный номер ресторана / сети ресторанов;\n",
    " - **City** — город, в котором находится ресторан;\n",
    " - **Cuisine Style** — кухня или кухни, к которым можно отнести блюда, предлагаемые в ресторане;\n",
    " - **Ranking** — место, которое занимает данный ресторан среди всех ресторанов своего города;\n",
    " - **Rating** — рейтинг ресторана по данным TripAdvisor (именно это значение должна будет предсказывать модель);\n",
    " - **Price Range** — диапазон цен в ресторане;\n",
    " - **Number of Reviews** — количество отзывов о ресторане;\n",
    " - **Reviews** — данные о двух отзывах, которые отображаются на сайте ресторана;\n",
    " - **URL_TA** — URL страницы ресторана на TripAdvosor;\n",
    " - **ID_TA** — идентификатор ресторана в базе данных TripAdvisor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек, установка параметров, определение функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции используемые в ноутбуке\n",
    "\n",
    "def pre_process(df):\n",
    "    '''\n",
    "    реализация предобработки датасета из учебного проекта о_вкусной_и_здоровой_пище\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    df: pd.DataFrame\n",
    "        датафрейм для предобработки  \n",
    "    \n",
    "    Returns\n",
    "    -------  \n",
    "    pd.DataFrame\n",
    "        содержит предобработанные признаки: City, Cuisine Style, Ranking, Price Range,\n",
    "        Number of Reviews, ID_TA\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    признак Restaurant_id функцией не обрабатывается ввиду неинформативности\n",
    "    признак Reviews функцией не обрабатываетсмя ввиду не использования признака непосредственно,\n",
    "        информация признака используется для создания нескольких новых признаков отдельно.\n",
    "    '''\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # предобработка признака City\n",
    "    df = pd.concat([df,pd.get_dummies(df.City)],axis=1)\n",
    "\n",
    "    # предобработка признака Cuisine Style\n",
    "    df['Cuisine_Style_NaN'] = df.Cuisine_Style.isna().astype(int8)\n",
    "    df.Cuisine_Style = df.Cuisine_Style.fillna(\"['Nan_Style']\").str[2:-2].str.split(\"', '\")\n",
    "    cuisine_styles = sorted(set(df.Cuisine_Style.sum()))\n",
    "    for style in cuisine_styles:\n",
    "        df[style] = df.Cuisine_Style.apply(lambda x: int(style in x))\n",
    "\n",
    "    # предобработка признака Ranking\n",
    "    scaler = MinMaxScaler()\n",
    "    grouped_by_City = df.groupby('City')\n",
    "    for group in grouped_by_City.groups:\n",
    "        index = grouped_by_City.groups[group]\n",
    "        scaled_values = scaler.fit_transform(df[['Ranking']].loc[index])\n",
    "        df.Ranking.loc[index] = pd.Series(scaled_values.flatten(), index=index)\n",
    "    \n",
    "    # предобработка признака Price Range\n",
    "    df['Price_Range_NaN'] = df.Price_Range.isna().astype(int8)\n",
    "    price_range_encod = {'$': 1, '$$ - $$$': 2, '$$$$': 3}\n",
    "    df['Price_Range_enc'] = df.Price_Range.map(price_range_encod)\n",
    "    df.Price_Range_enc.fillna(df.Price_Range_enc.mean(),inplace=True)\n",
    "\n",
    "    # предобработка признака Number of Reviews\n",
    "    df['NoR_NaN'] = df.Number_of_Reviews.isna().astype(int8)\n",
    "    df.Number_of_Reviews.fillna(1,inplace=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    for group in grouped_by_City.groups:\n",
    "        index = grouped_by_City.groups[group]\n",
    "        scaled_values = scaler.fit_transform(df[['Number_of_Reviews']].loc[index])\n",
    "        df.Number_of_Reviews.loc[index] = pd.Series(scaled_values.flatten(), index=index)\n",
    "\n",
    "    # предобработка признака ID_TA\n",
    "    df.ID_TA = df.ID_TA.str[1:].astype(int)\n",
    "    \n",
    "    # предобработка признака URL_TA\n",
    "    df['g_id'] = df.URL_TA.apply(lambda x: int(x[x.find('-g')+2: x.find('-',x.find('-g')+2)]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_cuisine_styles(row):\n",
    "    '''\n",
    "    получение списка уникальных наименований стиля кухни, встречающихся в колонке Cuisine_Style\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    row: pd.Series, str\n",
    "        содержит названия стилей кухни в ресторане в виде строкового представления списка \n",
    "        (формат \"['Стиль_1', 'Стиль_2', ..., 'Стиль_N']\")\n",
    "    \n",
    "    Returns\n",
    "    -------  \n",
    "    list, str\n",
    "        список уникальных наименований стиля кухни, встречающихся в колонке Cuisine_Style             \n",
    "    '''     \n",
    "    return sorted(set(row.fillna(\"['Nan_Style']\").str[2:-2].str.split(\"', '\").sum()))\n",
    "\n",
    "def get_review_texts(row):\n",
    "    '''\n",
    "    извлечение текста отзыва/ов из признака Reviews\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    row: pd.Series, str\n",
    "        содержит текст отзыва/ов в формате \"[['текст/-ы_отзыва/-ов'], [...]]\"\n",
    "    \n",
    "    Returns\n",
    "    -------  \n",
    "    pd.Series, str\n",
    "        текст/-ы отзыва/ов из признака Reviews \n",
    "    '''\n",
    "    return row.apply(lambda x:x[: x.find('], [')+1]).str.replace(\"[\\[\\]]\", \"\")\n",
    "    \n",
    "def get_review_date_lists(row):\n",
    "    '''\n",
    "    извлечение в строковом виде даты отзыва/-ов из признака Reviews\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    row: pd.Series, str\n",
    "        содержит дату отзыва/ов в формате \"[[...], ['дата/-ы_отзыва/-ов']]\"\n",
    "    \n",
    "    Returns\n",
    "    -------  \n",
    "    pd.Series, str\n",
    "        дата/-ы отзыва/ов из признака Reviews              \n",
    "    '''\n",
    "    return row.apply(lambda x:x[ x.find('], [')+3:]).str.replace(\"[\\[\\]' ]\", \"\").str.split(\",\")\n",
    "\n",
    "def get_rest_names(row):\n",
    "    '''\n",
    "    извлечение названия ресторана из  из признака URL_TA\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    row: pd.Series, str\n",
    "        содержит название ресорана в формате \"...-Reviews-НАЗВАНИЕ_РЕСТОРАНА-...\"\n",
    "    \n",
    "    Returns\n",
    "    -------  \n",
    "    pd.Series, str\n",
    "        названия ресторана из  из признака URL_TA              \n",
    "    ''' \n",
    "    return row.apply(lambda x: x[x.find('Reviews-')+8: x.find('-',x.find('Reviews-')+8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# установка параметров\n",
    "%pylab inline\n",
    "\n",
    "pd.set_option('display.max_rows', 50) # выведем больше строк\n",
    "pd.set_option('display.max_columns', 30) # выведем больше колонок\n",
    "\n",
    "# альтернативные пути на kaggle и локальный (НЕ ЗАБЫТЬ МЕНЯТЬ!)\n",
    "path = './Preproject3_data/'\n",
    "# path = '/kaggle/input/sf-dst-restaurant-rating/'\n",
    "\n",
    "# url-ы файов с позитивной и негативной английской лексикой \n",
    "pos_url = \\\n",
    "'https://gist.githubusercontent.com/mkulakowski2/4289437/raw/1bb4d7f9ee82150f339f09b5b1a0e6823d633958/positive-words.txt'\n",
    "neg_url = \\\n",
    "'https://gist.githubusercontent.com/mkulakowski2/4289441/raw/dad8b64b307cd6df8068a379079becbb3f91101a/negative-words.txt'\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Preproject3_data/kaggle_task.csv\n",
      "./Preproject3_data/main_task.csv\n",
      "./Preproject3_data/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# проверка пути и имен файлов\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение данных\n",
    "df_train = pd.read_csv(f'{path}main_task.csv')\n",
    "df_test = pd.read_csv(f'{path}kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(f'{path}sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ознакомление с данными\n",
    "\n",
    "Для корректной обработки признаков объединяем трейн и тест в один датасет ***data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на полученный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 11 columns):\n",
      "Restaurant_id        50000 non-null object\n",
      "City                 50000 non-null object\n",
      "Cuisine Style        38410 non-null object\n",
      "Ranking              50000 non-null float64\n",
      "Price Range          32639 non-null object\n",
      "Number of Reviews    46800 non-null float64\n",
      "Reviews              49998 non-null object\n",
      "URL_TA               50000 non-null object\n",
      "ID_TA                50000 non-null object\n",
      "sample               50000 non-null int64\n",
      "Rating               50000 non-null float64\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>City</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "      <th>sample</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21569</td>\n",
       "      <td>id_4698</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>['Spanish']</td>\n",
       "      <td>4701.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g187514-d7368884-Reviews-Lo...</td>\n",
       "      <td>d7368884</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3085</td>\n",
       "      <td>id_3085</td>\n",
       "      <td>Rome</td>\n",
       "      <td>['Italian', 'Steakhouse', 'Pizza', 'Mediterran...</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>647.0</td>\n",
       "      <td>[['Well worth a visit', 'A good choice'], ['10...</td>\n",
       "      <td>/Restaurant_Review-g187791-d1950660-Reviews-Ga...</td>\n",
       "      <td>d1950660</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47907</td>\n",
       "      <td>id_2226</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>['Dutch', 'European']</td>\n",
       "      <td>2231.0</td>\n",
       "      <td>$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['Great coffee and breakfast'], ['12/02/2017']]</td>\n",
       "      <td>/Restaurant_Review-g188590-d13171238-Reviews-2...</td>\n",
       "      <td>d13171238</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37556</td>\n",
       "      <td>id_7772</td>\n",
       "      <td>London</td>\n",
       "      <td>['Pizza', 'Italian']</td>\n",
       "      <td>7781.0</td>\n",
       "      <td>$</td>\n",
       "      <td>26.0</td>\n",
       "      <td>[['Good Value Pizza', 'Very nice pizza'], ['12...</td>\n",
       "      <td>/Restaurant_Review-g186338-d7589191-Reviews-Pi...</td>\n",
       "      <td>d7589191</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27493</td>\n",
       "      <td>id_9842</td>\n",
       "      <td>Paris</td>\n",
       "      <td>['Middle Eastern']</td>\n",
       "      <td>9844.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>52.0</td>\n",
       "      <td>[['Ali', 'Beautiful Paris!'], ['01/21/2017', '...</td>\n",
       "      <td>/Restaurant_Review-g187147-d2659008-Reviews-Le...</td>\n",
       "      <td>d2659008</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Restaurant_id       City  \\\n",
       "21569       id_4698     Madrid   \n",
       "3085        id_3085       Rome   \n",
       "47907       id_2226  Amsterdam   \n",
       "37556       id_7772     London   \n",
       "27493       id_9842      Paris   \n",
       "\n",
       "                                           Cuisine Style  Ranking Price Range  \\\n",
       "21569                                        ['Spanish']   4701.0    $$ - $$$   \n",
       "3085   ['Italian', 'Steakhouse', 'Pizza', 'Mediterran...   1355.0    $$ - $$$   \n",
       "47907                              ['Dutch', 'European']   2231.0           $   \n",
       "37556                               ['Pizza', 'Italian']   7781.0           $   \n",
       "27493                                 ['Middle Eastern']   9844.0    $$ - $$$   \n",
       "\n",
       "       Number of Reviews                                            Reviews  \\\n",
       "21569                5.0                                           [[], []]   \n",
       "3085               647.0  [['Well worth a visit', 'A good choice'], ['10...   \n",
       "47907                NaN   [['Great coffee and breakfast'], ['12/02/2017']]   \n",
       "37556               26.0  [['Good Value Pizza', 'Very nice pizza'], ['12...   \n",
       "27493               52.0  [['Ali', 'Beautiful Paris!'], ['01/21/2017', '...   \n",
       "\n",
       "                                                  URL_TA      ID_TA  sample  \\\n",
       "21569  /Restaurant_Review-g187514-d7368884-Reviews-Lo...   d7368884       1   \n",
       "3085   /Restaurant_Review-g187791-d1950660-Reviews-Ga...   d1950660       0   \n",
       "47907  /Restaurant_Review-g188590-d13171238-Reviews-2...  d13171238       1   \n",
       "37556  /Restaurant_Review-g186338-d7589191-Reviews-Pi...   d7589191       1   \n",
       "27493  /Restaurant_Review-g187147-d2659008-Reviews-Le...   d2659008       1   \n",
       "\n",
       "       Rating  \n",
       "21569     4.5  \n",
       "3085      0.0  \n",
       "47907     5.0  \n",
       "37556     4.0  \n",
       "27493     3.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Restaurant_id        <class 'str'>\n",
      "City                 <class 'str'>\n",
      "Cuisine Style        <class 'str'>\n",
      "Ranking              <class 'numpy.float64'>\n",
      "Price Range          <class 'str'>\n",
      "Number of Reviews    <class 'numpy.float64'>\n",
      "Reviews              <class 'str'>\n",
      "URL_TA               <class 'str'>\n",
      "ID_TA                <class 'str'>\n",
      "sample               <class 'numpy.int64'>\n",
      "Rating               <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "display(data.sample(5))\n",
    "print()\n",
    "for col in data.columns: print('{:20} {}'.format(col, type(data.loc[0][col])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски в явном виде *(NaN)* наблюдаются в четырех признаках: `Cuisine Style`, `Price Range`, `Number of Reviews` и `Reviews`. Кроме трех числовых признаков `Ranking`, `Rating` и `Number of Reviews`(один из них, `Rating` - целевая переменная) и одного вспомогательного временного столбца `sample` признаки представлены строками.\n",
    "\n",
    "Изменеим имена колонок для возможности обращения к колонкам как к атрибутам DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с предоставленными данными\n",
    "\n",
    "Сначала рассмотрим существующие признаки, выберем способы их предобработки, извлечем из существующих признаков информацию для создания новых.  \n",
    "Затем предобработаем существующие признаки согласно выбранным способам.  \n",
    "После этого создадим новые, при необходимости предобработаем и их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant_id\n",
    "Согласно описанию - идентификационный номер ресторана / сети ресторанов   \n",
    "\n",
    "Посмотрим на значения признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15243      id_10\n",
       "22343    id_1598\n",
       "34010    id_1984\n",
       "7346     id_7346\n",
       "41049    id_4490\n",
       "Name: Restaurant_id, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Restaurant_id.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения признака строковые, формата **'id_ЧИСЛО'**, где **ЧИСЛО** - некоторое целое число.\n",
    "Проверим, все ли значения выглядит подобным образом, для этого убедимся что первые три символа везде **'id_'** и что все значения после первых 3-х симвлов содержат только цифры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.Restaurant_id.str[:3] == 'id_').all(), data.Restaurant_id.str[3:].str.isnumeric().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё так и есть. Можно отбросить первые три символа(они везде одинаковые и потому не несут никакой информации) и в качестве значения признака принять приведенное к числовому виду **ЧИСЛО**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сопоставление `Restaurant id` с другими признаками из набора данных для обучения показало что как правило `Ranking` и **ЧИСЛО** в `Restaurant id` либо совпадают с точностью до 1 либо очень близки (возможно **ЧИСЛО** это `Ranking` в момент внесения ресторана в набор данных). Это наблюдение делает информативным казалось бы бесполезный признак.  \n",
    "UPD: Однако изучение набора данных для получения предсказания (Submission) показало, что в этих данных такая взаимосвязь отсутсвует. Вероятно оригигальные значения `Restaurant_id` были заменены. \"Казалось бы бесполезный признак\" не кажется таковым, он и вправду бесполезен для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков в признаке нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City\n",
    "Согласно описанию - город, в котором находится ресторан   \n",
    "\n",
    "Посмотрим на значения признака и заодно проверим, есть ли пропуски в неявном виде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Paris', 'Helsinki', 'Edinburgh', 'London', 'Bratislava', 'Lisbon',\n",
       "       'Budapest', 'Stockholm', 'Rome', 'Milan', 'Munich', 'Hamburg',\n",
       "       'Prague', 'Vienna', 'Dublin', 'Barcelona', 'Brussels', 'Madrid',\n",
       "       'Oslo', 'Amsterdam', 'Berlin', 'Lyon', 'Athens', 'Warsaw',\n",
       "       'Oporto', 'Krakow', 'Copenhagen', 'Luxembourg', 'Zurich', 'Geneva',\n",
       "       'Ljubljana'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.City.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков, выбросов нет. Остается привести признак в числовой вид, применив dummy-кодирование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuisine_Style\n",
    "согласно описанию - кухня или кухни, к которым можно отнести блюда, предлагаемые в ресторане.  \n",
    "\n",
    "Посмотрим как устроен признак:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33553                                          ['Italian']\n",
       "9427                                                   NaN\n",
       "199      ['Middle Eastern', 'Vegetarian Friendly', 'Veg...\n",
       "12447                                                  NaN\n",
       "39489                                                  NaN\n",
       "Name: Cuisine_Style, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Cuisine_Style.sample(5,random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала создадим признак `Cuisine_Style_NaN` - наличие/отсутствие пропуска в признаке.\n",
    "\n",
    "Затем заполним пропуски в признаке строковым значением *['Nan_Style']* и после этого преобразуем строковое представление списков непосредственно в списки.\n",
    "\n",
    "После чего мы создадим dummy-признаки по значениям в списках полученных из строковых значений в `Cuisine_Style` \n",
    "\n",
    "Сохраним список всех таких значений(наименований кухни), встречающихся в в `Cuisine_Style`, этот список нам понадобится в дальнейшем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cuisine_styles = get_cuisine_styles(data.Cuisine_Style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, не было ли в признаке пропусков в неявном виде (т.е. в виде пустых строк, строкового представления пустого списка и т.д.). Если это так, то в `cuisine_styles` должна оказаться пустая строка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'' in cuisine_styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking\n",
    "Согласно описанию - место, которое занимает данный ресторан среди всех ресторанов своего города\n",
    "\n",
    "Признак числовой.  \n",
    "Пропусков нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каждом городе разное количество ресторанов, поэтому и диапозон `Ranking` в каждом городе различный (что приводит к тому что наихудший ресторан в маленьком городе будет иметь такой же `Ranking` как и отличный ресторан в мегаполисе). Такая разница масштабов может помешать модели, имеет смысл отнормировать  Ranking в каждом городе отдельно, что мы и сделаем. \n",
    "\n",
    "Так же можно использовать как оценку количества ресторанов в городе максимальную величину `Ranking` для каждого города. Эта величина будет использована как самостоятельный признак и будет участвовать в создании других новых признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним оценку количества ресторанов в городе, она нам понадобится при создании новых признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rest_estimate = data.groupby('City').Ranking.max() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price_Range\n",
    "Согласно описанию - диапазон цен в ресторане   \n",
    "\n",
    "Посмотрим на значения признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$$ - $$$', '$$$$', '$', nan], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Price_Range.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала создадим бинарный признак `Price_Range_NaN` -  наличие (1) или отсутствие (0) пропуска в признаке.\n",
    "\n",
    "Затем приведем признак к числовому виду, сперва закодировав каждый из трех вариантов не-NaN значений соответствующим числом от 1 (для низкого ценового диапозона) до 3 (для высокого ценового диапзона), а затем заполнив пропуски средним арифметическим уже закодированных непустых ячеек."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number_of_Reviews\n",
    "Согласно описанию - количество отзывов о ресторане  \n",
    "\n",
    "Признак в числовой форме.\n",
    "Пропуски в признаке есть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Number_of_Reviews.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение признака в области 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.Number_of_Reviews[data.Number_of_Reviews<10].hist(bins = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед заполнением пропуска создадим бинарный признак наличия/отсутствия значения в признаке , обозначим его `NoR_NaN`. \n",
    "\n",
    "Если сопоставить количество пропусков и распределение, то может возникнуть предположение, что пропуски подразумевают значение 0 или 1. Такая версия не испортит общий вид распределения. Заполнение пропусков 1 в отличии от заполнения 0 упростит использование данного признака при создании признаков новых (на случай если вдруг появится идея поделить на `Number_of_Reviews`) .Поэтому заполним пропуски 1. Этим обработка признака и ограничится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID_TA\n",
    "Согласно описанию - идентификатор ресторана в базе данных TripAdvisor\n",
    "\n",
    "Посмотрим на значения признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    d10746918\n",
       "1     d6674944\n",
       "2    d13129638\n",
       "3      d680417\n",
       "4     d1112354\n",
       "Name: ID_TA, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ID_TA[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения признака строковые, формата **'dЧИСЛО'**, где **ЧИСЛО** - некоторое целое число. Проверим, все ли значения выглядит подобным образом, для этого убедимся что первый символ везде 'd' и что все символы кроме первого - только цифры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.ID_TA.str[0] == 'd').all(), (data.ID_TA.str[1:].str.isnumeric()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем признак -  примем в качесвте значения приведенную к числовому виду его цифровая часть (т.е. **ЧИСЛО**).  \n",
    "В работе будет использоваться гипотеза о том что цифровая часть отражает хронологический порядок появления ресторана в базе данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews\n",
    "Согласно описанию - данные о не более чем двух последних отзывах, которые отображаются на сайте ресторана  \n",
    "\n",
    "Посмотрим на значения признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             [[], []]\n",
       "1    [['Very good reviews!', 'Fine dining in Hakani...\n",
       "2    [['Better than the Links', 'Ivy Black'], ['12/...\n",
       "3    [['Most exquisite', 'Delicious and authentic']...\n",
       "4    [['Always the best in bratislava', 'Very good ...\n",
       "Name: Reviews, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Reviews[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признак строковый,в нем есть неявные пропуски (значения \"[[], []]\"), при работе с признаком надо будет учитывать их наличие. Удалять наблюдения с такими значениями не следует ввиду их значительного количества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8112"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.Reviews == '[[], []]').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В признаке пропусков в явном виде 2, заполним их строковым значением \"[[], []]\"\n"
     ]
    }
   ],
   "source": [
    "print('В признаке пропусков в явном виде {}, заполним их строковым значением \"[[], []]\"'.format(data.Reviews.isna().sum()))\n",
    "data.Reviews.fillna('[[], []]',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с  признаком:\n",
    " - отделим и сохраним текстовую составляющую (собственно отзывы)\n",
    " - получим список дат отзывовов.   \n",
    " На основе этой информации позднее создадим новые признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Review_texts = get_review_texts(data.Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_date_lists = get_review_date_lists(data.Reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL_TA\n",
    "Согласно описанию - URL страницы ресторана на TripAdvosor  \n",
    "\n",
    "Посмотрим на значения признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Restaurant_Review-g187147-d10746918-Reviews-Le_Perchoir-Paris_Ile_de_France.html\n",
      "/Restaurant_Review-g189934-d6674944-Reviews-Ravintola_Kolmon3n-Helsinki_Uusimaa.html\n",
      "/Restaurant_Review-g186525-d13129638-Reviews-Black_Ivy-Edinburgh_Scotland.html\n",
      "/Restaurant_Review-g186338-d680417-Reviews-Quirinale-London_England.html\n",
      "/Restaurant_Review-g274924-d1112354-Reviews-Massimo_Ristorante-Bratislava_Bratislava_Region.html\n"
     ]
    }
   ],
   "source": [
    "for s in data.URL_TA[:5]: print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения строковые, в строке присутсвует индентификатор формата 'g123456'(сопоставление с другими признаками показало что это ID города), затем ID_TA, название ресторана, город/регион.  \n",
    "Получим название и попытаемся такой признак обработать и применить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_names = get_rest_names(data.URL_TA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же получим числовую часть индентификатора вида 'g123456' - возможно в ID города в TripAdvisor содержится \n",
    "какая-то информация (создадим отельный признак `g_id`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация предобработки.\n",
    "Проведем кодирование существующих признаков в соотвтетсвии с принятыми решениями о способах предобработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pre_process(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на максимальные корреляции признаков с целевой переменной (поскольку значительная часть признаков бинарные, то абсолютные значения корреляция Пирсона не очень информативны - тем не менее некотрое представление о нличии взаимосвзяи они дать могут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating                 1.000000\n",
       "sample                 0.936543\n",
       "Ranking                0.168798\n",
       "ID_TA                  0.049589\n",
       "Vegetarian Friendly    0.037317\n",
       "Vegan Options          0.029015\n",
       "Rome                   0.027527\n",
       "Gluten Free Options    0.025691\n",
       "Healthy                0.023766\n",
       "Milan                  0.023233\n",
       "Delicatessen           0.021144\n",
       "Chinese                0.021039\n",
       "Price_Range_NaN        0.020519\n",
       "Mediterranean          0.018614\n",
       "Wine Bar               0.017776\n",
       "Athens                 0.016852\n",
       "Madrid                 0.016232\n",
       "European               0.016217\n",
       "Vietnamese             0.013444\n",
       "Berlin                 0.012834\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr().Rating.abs().sort_values(ascending=False).drop(['Rating','sample'])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `population` - население города, в которм расположен ресторан. Признак возможно интресен и сам по себе, но с большей вероятнотью интересен в сочетании с другими признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.Series({\n",
    "    'Paris':2140526, 'Stockholm':961609, 'London': 8787892, 'Berlin':3601131, 'Munich':1456039, \n",
    "    'Oporto':240000,'Milan':1366180, 'Bratislava': 425923, 'Vienna':1840573, 'Rome': 2872800, \n",
    "    'Barcelona':1620343, 'Madrid':3223334,'Dublin':553165, 'Brussels':1198726, 'Zurich': 428000, \n",
    "    'Warsaw':1758143, 'Budapest':1749734, 'Copenhagen':615993,'Amsterdam':859732, 'Lyon':515695, \n",
    "    'Hamburg':1830584, 'Lisbon':506654, 'Prague':1280508, 'Oslo':673469,'Helsinki':643272, \n",
    "    'Edinburgh':524900 ,'Geneva':499000, 'Ljubljana':258900, 'Athens':655780, 'Luxembourg':115227, \n",
    "    'Krakow':766739\n",
    "})\n",
    "\n",
    "data['City_population'] = data.City.map(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `tourist_arrival` количество постивших город туритсов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourist_arrival = pd.Series({\n",
    "    'London': 19059500, 'Paris': 13926300,'Rome':  9353900,'Prague':  8200600,'Amsterdam':  6898600, \n",
    "    'Barcelona':  6515500, 'Milan':  6175000,'Vienna':  5867600,'Berlin':  5559600,'Madrid':  5131700,\n",
    "    'Dublin':  4810000,'Athens':  4526000,'Munich':  3389300,'Budapest':  3511400,'Lisbon':  3136100,\n",
    "    'Brussels':  2511500,'Copenhagen':  2887700,'Warsaw':  2733000,'Krakow':  2650000,\n",
    "    'Stockholm':  2327000,'Oporto':  1969300,'Bratislava': 986201,'Lyon': 1700000,'Hamburg': 2713200,\n",
    "    'Luxembourg': 1018000,'Ljubljana':  1022862,'Edinburgh': 3300000,'Helsinki': 1700000,'Oslo': 1352112,\n",
    "    'Zurich': 2000000,'Geneva': 2200000\n",
    "})\n",
    "\n",
    "data['tourist_arrival'] = data.City.map(tourist_arrival)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `tourist_population_prop` - отношение прибывших туристов к населению города"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourist_population_prop = tourist_arrival/population\n",
    "data['tourist_population_prop'] = data.City.map(tourist_population_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `styles_num` - количество стилей кухни, представленных в ресторане."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['styles_num'] = data.apply(lambda x: 0 if x.Nan_Style else len(x.Cuisine_Style),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `num_rest_estimate` оценка количества ресторанов в городе (оценкой служит Ranking.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_rest_estimate'] = data.apply(lambda x: num_rest_estimate[x.City], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `rest_per_capita` -  оценочное (по Ranking.max()) количество ресторанов на душу населения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ['rest_per_capita'] = data.apply(lambda x: num_rest_estimate[x.City]/x.City_population, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `reviews_per_capita` - количество отзывов на душу населения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews_per_capita']=data.Number_of_Reviews/data.City_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `since_review` - время прошедшее с даты последнего отзыва"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_data = lambda x: datetime.datetime.strptime(x, '%m/%d/%Y').date() # функция перевода str в datetime\n",
    "today = datetime.datetime.today().date()\n",
    "\n",
    "data['since_review'] = review_date_lists.apply(lambda x: (today - str_to_data(x[-1])).days if x[-1] \n",
    "                                             else -999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `review_date_range` временной интервал между отзывами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review_date_range'] = review_date_lists.apply(lambda x: (str_to_data(x[0]) - str_to_data(x[1])).days if len(x) == 2 \n",
    "                                                  else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `rank_dif_NoR` - разница в рангах отранжированного количества отзывов ***Number_of_Reviews*** и отранжированных по цифрой части ***ID_TA***, основан на предположении, что ***ID_TA*** заполнялся в хронологическом порядке и предположении, что чем дольше ресторан работает, тем больше должно быть отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoR_index = data.Number_of_Reviews[data.Number_of_Reviews != 0].index\n",
    "\n",
    "ID_TA_with_NoR = data.loc[NoR_index].ID_TA\n",
    "\n",
    "NoR_rank_dict = {val: rank for rank, val in enumerate(sorted(data.Number_of_Reviews[NoR_index],reverse=True))}\n",
    "NoR_rank = data.Number_of_Reviews[NoR_index].map(NoR_rank_dict)\n",
    "\n",
    "ID_TA_NoR_rank_dict = {val: rank for rank, val in enumerate(sorted(ID_TA_with_NoR))}\n",
    "ID_TA_NoR_rank = ID_TA_with_NoR.map(ID_TA_NoR_rank_dict)\n",
    "\n",
    "data['rank_dif_NoR'] = ID_TA_NoR_rank - NoR_rank\n",
    "data.rank_dif_NoR.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `rev_text_length` - длинна извлеченного из `Reviews` текста отзыва(-ов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rev_text_length'] = Review_texts.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `rev_on_website` - количество отзывов на сайте, согласно признаку `Reviews`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rev_on_website'] = Review_texts.apply(lambda x: len(x.split(', ')) if x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `punct_in_review` - бинарный признак наличия/отсутствия знаков пунктуации в тектсе отзыва(-ов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"!;:?.,\"\n",
    "data['punct_in_review'] = Review_texts.apply(lambda x: int(bool(set(list(punct)) & set(list(x.replace(', ',''))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `Name_lenght` длина названия в символах. Предположительно хорошие рестораны имеют более претенциозные названия, вероятно - более длинные, чем названия простецких забегаловок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Name_lenght'] = rest_names.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `words_in_name` длина названия в словах. Идея признака та же, что и у `Name_lenght`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['words_in_name'] = rest_names.str.split('_').apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `is_capital`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_capital_dict = {\n",
    "    'Paris':1, 'Stockholm':1, 'London': 1, 'Berlin':1, 'Munich':0, \n",
    "    'Oporto':0,'Milan':0, 'Bratislava': 1, 'Vienna':1, 'Rome': 1, \n",
    "    'Barcelona':0, 'Madrid':1,'Dublin':1, 'Brussels':1, 'Zurich': 0, \n",
    "    'Warsaw':1, 'Budapest':1, 'Copenhagen':1,'Amsterdam':1, 'Lyon':0, \n",
    "    'Hamburg':0, 'Lisbon':1, 'Prague':1, 'Oslo':1,'Helsinki':1, \n",
    "    'Edinburgh':0 ,'Geneva':0, 'Ljubljana':1, 'Athens':1, 'Luxembourg':1, \n",
    "    'Krakow':0\n",
    "}\n",
    "\n",
    "data['is_capital'] = data.City.map(is_capital_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем величину `uniqueness_of_cuisine` - это величина обратная тому, сколько раз кухня встречается в наборе данных.  \n",
    "`uniqueness_of_cuisine` принимает значения в интервале (0, 1] (значения стремящиеся к 0 - кухня встречается очень часто, 1 - кухня встречется всего 1 раз)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cuistyle_list = data.Cuisine_Style.sum()    \n",
    "uniqueness_of_cuisine = 1/pd.Series(total_cuistyle_list).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `sum_uniqueness` - сумма уникальностей стилей кухни ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_uniqueness = lambda x: uniqueness_of_cuisine[x].sum()\n",
    "data['sum_uniqueness'] = data.Cuisine_Style.apply(sum_uniqueness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `max_uniqueness` - максимальная уникальность кухни в ресторане"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_uniqueness = lambda x: uniqueness_of_cuisine[x].max()\n",
    "data['max_uniqueness'] = data.Cuisine_Style.apply(max_uniqueness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `min_uniqueness` - минимальная уникальность (т.е. максимальная распрстранненность, популярность) кухни в ресторане"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_uniqueness = lambda x: uniqueness_of_cuisine[x].min()\n",
    "data['min_uniqueness'] = data.Cuisine_Style.apply(min_uniqueness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем величину `city_uniqueness_of_cuisine` - аналогично `uniqueness_of_cuisine`, только применительно к каждому городу отдельно. С помощью этой величины создадим три новых признака `city_sum_uniqueness` ,`city_max_uniqueness` и `city_min_uniqueness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grouped_by_City = data.groupby('City')\n",
    "\n",
    "city_sum_uniqueness = lambda x: city_uniqueness_of_cuisine[x].sum()\n",
    "city_max_uniqueness = lambda x: city_uniqueness_of_cuisine[x].max()\n",
    "city_min_uniqueness = lambda x: city_uniqueness_of_cuisine[x].min()\n",
    "\n",
    "temp_city_sum = pd.Series()\n",
    "temp_city_max = pd.Series()\n",
    "temp_city_min = pd.Series()\n",
    "\n",
    "for group in grouped_by_City.groups:\n",
    "    index = grouped_by_City.groups[group]\n",
    "    \n",
    "    city_cuistyle_list = data.Cuisine_Style.loc[index].sum()    \n",
    "    city_uniqueness_of_cuisine = 1/pd.Series(city_cuistyle_list).value_counts()\n",
    "    \n",
    "    temp_city_sum = temp_city_sum.append(data.Cuisine_Style.loc[index].apply(city_sum_uniqueness)) \n",
    "    temp_city_max = temp_city_max.append(data.Cuisine_Style.loc[index].apply(city_max_uniqueness))  \n",
    "    temp_city_min = temp_city_min.append(data.Cuisine_Style.loc[index].apply(city_min_uniqueness))\n",
    "    \n",
    "data['city_sum_uniqueness'] = temp_city_sum\n",
    "data['city_max_uniqueness'] = temp_city_max\n",
    "data['city_min_uniqueness'] = temp_city_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем новую величину распрастранненость/популярность кухни `prevalence_of_cuisine` определим её как ***1 - uniqueness_of_cuisine***.  \n",
    "`prevalence_of_cuisine` принимает значения в интервале [0, 1) (0 - кухня встречается всего  1 раз, значения стремящиеся к 1 - кухня крайне распространена)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence_of_cuisine = 1 - uniqueness_of_cuisine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак `sum_prevalence` - сумма распрастраннености стилей кухни ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prevalence = lambda x: prevalence_of_cuisine[x].sum()\n",
    "data['sum_prevalence'] = data.Cuisine_Style.apply(sum_prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим анологичный признак для каждого города - `city_sum_prevalence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grouped_by_City = data.groupby('City')\n",
    "\n",
    "city_sum_prevalence = lambda x: city_prevalence_of_cuisine[x].sum()\n",
    "\n",
    "temp_city_sum = pd.Series()\n",
    "\n",
    "for group in grouped_by_City.groups:\n",
    "    index = grouped_by_City.groups[group]\n",
    "    \n",
    "    city_cuistyle_list = data.Cuisine_Style.loc[index].sum()    \n",
    "    city_prevalence_of_cuisine = 1 - 1/pd.Series(city_cuistyle_list).value_counts()\n",
    "    \n",
    "    temp_city_sum = temp_city_sum.append(data.Cuisine_Style.loc[index].apply(city_sum_prevalence)) \n",
    "    \n",
    "data['city_sum_prevalence'] = temp_city_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый признак - тональность отзыва/-ов `review_sentiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_req = requests.get(pos_url)\n",
    "neg_req = requests.get(neg_url)\n",
    "\n",
    "pos_words = pos_req.text[pos_req.text.find('abound'):].strip().split('\\n')\n",
    "neg_words = neg_req.text[neg_req.text.find('abnormal'):].strip().split('\\n')\n",
    "\n",
    "Review_words = Review_texts.replace(to_replace=r'\\W',value = ' ',regex=True).str.lower().str.split()\n",
    "\n",
    "review_sentiment = lambda x: sum([int(w in pos_words) for w in x]) - sum([int(w in neg_words) for w in x])\n",
    "\n",
    "data['review_sentiment']    = Review_words.apply(review_sentiment).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передадим модели некоторые особенности распределений целевой переменной в каждом городе \n",
    "(потенциально чревато переобучением, проверим на валидационной части выборки не просело ли качество)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['city_median_rating'] = data.City.map(grouped_by_City.Rating.median())\n",
    "\n",
    "data['city_mean_rating'] = data.City.map(grouped_by_City.Rating.mean())\n",
    "\n",
    "data['city_rating_skewness'] = data['city_mean_rating'] - data['city_median_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завершение подготовки данных для обучения модели\n",
    "\n",
    "Удалим те столбцы что более не нужны для создания новых признаков и при этом мы не собираемся их передавать модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "coltodrop = ['Restaurant_id','City', 'Reviews', 'URL_TA', 'Price_Range','Cuisine_Style']\n",
    "enrichmented_data = data.drop(columns=coltodrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько строк проверки корректности обработки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrichmented_data.dtypes[enrichmented_data.dtypes == object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrichmented_data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 195)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrichmented_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В самом начале мы для корректной обработки признаков объединили два исходных датсета в один. Теперь обратно разделим данные на часть для обучения и тестирования модели и часть для получения предсказания (Submission)  и удалим внесенные нами для удобства обработки колонки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = enrichmented_data.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = enrichmented_data.query('sample == 0').drop(['sample','Rating'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
    "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще раз проверяем размерности полученных датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 193), (40000, 194), (40000, 193), (32000, 193), (8000, 193))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаём, обучаем и тестируем модель\n",
    "## Первичное обучение и тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Создаём модель\n",
    "regr = RandomForestRegressor(n_estimators=100, random_state = RANDOM_SEED)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются  \n",
    "Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.197031875\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Искомые значения рейтинга дискретны - от 1 до 5 с шагом 0.5, наверное имеет смысл округлить полученные результаты \n",
    "до этих значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.162\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error((y_pred*2).round()/2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ж, мы получили уже неплохой результат. Но не станем останавливаться и попробуем еще хоть немного продвинуться вперед ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор неполезных признаков\n",
    "Обучив модель, мы теперь можем попытаться улучшить наш датасет отбросив те признаки , которые ухудшают метрику на валидационной части выборки, расчитывая на то что это улучшит точность работы модели на данных для Submission.  \n",
    "Мы последовательно будем изымать по одному признаку из датасета и проверять как изменилась метрика (будем сравнивать с MAE при полном датасете). Если значение MAE улучшилось в отсутсвии признака, то признак будет отнесен к неполезным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 193/193 [3:15:05<00:00, 60.65s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "MAE_threshold = metrics.mean_absolute_error(y_pred, y_test)\n",
    "\n",
    "unuseful_features = pd.Series([])\n",
    "\n",
    "for col in tqdm(X.columns):\n",
    "    X_tmp = X.drop(columns=col)\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X_tmp, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "    regr.fit(X_trn, y_trn)\n",
    "    \n",
    "    y_pr = regr.predict(X_tst)\n",
    "    \n",
    "    MAE_tmp = metrics.mean_absolute_error(y_pr, y_tst) \n",
    "    \n",
    "    if MAE_tmp < MAE_threshold : \n",
    "        unuseful_features[col] = MAE_threshold - MAE_tmp\n",
    "\n",
    "unuseful_features = unuseful_features.sort_values(ascending = False)\n",
    "# unuseful_features.to_csv('unuseful_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате мы получили pd.Series `unuseful_features` c индексами - наименованием признака и значениями - уменьшением метрики МАЕ в отсутствии признака (т.е \"вредом\" от признака)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор оптимального количества исключаемых из датасета признаков\n",
    "Получив неполезные признаки вместо того чтобы просто удалить их из датасета постараемся подобрать оптимальное количество удалямых признаков. Для этого станем удалять признаки по одному, начиная с признака с наибольшим \"вредом\" и будем следить за значениеми обычного МАЕ и МАЕ с использованием округдения предсказания до 0,5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [1:06:24<00:00, 43.31s/it]\n"
     ]
    }
   ],
   "source": [
    "MAE_changes = pd.DataFrame(columns=['MAE', 'MAE_round'])\n",
    "\n",
    "for loc in tqdm(range(0,len(unuseful_features),1)):\n",
    "    to_drop = unuseful_features.index[:loc]\n",
    "    \n",
    "    X_tmp = X.drop(columns=to_drop)\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X_tmp, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "    regr.fit(X_trn, y_trn)\n",
    "    \n",
    "    y_pr = regr.predict(X_tst)\n",
    "    \n",
    "    MAE_tmp = metrics.mean_absolute_error(y_pr, y_tst) \n",
    "    MAE_round_tmp = metrics.mean_absolute_error((y_pr*2).round()/2, y_tst)\n",
    "    MAE_changes.loc[loc] = [MAE_tmp,MAE_round_tmp]\n",
    "#     print('{:3}  {:.6f}  {:.6f}'.format(loc, MAE_tmp,MAE_round_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примем в качестве оптимального результата минимум суммы `MAE` и `MAE_round` и соответсвенно удалим из датасета количество признаков `optim_count` при удалении которого достигается такой миниум."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_count = MAE_changes.sum(axis=1).idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19533625 0.16\n"
     ]
    }
   ],
   "source": [
    "X_optim = X.drop(columns=unuseful_features.index[:optim_count])\n",
    "X_trn, X_tst, y_trn, y_tst = train_test_split(X_optim, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "regr.fit(X_trn, y_trn)\n",
    "\n",
    "y_pr = regr.predict(X_tst)\n",
    "    \n",
    "MAE_optim = metrics.mean_absolute_error(y_pr, y_tst) \n",
    "MAE_round_optim = metrics.mean_absolute_error((y_pr*2).round()/2, y_tst) \n",
    "\n",
    "print(MAE_optim,MAE_round_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Применим обученную на оптимизированом нами датасете модель для получения предсказания на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(columns=unuseful_features.index[:optim_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = regr.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>id_0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>id_1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>id_2</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>id_3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>id_4</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>id_5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>id_6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>id_7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>id_8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>id_9</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant_id  Rating\n",
       "0          id_0     3.0\n",
       "1          id_1     4.0\n",
       "2          id_2     4.5\n",
       "3          id_3     4.5\n",
       "4          id_4     4.5\n",
       "5          id_5     4.5\n",
       "6          id_6     1.5\n",
       "7          id_7     3.0\n",
       "8          id_8     4.0\n",
       "9          id_9     4.5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['Rating'] = (predict_submission*2).round()/2\n",
    "sample_submission.to_csv('submission_tmp.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 201 entries, Restaurant_id to city_rating_skewness\n",
      "dtypes: float64(21), int32(1), int64(139), int8(3), object(6), uint8(31)\n",
      "memory usage: 65.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
