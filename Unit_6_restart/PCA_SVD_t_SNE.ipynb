{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "АЛГОРИТМ РЕАЛИЗАЦИИ PCA\n",
    "1. Стандартизировать данные.\n",
    "2. Рассчитать ковариационную матрицу для объектов.\n",
    "3. Рассчитать собственные значения и собственные векторы для ковариационной матрицы.\n",
    "4. Отсортировать собственные значения и соответствующие им собственные векторы.\n",
    "5. Выбрать  наибольших собственных значений и сформировать матрицу соответствующих собственных векторов.\n",
    "6. Преобразовать исходные данные, умножив матрицу данных на матрицу отобранных собственных векторов.\n",
    "\n",
    "Рассмотрим все шаги на примере.\n",
    "\n",
    ">Примечание. Так как в процессе реализации алгоритма мы будем сталкиваться с достаточно громоздкими вычислениями, часть из них мы будем сопровождать кодом для их выполнения в Python.>\n",
    "\n",
    "Допустим, у нас есть набор данных, состоящий из четырёх признаков:\n",
    "\n",
    "$x_1$|$x_2$|$x_3$|$x_4$\n",
    "-|-|-|-\n",
    "1|2|3|4\n",
    "5|5|6|7\n",
    "1|4|2|3\n",
    "5|3|2|1\n",
    "8|1|2|2\n",
    "\n",
    "\n",
    "Мы хотим сократить количество измерений до двух.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.632456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.563740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.173749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.042493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>-1.264911</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.608121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4\n",
       "0 -1.000000 -0.632456  0.000000  0.260623\n",
       "1  0.333333  1.264911  1.732051  1.563740\n",
       "2 -1.000000  0.632456 -0.577350 -0.173749\n",
       "3  0.333333  0.000000 -0.577350 -1.042493\n",
       "4  1.333333 -1.264911 -0.577350 -0.608121"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "A = np.matrix([[1,2,3,4],\n",
    "               [5,5,6,7],\n",
    "               [1,4,2,3],\n",
    "               [5,3,2,1],\n",
    "               [8,1,2,2]])\n",
    "\n",
    "df = pd.DataFrame(A,columns  = ['x1','x2','x3','x4'])\n",
    "# Стандартизировать данные.\n",
    "df_std  = (df - df.mean()) / (df.std())\n",
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.31622777,  0.04811252, -0.18098843],\n",
       "       [-0.31622777,  1.        ,  0.63900965,  0.61812254],\n",
       "       [ 0.04811252,  0.63900965,  1.        ,  0.94044349],\n",
       "       [-0.18098843,  0.61812254,  0.94044349,  1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Рассчитать ковариационную матрицу для объектов.\n",
    "cov_mat = np.cov(df_std.T)\n",
    "cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитать собственные значения и собственные векторы для ковариационной матрицы.\n",
    "eigen_val, eigen_vectors = np.linalg.eig(cov_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам необходимо выбрать два собственных вектора, так как в итоге мы хотим получить две компоненты. Нужно взять векторы с наибольшими собственными значениями. При нахождении собственных векторов в Python они выводятся в соответствии с убыванием соответствующих собственных значений, поэтому берём первые два вектора:   \n",
    "\n",
    "$$e_1 \\ (0.161960, -0.524048, -0.585896, -0.596547)$$\n",
    "$$e_2 \\ (-0.917059, 0.206922, -0.320539, -0.115935)$$\n",
    "   \n",
    "Осталось только найти главные компоненты. Для этого перемножаем матрицу стандартизированных признаков на матрицу с собственными векторами и получаем матрицу главных компонент:   \n",
    "   \n",
    "   \n",
    "$$\\left(\\begin{array}{rrrr}-1.000000 & -0.632456 & 0.000000 & 0.260623 \\\\ 0.333333 & 1.264911 & 1.732051 & 1.563740 \\\\ -1.000000 & 0.632456 & -0.577350 & -0.173749 \\\\ 0.333333 & 0.000000 & -0.577350 & -1.042493 \\\\ 1.333333 & -1.264911 & -0.577350 & -0.608121\\end{array}\\right) \\cdot \\left(\\begin{array}{rr}0.161960 & -0.917059 \\\\ -0.524048 & 0.206922 \\\\ -0.585896 & -0.320539 \\\\ -0.596547 & -0.115935\\end{array}\\right)=\\left(\\begin{array}{rr}0.014003 & 0.755975 \\\\ -2.556534 & -0.780432 \\\\ -0.051480 & 1.253135 \\\\ 1.014150 & 0.000239 \\\\ 1.579861 & -1.228917\\end{array}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.014003</td>\n",
       "      <td>0.755975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-2.556534</td>\n",
       "      <td>-0.780432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.051480</td>\n",
       "      <td>1.253135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.014150</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.579861</td>\n",
       "      <td>-1.228917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.014003  0.755975\n",
       "1 -2.556534 -0.780432\n",
       "2 -0.051480  1.253135\n",
       "3  1.014150  0.000239\n",
       "4  1.579861 -1.228917"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std @ eigen_vectors[:,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы получили две главных компоненты. Можно проверить, получили ли бы мы тот же результат, если бы воспользовались сразу готовым алгоритмом на `Python` — `PCA`.\n",
    "\n",
    "В параметр `n_components` в качестве значения можно передать количество необходимых компонентов или минимально допустимую объяснённую дисперсию в виде десятичной дроби. Например, если нам нужно столько компонент, чтобы они объясняли не менее 90 % разброса данных, то мы запишем `n_components = 0.9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.40033078e-02,  7.55974765e-01],\n",
       "       [ 2.55653399e+00, -7.80431775e-01],\n",
       "       [ 5.14801919e-02,  1.25313470e+00],\n",
       "       [-1.01415002e+00,  2.38808310e-04],\n",
       "       [-1.57986086e+00, -1.22891650e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#импортируем нужный алгоритм\n",
    "from sklearn.decomposition import PCA\n",
    "#определяем метод главных компонент с двумя компонентами\n",
    "pca = PCA(n_components=2)\n",
    "#обучаем алгоритм на наших данных\n",
    "principalComponents = pca.fit_transform(df_std)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.1\n",
    "Найдите матрицу ковариаций для векторов $(3, 4, 1)$ и $(1, 6, 2)$. В качестве ответа укажите сумму всех значений матрицы, округлённую до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.33"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = np.cov(np.array([[3,4,1],[1,6,2]])).sum()\n",
    "round(ans,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.5\n",
    "Дана матрица признаков:\n",
    "```python\n",
    "A = np.matrix([[8,7,2,9],\n",
    "               [1,3,6,3],\n",
    "               [7,2,0,3],\n",
    "               [10,3,1,1],\n",
    "               [8,1,3,4]])\n",
    "```\n",
    "Какое минимальное количество главных компонент надо выделить, чтобы сохранить информацию о как минимум 90 % разброса данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.matrix([[8,7,2,9],\n",
    "               [1,3,6,3],\n",
    "               [7,2,0,3],\n",
    "               [10,3,1,1],\n",
    "               [8,1,3,4]])\n",
    "pca = PCA(n_components=0.9)\n",
    "#обучаем алгоритм на наших данных\n",
    "A_std = (A - A.mean(axis=0))/A.std(axis=0,ddof=1)\n",
    "pca.fit_transform(A_std).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Снижение размерности: SVD и t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с сингулярного разложения. SVD используется не только для снижения размерности, но и в целом имеет множество применений в машинном обучении, например, в рекомендательных системах — в одном из следующих модулей вы сможете изучить эту тему подробнее.\n",
    "\n",
    "Суть сингулярного разложения заключается в следующей теореме ↓\n",
    "\n",
    "Любую прямоугольную матрицу $A$ размера $(n, m)$ можно представить в виде произведения трёх матриц:\n",
    "\n",
    "$$A_{n \\times m}=U_{n \\times n} \\cdot D_{n \\times m} \\cdot V_{m \\times m}^{T}$$\n",
    "\n",
    "В этой формуле:\n",
    "\n",
    "$U$ — матрица размера $(n, n)$. Все её столбцы ортогональны друг другу и имеют единичную длину. Такие матрицы называются ортогональными. Эта матрица содержит нормированные собственные векторы матрицы $AA^T$.  \n",
    "$D$  — матрица размера $(n, m)$. На её главной диагонали стоят числа, называемые сингулярными числами (они являются корнями из собственных значений матриц $AA^T$ и $A^AT$), а вне главной диагонали стоят нули. Если мы решаем задачу снижения размерности, то элементы этой матрицы, если их возвести в квадрат, можно интерпретировать как дисперсию, которую объясняет каждая компонента.  \n",
    "$V$ — матрица размера $(m, m)$. Она тоже ортогональная и содержит нормированные собственные векторы матрицы $A^AT$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, нам необходимо получить сингулярное разложение для следующей матрицы:\n",
    "\n",
    "$$A=\\left(\\begin{array}{ccc}-1 & 1 & 0 \\\\ -1 & -1 & 1\\end{array}\\right)$$\n",
    "\n",
    "Начнём с поиска матрицы $U$.    \n",
    "Для этого нам необходимо сначала вычислить произведение матриц $A$ и $A^T$:\n",
    "\n",
    "$$A \\cdot A^{T}=\\left(\\begin{array}{rrr}-1 & 1 & 0 \\\\ -1 & -1 & 1\\end{array}\\right) \\cdot\\left(\\begin{array}{rr}-1 & -1 \\\\ 1 & -1 \\\\ 0 & 1\\end{array}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.1\n",
    "Вычислите получившееся произведение матриц  и $A \\cdot A^{T}$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [0, 3]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[-1,1,0],[-1,-1,1]])\n",
    "AAT = A@A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам необходимо решить характеристическое уравнение $det(A - \\lambda E) = 0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import *\n",
    "\n",
    "lamda = symbols('lamda')\n",
    "p = Matrix(AAT).charpoly(lamda)\n",
    "factor(p.as_expr())\n",
    "solve(p,lamda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем два собственных значения: $2, 3$ . Теперь можно извлечь из них корень и получить сингулярные значения (они нужны для матрицы $D$):\n",
    "$$\\sigma_1 = \\sqrt{2}, \\ \\sigma_2 = \\sqrt{3}$$\n",
    "\n",
    "Найдем собственные вектора и нормируем их:, чтобы составить матрицу $U$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1\\\\0\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1],\n",
       "[0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0\\\\1\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[0],\n",
       "[1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.00000000000000],\n",
       "       [0]], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1.00000000000000]], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AAT = A@A.T\n",
    "eigenvec = Matrix(AAT).eigenvects()\n",
    "[display(x[2][0]) for x in eigenvec];\n",
    "[display(np.array(x[2][0])/np.linalg.norm(np.array(x[2][0],dtype=float))) for x in eigenvec];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для нахождения матрицы V нам необходимо повторить всё для $A^{T} \\cdot A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATA = A.T@A\n",
    "lamda = symbols('lamda')\n",
    "p = Matrix(ATA).charpoly(lamda)\n",
    "factor(p.as_expr())\n",
    "solve(p,lamda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma_1 = 0, \\ \\sigma_2 = \\sqrt{2}, \\ \\sigma_3 = \\sqrt{3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}\\frac{1}{2}\\\\\\frac{1}{2}\\\\1\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1/2],\n",
       "[1/2],\n",
       "[  1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}-1\\\\1\\\\0\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[-1],\n",
       "[ 1],\n",
       "[ 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}-1\\\\-1\\\\1\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[-1],\n",
       "[-1],\n",
       "[ 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.408248290463863],\n",
       "       [0.408248290463863],\n",
       "       [0.816496580927726]], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.707106781186547],\n",
       "       [0.707106781186547],\n",
       "       [0]], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.577350269189626],\n",
       "       [-0.577350269189626],\n",
       "       [0.577350269189626]], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ATA = A.T@A\n",
    "eigenvec = Matrix(ATA).eigenvects()\n",
    "[display(x[2][0]) for x in eigenvec];\n",
    "[display(np.array(x[2][0])/np.linalg.norm(np.array(x[2][0],dtype=float))) for x in eigenvec];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем записать соответствующую матрицу $V$. Для этого полученные собственные векторы располагаем в столбцах матрицы в порядке убывания их собственных чисел:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы реализовать сингулярное разложение с помощью библиотеки `sklearn`, необходимо использовать алгоритм `TruncatedSVD()`, в который передаётся n_components в качестве параметра, определяющего количество итоговых компонент:\n",
    "```python\n",
    "# создаём объект класса TruncatedSVD\n",
    "# n_components — размерность нового пространства, n_iter — количество итераций\n",
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "# обучаем модель на данных X\n",
    "svd.fit(X)\n",
    "# применяем уменьшение размерности к матрице X\n",
    "transformed = svd.transform(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.22044605e-16,  1.41421356e+00],\n",
       "       [ 1.73205081e+00, -1.94289029e-16]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "# создаём объект класса TruncatedSVD\n",
    "# n_components — размерность нового пространства, n_iter — количество итераций\n",
    "svd = TruncatedSVD(n_components=2, n_iter=7, random_state=42)\n",
    "# обучаем модель на данных X\n",
    "svd.fit(A)\n",
    "# применяем уменьшение размерности к матрице X\n",
    "transformed = svd.transform(A)\n",
    "transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "Итак, вы уже знакомы с двумя алгоритмами для понижения размерности — PCA и SVD. Теперь давайте познакомимся с третьим — t-SNE (стохастическое вложение соседей с t-распределением). Его преимущество относительно первых двух заключается в том, что он может реализовывать уменьшение размерности и разделение для данных, которые являются линейно неразделимыми. Подобные данные можно визуализировать так:\n",
    "\n",
    "Для реализации t-SNE в sklearn понадобится алгоритм TSNE():\n",
    "```python\n",
    "# импортируем класс TSNE из модуля manifold библиотеки sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "# создаём объект класса TSNE\n",
    "# n_components — размерность нового пространства\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=500, random_state=42)\n",
    "# обучаем модель на данных X\n",
    "tsne.fit(X)\n",
    "# применяем уменьшение размерности к матрице X\n",
    "tsne.transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  164.85704,  1814.0579 ],\n",
       "       [ -164.85692, -1814.0576 ]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# импортируем класс TSNE из модуля manifold библиотеки sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "# создаём объект класса TSNE\n",
    "# n_components — размерность нового пространства\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=500, random_state=42)\n",
    "# обучаем модель на данных X\n",
    "# tsne.fit(A)\n",
    "# применяем уменьшение размерности к матрице X\n",
    "# tsne.transform(A)\n",
    "tsne.fit_transform(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1/2, 4]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = symbols('x')\n",
    "# f = -x**4 + 6*x**3 -4*x**2 + 80\n",
    "# f_x = f.diff(x)\n",
    "# solve(f_x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(\\lambda - 3\\right) \\left(\\lambda - 2\\right)$"
      ],
      "text/plain": [
       "(lamda - 3)*(lamda - 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamda = symbols('lamda')\n",
    "p = Matrix(AAT).charpoly(lamda)\n",
    "factor(p.as_expr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lamda = symbols('lamda')\n",
    "# p = Matrix(AAT).charpoly(lamda)\n",
    "# factor(p.as_expr())\n",
    "# solve(p,lamda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
